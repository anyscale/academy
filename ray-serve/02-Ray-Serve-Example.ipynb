{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Serve - Model Serving Challenges\n",
    "\n",
    "© 2019-2020, Anyscale. All Rights Reserved\n",
    "\n",
    "![Anyscale Academy](../images/AnyscaleAcademy_Logo_clearbanner_141x100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll explore a nontrivial example for Ray Serve.\n",
    "\n",
    "We'll work through an example that also covers training a model, deploying it, then updating later, based on this [documentation example](https://docs.ray.io/en/latest/serve/deployment.html). This page also has a section on [deployment to Kubernetes](https://docs.ray.io/en/latest/serve/deployment.html#deploying-as-a-kubernetes-service).\n",
    "\n",
    "See also the Serve documentation's [mini-tutorials](https://docs.ray.io/en/latest/serve/tutorials/index.html) for using Serve with various frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!../tools/start-ray.sh --check --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import serve\n",
    "import os\n",
    "import requests  # for making web requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(address='auto', ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this time, we either have to restart the ray cluster, or use a different port using the `http_port` argument, which we do here. The next release of Ray will have `serve.shutdown()` method that will allow us to cleanly shutdown Serve at the end of each lesson (like the last one).\n",
    "\n",
    "There is also an `http_host` argument, which defaults to `localhost`. When you want to serve requests from other machines, use `0.0.0.0` for this argument, so those machines can access this service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PORT=8001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serve.init(name='serve-example-2', http_port=PORT)  # Name for this Serve instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, Get a Model to Serve ;)\n",
    "\n",
    "We'll begin by training a classifier with the Iris data we used before, this time using [scikit-learn](https://scikit-learn.org/stable/). The details aren't too important for our purposes, except for the fact we'll save the trained model to disk for subsequent serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "iris_dataset = load_iris()\n",
    "data, target, target_names = iris_dataset[\"data\"], iris_dataset[\n",
    "    \"target\"], iris_dataset[\"target_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation split\n",
    "data, target = sklearn.utils.shuffle(data, target)\n",
    "train_x, train_y = data[:100], target[:100]\n",
    "val_x, val_y = data[100:], target[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models\n",
    "model.fit(train_x, train_y)\n",
    "print(\"MSE:\", mean_squared_error(model.predict(val_x), val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and label to file. (This could also be S3 or other \"global\" place)\n",
    "os.path.exists('/tmp/data') or os.makedirs('/tmp/data')\n",
    "with open(\"/tmp/data/iris_model_logistic_regression.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "with open(\"/tmp/data/iris_labels.json\", \"w\") as f:\n",
    "    json.dump(target_names.tolist(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Model and Serve It\n",
    "\n",
    "Next, we define a servable model by instantiating a class and defining the `__call__` method that Ray Serve will use. Then, we'll define the backend and endpoint that use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoostingModelv1:\n",
    "    def __init__(self):\n",
    "        with open(\"/tmp/data/iris_model_logistic_regression.pkl\", \"rb\") as f:\n",
    "            self.model = pickle.load(f)\n",
    "        with open(\"/tmp/data/iris_labels.json\") as f:\n",
    "            self.label_list = json.load(f)\n",
    "\n",
    "    def __call__(self, flask_request):\n",
    "        payload = flask_request.json\n",
    "        print(\"Worker: received flask request with data\", payload)\n",
    "\n",
    "        input_vector = [\n",
    "            payload[\"sepal length\"],\n",
    "            payload[\"sepal width\"],\n",
    "            payload[\"petal length\"],\n",
    "            payload[\"petal width\"],\n",
    "        ]\n",
    "        prediction = self.model.predict([input_vector])[0]\n",
    "        human_name = self.label_list[prediction]\n",
    "        return {\"result\": human_name, \"version\": \"v1\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serve.create_backend(\"lr:v1\", BoostingModelv1)\n",
    "serve.create_endpoint(\"iris_classifier\", backend=\"lr:v1\", route=\"/regressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally, Serve stores the model as a Ray actor and routes traffic to it as the endpoint is queried, in this case over HTTP. \n",
    "\n",
    "Now let’s query the endpoint to see results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_request_input = {\n",
    "    \"sepal length\": 1.2,\n",
    "    \"sepal width\": 1.0,\n",
    "    \"petal length\": 1.1,\n",
    "    \"petal width\": 0.9,\n",
    "}\n",
    "response = requests.get(f\"http://localhost:{PORT}/regressor\", json=sample_request_input)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying Updated Models\n",
    "\n",
    "Updating the model is as simple as deploying the first version. First we train a new model on the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a new model\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# Training and validation split\n",
    "np.random.shuffle(data), np.random.shuffle(target)\n",
    "train_x, train_y = data[:100], target[:100]\n",
    "val_x, val_y = data[100:], target[100:]\n",
    "\n",
    "# Train and evaluate models\n",
    "model.fit(train_x, train_y)\n",
    "print(\"MSE:\", mean_squared_error(model.predict(val_x), val_y))\n",
    "\n",
    "# Save the model and label to file\n",
    "with open(\"/tmp/data/iris_model_logistic_regression_2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "with open(\"/tmp/data/iris_labels_2.json\", \"w\") as f:\n",
    "    json.dump(target_names.tolist(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a new model class that uses the saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoostingModelv2:\n",
    "    def __init__(self):\n",
    "        with open(\"/tmp/data/iris_model_logistic_regression_2.pkl\", \"rb\") as f:\n",
    "            self.model = pickle.load(f)\n",
    "        with open(\"/tmp/data/iris_labels_2.json\") as f:\n",
    "            self.label_list = json.load(f)\n",
    "\n",
    "    def __call__(self, flask_request):\n",
    "        payload = flask_request.json\n",
    "        print(\"Worker: received flask request with data\", payload)\n",
    "\n",
    "        input_vector = [\n",
    "            payload[\"sepal length\"],\n",
    "            payload[\"sepal width\"],\n",
    "            payload[\"petal length\"],\n",
    "            payload[\"petal width\"],\n",
    "        ]\n",
    "        prediction = self.model.predict([input_vector])[0]\n",
    "        human_name = self.label_list[prediction]\n",
    "        return {\"result\": human_name, \"version\": \"v2\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a new backend with this model and set the `iris_classifier` traffic to split the traffic between the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serve.create_backend(\"lr:v2\", BoostingModelv2)\n",
    "serve.set_traffic(\"iris_classifier\", {\"lr:v2\": 0.25, \"lr:v1\": 0.75})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    response = requests.get(f\"http://localhost:{PORT}/regressor\", json=sample_request_input).json()\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Try More Models and Traffic Patterns\n",
    "\n",
    "Here are some things you can try:\n",
    "\n",
    "1. Refactor for the `BoostingModelvN` classes to eliminate duplication. We don't need separate implementations because we could use constructor arguments to specify what's unique for each one. Recall that you can pass constructor arguments to `serve.create_backend()`.\n",
    "2. Add one or more new models.\n",
    "3. Change the traffic patterns.\n",
    "4. \"Automate\" the steps we did:\n",
    "    * Wrap the training in a function.\n",
    "    * Run the whole sequence of retraining every minute for a few minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = serve.list_endpoints()\n",
    "for name in eps.keys():\n",
    "    serve.delete_endpoint(name)\n",
    "\n",
    "bes = serve.list_backends()\n",
    "for name in bes.keys():\n",
    "    serve.delete_backend(name)\n",
    "\n",
    "eps = serve.list_endpoints()\n",
    "bes = serve.list_backends()\n",
    "print(f'endpoints: {eps}, backends {bes}')\n",
    "\n",
    "# serve.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()  # \"Undo ray.init()\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

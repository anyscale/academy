{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline of the notebook\n",
    "\n",
    "- [Defining a MDP for recommendation system using gym API](#recsys) (15 min)\n",
    "- [Online RL - Bandits](#bandits) (15 min)\n",
    "- [Online RL - DQN](#dqn) (15 min)\n",
    "- [Break](#break) (5 min)\n",
    "- [Offline RL](#offline-rl) - (15 min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a RecSys gym environement <a class=\"anchor\" id=\"recsys\"></a>\n",
    "\n",
    "RL is usually a fit when it comes to sequential decision making problems. For example in recommendation systems, the particular items that our AI recommends could impact the interest profile of the users that it interacts with and as result, can have consequences on the next time-step that it is making a decision. This is in contrast to the passive prediction problems where the task is simply to predict the future and that prediction does not change the outcome.\n",
    "\n",
    "To successfully train RL agents we usually need a good simulator that can approximate real-world behavior about what is going to happen if your agent takes certain actions. It is always recomended to start with an environement that can be used to emulate real-world behavior. \n",
    "\n",
    "In this section, we will learn how to create and evaluate an exemplar RecSys environment using gym API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecSim\n",
    "\n",
    "In this notebook, we will use <b><a href=\"https://github.com/google-research/recsim\">Google's RecSim environment</a></b>, which was developed for the YouTube recommendation problem.  It is a configurable environment, where ideally you would plug in your own users, products, and embedding features.\n",
    "\n",
    "**Some further readings**\n",
    "\n",
    "- <a href=\"https://github.com/google-research/recsim\">RecSim github</a>\n",
    "- <a href=\"https://arxiv.org/pdf/1909.04847.pdf\">RecSim paper</a>\n",
    "\n",
    "The following image depicts all the components of the recsim packages:\n",
    "\n",
    "<img src=\"./images/recsim_environment.png\" width=\"70%\" />\n",
    "\n",
    "The environment is <i>Timelimit-based</i>, meaning the termination condition for an episode will be after a fixed number (10) of videos are watched. \n",
    "\n",
    "### Document Model\n",
    "Documents represent the candidate pool of items that need to be recommended with features sampled in the range [0, 1].  In this tutorial, we use <b>1 single feature \"sweetness\"</b> drawn from a uniform distribution between [0.8, 1.0] to represent \"chocolaty\" items and [0, 0.2] for the \"kaley\" options. \n",
    "- The documents can be different at each step (produced by some \"candidate generation\" process), or fixed throughout the simulation.\n",
    "- The recommendation algorithm observes the D candidate documents.  It then makes a selection (possibly ordered) of k documents and presents them in a \"slate\" to the user. We will focus on **slate size of 1** in this tutorial. \n",
    "\n",
    "### User Model\n",
    "In RecSim users are representation by a set of features some of which could be latent hidden variables not observed by our recommendation system during live interaction. In this tutorial we assume that a sampled user from the world does not own any observable features like age, gender, etc. and our AI should infer the latent state of the user from its history of interactions in the current session. \n",
    "- The user examines a \"slate\" of recommended items and makes a choice of one item. After making their choice, the user emits an engagement score which indicates how much that user was engaged with that particular item they chose. The agent has to learn to estimate the latent states of the user that shape their choice model in the future. \n",
    "\n",
    "### User Choice\n",
    "This module controls how a particular user would respond to a set of recommendations and how its latent state would evolve as a function of this interaction. \n",
    "In the environment in this tutorial, engagement is assumed to be a function of two competing phenomenas:\n",
    "-   The love of the user for sweet items ($sweetness(item_t)$)\n",
    "-   The long term satisfaction which cares about healthier options. It is inversely correlated with the sweetness of items suggested so far ($satisfaction_{t-1}$)\n",
    "\n",
    "$$satisfaction_t := satisfaction_{t-1} * \\sigma(-sweetness(item_{t}))$$\n",
    "$$r(item_t) \\propto sweetness(item_t) * satisfaction_{t-1}$$\n",
    "\n",
    "i.e. If a user who loves chocolates have not had chocolate for a while, a chocolate item would be more engaging than a kaley item. On the other hand if we keep recommending chocolate to the same person, they may lose interest and not use our recommendations. \n",
    "\n",
    "\n",
    "Let's look at this enviornement properties closer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment for running on anyscale\n",
    "# import os; os.environ[\"PATH\"] = \"/home/ray/anaconda3/bin:\" + os.environ[\"PATH\"]\n",
    "# !pip uninstall -y torch\n",
    "# !python -m pip install torch==1.12.1\n",
    "# !python -m pip install seaborn\n",
    "# import torch\n",
    "# print(f\"torch: {torch.__version__}\")\n",
    "\n",
    "# !pip uninstall -y -r matplotlib\n",
    "# !python3 -m pip install matplotlib==3.5.3\n",
    "# import matplotlib\n",
    "# print(f\"matplotlib: {matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ray import tune, air, data\n",
    "\n",
    "import recsim \n",
    "from rllib_recsim.rllib_recsim import ModifiedLongTermSatisfactionRecSimEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main parameters\n",
    "seed = 100\n",
    "num_candidates = 20\n",
    "reward_scale = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ModifiedLongTermSatisfactionRecSimEnv<RecSimRewardScalingWrapper<MultiDiscreteToDiscreteActionWrapper<RecSimObservationSpaceWrapper<RecSimResetWrapper<RecSimGymEnv instance>>>>>>\n"
     ]
    }
   ],
   "source": [
    "# Let's first instantiate the environment\n",
    "\n",
    "config = {\n",
    "    # The number of possible documents/videos/candidates that we can recommend\n",
    "    \"num_candidates\": num_candidates,  \n",
    "    # The number of recommendations that we will be making\n",
    "    \"slate_size\": 1, \n",
    "    # Set to False for re-using the same candidate documents each timestep.\n",
    "    \"resample_documents\": True,\n",
    "    # Use consistent seeds for the environment ...\n",
    "    \"seed\": seed,\n",
    "    # scale rewards with this factor\n",
    "    \"reward_scale\": reward_scale,\n",
    "}\n",
    "\n",
    "env = ModifiedLongTermSatisfactionRecSimEnv(config)\n",
    "print(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The printed environement shows a hierarchy of wrappers around the main RecSim environment. Next we'll investigate the behavior of observation and action space. For more info on how the environement is actually implemented we refer you to the source code acompanied with this tutorial [link](https://github.com/anyscale/academy/blob/main/ray-rllib/acm_recsys_tutorial_2022/rllib_recsim/rllib_recsim.py). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_space:\n",
      "--------------------\n",
      "Dict(user:Box([], [], (0,), float32), doc:Dict(0:Box(0.0, 1.0, (1,), float32), 1:Box(0.0, 1.0, (1,), float32), 2:Box(0.0, 1.0, (1,), float32), 3:Box(0.0, 1.0, (1,), float32), 4:Box(0.0, 1.0, (1,), float32), 5:Box(0.0, 1.0, (1,), float32), 6:Box(0.0, 1.0, (1,), float32), 7:Box(0.0, 1.0, (1,), float32), 8:Box(0.0, 1.0, (1,), float32), 9:Box(0.0, 1.0, (1,), float32), 10:Box(0.0, 1.0, (1,), float32), 11:Box(0.0, 1.0, (1,), float32), 12:Box(0.0, 1.0, (1,), float32), 13:Box(0.0, 1.0, (1,), float32), 14:Box(0.0, 1.0, (1,), float32), 15:Box(0.0, 1.0, (1,), float32), 16:Box(0.0, 1.0, (1,), float32), 17:Box(0.0, 1.0, (1,), float32), 18:Box(0.0, 1.0, (1,), float32), 19:Box(0.0, 1.0, (1,), float32)), response:Tuple(Dict(click:Discrete(2), engagement:Box(-1.0, 100.0, (), float32))), time:Box(-0.5, 0.5, (1,), float32))\n",
      "observation_space example:\n",
      "--------------------\n",
      "OrderedDict([('user', array([], dtype=float32)), ('doc', OrderedDict([('0', array([0.83111256], dtype=float32)), ('1', array([0.47927853], dtype=float32)), ('2', array([0.5880454], dtype=float32)), ('3', array([0.31429517], dtype=float32)), ('4', array([0.8732589], dtype=float32)), ('5', array([0.5587437], dtype=float32)), ('6', array([0.02945912], dtype=float32)), ('7', array([0.9591497], dtype=float32)), ('8', array([0.88397664], dtype=float32)), ('9', array([0.25147244], dtype=float32)), ('10', array([0.39137182], dtype=float32)), ('11', array([0.44803938], dtype=float32)), ('12', array([0.5563462], dtype=float32)), ('13', array([0.47802916], dtype=float32)), ('14', array([0.7866306], dtype=float32)), ('15', array([0.891135], dtype=float32)), ('16', array([0.7064005], dtype=float32)), ('17', array([0.6542282], dtype=float32)), ('18', array([0.5505308], dtype=float32)), ('19', array([0.41507348], dtype=float32))])), ('response', (OrderedDict([('click', 0), ('engagement', array(47.62905, dtype=float32))]),)), ('time', array([-0.37091717], dtype=float32))])\n",
      "observation space keys:\n",
      "--------------------\n",
      "['user', 'doc', 'response', 'time']\n"
     ]
    }
   ],
   "source": [
    "# Let's checkout the observation space and action space\n",
    "print(\"observation_space:\")\n",
    "print(\"-\"*20)\n",
    "print(env.observation_space)\n",
    "print(\"observation_space example:\")\n",
    "print(\"-\"*20)\n",
    "print(env.observation_space.sample())\n",
    "print(\"observation space keys:\")\n",
    "print(\"-\"*20)\n",
    "print(list(env.observation_space.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observation space is a dictionary of four keys. \n",
    "- The `user` key is empty, because there is no observable user features. \n",
    "- The `doc` key contains a set of documents presented with numerical keys. Each doc item has a scalar score representing its sweetness. \n",
    "- The `response` key includes a single record of `click` and `engagement` from the immediate previous interaction. \n",
    "- The `time` shows a normalized timestep within the session for this user. -0.5 corresponds to the beginnig of the interaction and +0.5 corresponds to the end of the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_space:\n",
      "--------------------\n",
      "Discrete(20)\n",
      "action_space example:\n",
      "--------------------\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Let's checkout the action space\n",
    "print(\"action_space:\")\n",
    "print(\"-\"*20)\n",
    "print(env.action_space)\n",
    "print(\"action_space example:\")\n",
    "print(\"-\"*20)\n",
    "print(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The action space is simply an integer number between 0, 19 (`Discrete(20)`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now checkout environement's reward behavior. Let's see what happens if we always pick the sweetest item and plot the reward over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's checkout the reward space\n",
    "# TODO: code here\n",
    "rewards = []\n",
    "obs = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = int(max(obs[\"doc\"], key=lambda x: obs[\"doc\"][x]))\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    rewards.append(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'step')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGwCAYAAACzXI8XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABT6klEQVR4nO3deVxU5eIG8OfMMDPsA8guiAsIgriihrhkmlvXLe+tzK65ZNd+aOZSadcyyzRbzBbTStMyzRa1xdtmpKi5g6i5o6jIKioMwzLAzPz+QEYIFw7McJiZ5/v5zEfmnDOHh7xdnt73PecIRqPRCCIiIiIrJJM6ABEREVF9scgQERGR1WKRISIiIqvFIkNERERWi0WGiIiIrBaLDBEREVktFhkiIiKyWg5SB7A0g8GAzMxMuLm5QRAEqeMQERFRHRiNRhQWFiIwMBAy2e3HXWy+yGRmZiI4OFjqGERERFQP6enpCAoKuu1+my8ybm5uACr/Qbi7u0uchoiIiOpCo9EgODjY9Hv8dmy+yFRNJ7m7u7PIEBERWZm7LQvhYl8iIiKyWiwyREREZLVYZIiIiMhqscgQERGR1WKRISIiIqslaZFZsWIFOnToYLqiKDY2Fj///LNp/7333gtBEGq8pkyZImFiIiIiakokvfw6KCgIr7/+OsLCwmA0GvHZZ59hxIgROHz4MKKiogAAkydPxiuvvGL6jLOzs1RxiYiIqImRtMgMGzasxvvXXnsNK1aswL59+0xFxtnZGf7+/lLEIyIioiauyayR0ev12LhxI4qKihAbG2vavn79enh7e6N9+/aYO3cuiouL73genU4HjUZT40VERES2SfI7+x47dgyxsbEoLS2Fq6srtmzZgsjISADAo48+ipCQEAQGBuLo0aN4/vnncfr0aWzevPm251u8eDEWLFjQWPGJiIhIQoLRaDRKGaCsrAyXLl1CQUEBvv32W6xatQqJiYmmMlPdH3/8gf79+yM1NRVt2rS55fl0Oh10Op3pfdWzGgoKCviIAiIiIiuh0WigVqvv+vtb9NRSy5Yt8corr+DSpUsNClhFqVQiNDQUXbt2xeLFi9GxY0e8++67tzy2R48eAIDU1NTbnk+lUpmuguLzlYiIiGyb6CLzzDPPYPPmzWjdujXuv/9+bNy4scYISEMZDIbbni8lJQUAEBAQYLbvV18GgxHnrmiRpzXfz05ERETi1KvIpKSk4MCBA2jXrh2mTZuGgIAATJ06FcnJyaLONXfuXOzcuRMXLlzAsWPHMHfuXOzYsQNjx47FuXPn8OqrryIpKQkXLlzADz/8gHHjxqFPnz7o0KGD2NhmF78hGf3fTsTWI5lSRyEiIrJb9b5qqUuXLnjvvfeQmZmJ+fPnY9WqVejWrRs6deqETz/9FHVZepObm4tx48YhPDwc/fv3x8GDB/Hrr7/i/vvvh1KpxO+//46BAwciIiICs2bNwujRo/Hjjz/WN7JZhfm5AQCOZ/KqKCIiIqnU+6ql8vJybNmyBWvWrMG2bdtwzz33YNKkSbh8+TJeeOEF/P7779iwYcMdz7F69erb7gsODkZiYmJ941lcVGDl2hsWGSIiIumILjLJyclYs2YNvvzyS8hkMowbNw7vvPMOIiIiTMeMGjUK3bp1M2vQpqaqyJzNLURZhQFKhyZzSx4iIiK7IbrIdOvWDffffz9WrFiBkSNHQqFQ1DqmVatWeOSRR8wSsKlq7uEEtZMCBSXlOJNTiPbN1VJHIiIisjuii8z58+cREhJyx2NcXFywZs2aeoeyBoIgICrQHXvOXcWJTA2LDBERkQREz4fk5uZi//79tbbv378fhw4dMksoa3FznUyBxEmIiIjsk+giEx8fj/T09FrbMzIyEB8fb5ZQ1iIqsHIUhgt+iYiIpCG6yJw4cQJdunSptb1z5844ceKEWUJZi6oRmRNZGugNkj7pgYiIyC6JLjIqlQo5OTm1tmdlZcHBQfJnUDaq1j6ucFTIUFymx4WrRVLHISIisjuii8zAgQMxd+5cFBTcXBeSn5+PF154Affff79ZwzV1cpmAdgG8nwwREZFURBeZt956C+np6QgJCUG/fv3Qr18/tGrVCtnZ2Xj77bctkbFJ44JfIiIi6YieC2revDmOHj2K9evX48iRI3BycsKECRMwZsyYW95TxtZVLfg9wREZIiKiRlevRS0uLi548sknzZ3FKlV/VIHRaIQgCBInIiIish91KjI//PADhgwZAoVCgR9++OGOxw4fPtwswaxFWz83yGUCrhWVIVtTigC1k9SRiIiI7EadiszIkSORnZ0NX19fjBw58rbHCYIAvV5vrmxWwVEhR5ivK05lF+J4hoZFhoiIqBHVabGvwWCAr6+v6evbveytxFSJ5JOwiYiIJMFHNpvBzTv88solIiKixlSnqaX33nuvzid8+umn6x3GWkVxRIaIiEgSdSoy77zzTp1OJgiCXRaZqqmljPwS5BeXwcNZKXEiIiIi+1CnIpOWlmbpHFbN3VGBFl7OuHStGCcyNegZ6i11JCIiIrvQoDUyRqMRRiMflghweomIiEgK9Soyn3/+OaKjo+Hk5AQnJyd06NAB69atM3c2q8JHFRARETU+0Xf2Xbp0KV588UVMnToVcXFxAIDdu3djypQpyMvLw4wZM8we0hrcvHKJIzJERESNRXSRef/997FixQqMGzfOtG348OGIiorCyy+/bMdFpnJE5twVLUrK9HBSyiVOREREZPtETy1lZWWhZ8+etbb37NkTWVlZZglljXzdHeHtqoLBCJzM5qgMERFRYxBdZEJDQ/H111/X2v7VV18hLCzMLKGsFRf8EhERNS7RU0sLFizAww8/jJ07d5rWyPz5559ISEi4ZcGxJ1GB7kg8cwUnuOCXiIioUYgekRk9ejT2798Pb29vfPfdd/juu+/g7e2NAwcOYNSoUZbIaDXaN+eCXyIiosYkekQGALp27YovvvjC3FmsXtXU0qnsQpTrDVDI+SgrIiIiS6pXkdHr9diyZQtOnjwJAIiMjMSIESPg4FCv09mMYE9nuKkcUKirwLkrWkT4u0sdiYiIyKaJbh7Hjx/H8OHDkZ2djfDwcADAkiVL4OPjgx9//BHt27c3e0hrIZMJaBfojgNp13A8Q8MiQ0REZGGi5z6eeOIJREVF4fLly0hOTkZycjLS09PRoUMHPPnkk5bIaFV45RIREVHjET0ik5KSgkOHDsHT09O0zdPTE6+99hq6detm1nDW6OYdfnnlEhERkaWJHpFp27YtcnJyam3Pzc1FaGioWUJZs6oRmRNZGj5Qk4iIyMJEF5nFixfj6aefxrfffovLly/j8uXL+Pbbb/HMM89gyZIl0Gg0ppc9CvV1hdJBhsLSCqRfK5E6DhERkU0TPbX0j3/8AwDw0EMPQRAEADCNPAwbNsz0XhAE6PV6c+W0Ggq5DOF+bjiWUYDjmQVo0cxZ6khEREQ2S3SR2b59uyVy2JSoQPcbRUaDIdEBUschIiKyWaKLTN++fS2Rw6bcvHKJC36JiIgsibeetYDIQD6qgIiIqDGwyFhAuwA3CAKQW6jDlUKd1HGIiIhsFouMBTgrHdDa2wUAp5eIiIgsiUXGQqI4vURERGRxoovM/PnzcfHiRbN88xUrVqBDhw5wd3eHu7s7YmNj8fPPP5v2l5aWIj4+Hs2aNYOrqytGjx59y5vxNUVc8EtERGR5oovM999/jzZt2qB///7YsGEDdLr6rwEJCgrC66+/jqSkJBw6dAj33XcfRowYgePHjwMAZsyYgR9//BHffPMNEhMTkZmZiQcffLDe368xcUSGiIjI8gRjPe6jf/jwYaxZswZffvklKioq8Mgjj2DixIlmedaSl5cX3nzzTfzzn/+Ej48PNmzYgH/+858AgFOnTqFdu3bYu3cv7rnnnjqdT6PRQK1Wo6CgAO7ujfc06utFZej86jYAwNGXB8LdUdFo35uIiMja1fX3d73WyHTu3BnvvfceMjMzsXr1aly+fBlxcXHo0KED3n33XRQUiJ9O0ev12LhxI4qKihAbG4ukpCSUl5djwIABpmMiIiLQokUL7N2797bn0el0NR6TINWjEjxdlGju4QQAOMlRGSIiIoto0GJfo9GI8vJylJWVwWg0wtPTEx988AGCg4Px1Vdf1ekcx44dg6urK1QqFaZMmYItW7YgMjIS2dnZUCqV8PDwqHG8n58fsrOzb3u+xYsXQ61Wm17BwcEN+REbJNK0ToZFhoiIyBLqVWSSkpIwdepUBAQEYMaMGejcuTNOnjyJxMREnD17Fq+99hqefvrpOp0rPDwcKSkp2L9/P5566ik8/vjjOHHiRH1iAQDmzp2LgoIC0ys9Pb3e52qoKBYZIiIiixL9iILo6GicOnUKAwcOxOrVqzFs2DDI5fIax4wZMwbTp0+v0/mUSiVCQ0MBAF27dsXBgwfx7rvv4uGHH0ZZWRny8/NrjMrk5OTA39//tudTqVRQqVRifyyLuLngl1cuERERWYLoEZmHHnoIFy5cwP/+9z+MHDmyVokBAG9vbxgMhnoFMhgM0Ol06Nq1KxQKBRISEkz7Tp8+jUuXLiE2NrZe525sVSMyqbla6Crs70ngREREliZ6RObFF1802zefO3cuhgwZghYtWqCwsBAbNmzAjh078Ouvv0KtVmPSpEmYOXMmvLy84O7ujmnTpiE2NrbOVyxJLUDtCE9nBa4Xl+NMthbRQWqpIxEREdmUOhWZmTNn1vmES5curfOxubm5GDduHLKysqBWq9GhQwf8+uuvuP/++wEA77zzDmQyGUaPHg2dTodBgwbhww8/rPP5pSYIAqIC1didmofjmQUsMkRERGZWpyJz+PDhGu+Tk5NRUVGB8PBwAMCZM2cgl8vRtWtXUd989erVd9zv6OiI5cuXY/ny5aLO25REBbrfKDJc8EtERGRudSoy27dvN329dOlSuLm54bPPPoOnpycA4Pr165gwYQJ69+5tmZRWLJKPKiAiIrIY0Yt93377bSxevNhUYgDA09MTCxcuxNtvv23WcLag6sqlk1mF0BtE30SZiIiI7kB0kdFoNLhy5Uqt7VeuXEFhYaFZQtmSVt4ucFLIUVKuR1pekdRxiIiIbIroIjNq1ChMmDABmzdvxuXLl3H58mVs2rQJkyZNspoHOjYmuUxAuwA3AJxeIiIiMjfRRWblypUYMmQIHn30UYSEhCAkJASPPvooBg8ebFVXFDWmqumlE1zwS0REZFai7yPj7OyMDz/8EG+++SbOnTsHAGjTpg1cXFzMHs5WVN0Y7y+OyBAREZlVvR8amZWVhaysLISFhcHFxQVGIxey3s7NRxVo+M+JiIjIjEQXmatXr6J///5o27Ythg4diqysLADApEmTMGvWLLMHtAVt/V3hIBOQX1yOzIJSqeMQERHZDNFFZsaMGVAoFLh06RKcnZ1N2x9++GH88ssvZg1nK1QOcoT6ugIAjmdweomIiMhcRBeZ3377DUuWLEFQUFCN7WFhYbh48aLZgtma6tNLREREZB6ii0xRUVGNkZgq165dg0qlMksoW9S+edUdfllkiIiIzEV0kenduzc+//xz03tBEGAwGPDGG2+gX79+Zg1nS25egs2pJSIiInMRffn1G2+8gf79++PQoUMoKyvDc889h+PHj+PatWv4888/LZHRJlTdFC+zoBTXi8rg6aKUOBEREZH1Ez0i0759e5w5cwZxcXEYMWIEioqK8OCDD+Lw4cNo06aNJTLaBDdHBVo2q5yS4/QSERGReYgekQEAtVqNefPmmTuLzYsKVOPC1WIczyxArzBvqeMQERFZvXrdEG/Xrl147LHH0LNnT2RkZAAA1q1bh927d5s1nK2JDOSCXyIiInMSXWQ2bdqEQYMGwcnJCcnJydDpdACAgoICLFq0yOwBbUmUqchwwS8REZE5iC4yCxcuxMqVK/HJJ59AoVCYtsfFxSE5Odms4WxN1ZVL5/OKUFxWIXEaIiIi6ye6yJw+fRp9+vSptV2tViM/P98cmWyWj5sKvm4qGI3AyaxCqeMQERFZPdFFxt/fH6mpqbW27969G61btzZLKFtWNb3E+8kQERE1nOgiM3nyZEyfPh379++HIAjIzMzE+vXrMXv2bDz11FOWyGhT+KgCIiIi8xF9+fWcOXNgMBjQv39/FBcXo0+fPlCpVJg9ezamTZtmiYw2JYpXLhEREZmNqCKj1+vx559/Ij4+Hs8++yxSU1Oh1WoRGRkJV1dXS2W0KVUjMqezC1GuN0Ahr9cV8ERERASRU0tyuRwDBw7E9evXoVQqERkZie7du7PEiBDs5QQ3RweU6Q04m6OVOg4REZFVq9cjCs6fP2+JLHZBEAREBvB+MkREROZQr/vIzJ49G1u3bkVWVhY0Gk2NF90dF/wSERGZh+jFvkOHDgUADB8+HIIgmLYbjUYIggC9Xm++dDbq5iXYLDJEREQNIbrIbN++3RI57EpU8xtFJksDg8EImUy4yyeIiIjoVkQXmb59+1oih10J9XGFykEGra4Cl64Vo6W3i9SRiIiIrJLoInP06NFbbhcEAY6OjmjRogVUKlWDg9kyB7kMEf5uOHK5AMczNSwyRERE9SS6yHTq1KnG2pi/UygUePjhh/HRRx/B0dGxQeFsWWSg+kaRKcADHQKkjkNERGSVRF+1tGXLFoSFheHjjz9GSkoKUlJS8PHHHyM8PBwbNmzA6tWr8ccff2DevHmWyGszeIdfIiKihhM9IvPaa6/h3XffxaBBg0zboqOjERQUhBdffBEHDhyAi4sLZs2ahbfeesusYW0JiwwREVHDiR6ROXbsGEJCQmptDwkJwbFjxwBUTj9lZWU1PJ0Ni/B3h0wA8rQ65GpKpY5DRERklUQXmYiICLz++usoKyszbSsvL8frr7+OiIgIAEBGRgb8/PzMl9IGOSnlaONT+WgHjsoQERHVj+ippeXLl2P48OEICgpChw4dAFSO0uj1emzduhUAcP78efzf//2feZPaoKhAd5zN1eJ4ZgH6RfhKHYeIiMjqiC4yPXv2RFpaGtavX48zZ84AAP71r3/h0UcfhZubGwDg3//+t3lT2qioQDW+S8nkiAwREVE9iS4yAODm5oYpU6aYO4vd4YJfIiKihhG9RobMJ/JGkbl0rRgFJeUSpyEiIrI+LDIS8nBWormHEwA+QJKIiKg+JC0yixcvRrdu3eDm5gZfX1+MHDkSp0+frnHMvffeC0EQarxsaVrr5vRSgcRJiIiIrI+kRSYxMRHx8fHYt28ftm3bhvLycgwcOBBFRUU1jps8eTKysrJMrzfeeEOixOYXFagGwBEZIiKi+qjXYt8qWq0WBoOhxjZ3d/c6f/6XX36p8X7t2rXw9fVFUlIS+vTpY9ru7OwMf3//Op1Tp9NBp9OZ3ms0TbsgcMEvERFR/YkekUlLS8MDDzwAFxcXqNVqeHp6wtPTEx4eHvD09GxQmIKCyukVLy+vGtvXr18Pb29vtG/fHnPnzkVxcfFtz7F48WKo1WrTKzg4uEGZLC2qeWWRSb2iRWm5XuI0RERE1kUwGo1GMR+Ii4uD0WjE9OnT4efnV+tJ2H379q1XEIPBgOHDhyM/Px+7d+82bf/4448REhKCwMBAHD16FM8//zy6d++OzZs33/I8txqRCQ4ORkFBgajRosZiNBrRdeHvuFZUhu/j49Ax2EPqSERERJLTaDRQq9V3/f0temrpyJEjSEpKQnh4eIMC/l18fDz++uuvGiUGAJ588knT19HR0QgICED//v1x7tw5tGnTptZ5VCoVVCqVWbNZkiAIiAp0x66zeTieqWGRISIiEkH01FK3bt2Qnp5u1hBTp07F1q1bsX37dgQFBd3x2B49egAAUlNTzZpBSlULfnnlEhERkTiiR2RWrVqFKVOmICMjA+3bt4dCoaixv+r5S3VhNBoxbdo0bNmyBTt27ECrVq3u+pmUlBQAQEBAgKjcTRkX/BIREdWP6CJz5coVnDt3DhMmTDBtEwQBRqMRgiBAr6/7gtX4+Hhs2LAB33//Pdzc3JCdnQ0AUKvVcHJywrlz57BhwwYMHToUzZo1w9GjRzFjxgz06dNHVGFq6qqKzKlsDfQGI+Qy4S6fICIiIqAeRWbixIno3Lkzvvzyy1su9hVjxYoVACpvelfdmjVrMH78eCiVSvz+++9YtmwZioqKEBwcjNGjR2PevHn1/p5NUctmLnBRylFUpsf5K1qE+blJHYmIiMgqiC4yFy9exA8//IDQ0NAGf/O7XTAVHByMxMTEBn+fpk4mE9AuwB2HLl7H8UwNiwwREVEdiV7se9999+HIkSOWyGLX+KgCIiIi8USPyAwbNgwzZszAsWPHEB0dXWux7/Dhw80Wzp7cvHKJC36JiIjqSnSRqXpg4yuvvFJrn9jFvnRTZLUrl6oWThMREdGdiZ5aMhgMt32xxNRfWz83KOQCCkrKkZFfInUcIiIiqyDp06/pJqWDDGG+lYt8Ob1ERERUN6Knlm41pVTdSy+9VO8w9i4q0B0nsjQ4nlGAQVF1e9o3ERGRPRNdZLZs2VLjfXl5OdLS0uDg4IA2bdqwyDRAVKA7vkniiAwREVFdiS4yhw8frrVNo9Fg/PjxGDVqlFlC2auo5rxyiYiISAyzrJFxd3fHggUL8OKLL5rjdHarXYA7BAHI1pTiqlYndRwiIqImz2yLfQsKClBQwJu5NYSrygEtm7kA4KgMERFRXYieWnrvvfdqvDcajcjKysK6deswZMgQswWzV5GB7kjLK8LxTA36tPWROg4REVGTJrrIvPPOOzXey2Qy+Pj44PHHH8fcuXPNFsxeRQW6439Hs/ioAiIiojoQXWTS0tIskYNuqHpUwQlOLREREd0Vb4jXxFQ9PDLtahGKdBUSpyEiImraRI/IlJaW4v3338f27duRm5sLg8FQY39ycrLZwtkjb1cV/N0dka0pxcksDWJaekkdiYiIqMkSXWQmTZqE3377Df/85z/RvXt3PtzQAqIC3ZGtKcXxTBYZIiKiOxFdZLZu3YqffvoJcXFxlshDqCwyCadyueCXiIjoLkSvkWnevDnc3NwskYVuiAzkHX6JiIjqQnSRefvtt/H888/j4sWLlshDuLng90xOIcoqDHc5moiIyH6JnlqKiYlBaWkpWrduDWdnZygUihr7r127ZrZw9irI0wlqJwUKSspxNrfQdEk2ERER1SS6yIwZMwYZGRlYtGgR/Pz8uNjXAgRBQGSAO/aev4rjmRoWGSIiotsQXWT27NmDvXv3omPHjpbIQzdEBVYWGd4Yj4iI6PZEr5GJiIhASUmJJbJQNVHNK9fJ/JXBK5eIiIhuR3SRef311zFr1izs2LEDV69ehUajqfEi86iaTjqZpYHBYJQ4DRERUdMkempp8ODBAID+/fvX2G40GiEIAvR6vXmS2bnW3i5QOchQVKbHhatFaO3jKnUkIiKiJkd0kdm+fbslctDfOMhliAhwx5H0fBzP1LDIEBER3YLoItO3b19L5KBbiAq8WWSGdQyUOg4REVGTU6cic/ToUbRv3x4ymQxHjx6947EdOnQwSzC6eWM8PqqAiIjo1upUZDp16oTs7Gz4+vqiU6dOEAQBRmPtBahcI2NeVQt+T2RqTGuQiIiI6KY6FZm0tDT4+PiYvqbGEeHvBrlMwNWiMuRodPBXO0odiYiIqEmpU5EJCQm55dd/d6tRGqo/R4UcbXxccCZHi+OZBSwyREREfyP6PjLjx49HUVFRre0XLlxAnz59zBKKbmrPJ2ETERHdlugic+TIEXTo0AF79+41bfvss8/QsWNHeHt7mzUcAZFc8EtERHRboi+/PnDgAF544QXce++9mDVrFlJTU/Hzzz9j6dKlmDx5siUy2rUojsgQERHdlugio1Ao8Oabb8LZ2RmvvvoqHBwckJiYiNjYWEvks3tVIzKXr5egoLgcameFxImIiIiaDtFTS+Xl5Zg1axaWLFmCuXPnIjY2Fg8++CB++uknS+Sze2onBYK9nAAAx7M4vURERFSd6BGZmJgYFBcXY8eOHbjnnntgNBrxxhtv4MEHH8TEiRPx4YcfWiKnXYsKUCP9WglOZGrQsw3XIREREVURPSITExODlJQU3HPPPQAqb4L3/PPPY+/evdi5c6fZA1L1O/xynQwREVF1okdkVq9efcvtnTt3RlJSUoMDUW1RzXnlEhER0a2IHpGprrS0FBqNxvTS6XSiPr948WJ069YNbm5u8PX1xciRI3H69Ola3yM+Ph7NmjWDq6srRo8ejZycnIbEtjpVVy6l5mpRUsZHQBAREVURXWSKioowdepU+Pr6wsXFBZ6enjVeYiQmJiI+Ph779u3Dtm3bUF5ejoEDB9a44d6MGTPw448/4ptvvkFiYiIyMzPx4IMPio1t1XzdVPB2VcJgBE5lc3qJiIioiuippeeeew7bt2/HihUr8O9//xvLly9HRkYGPvroI7z++uuizvXLL7/UeL927Vr4+voiKSkJffr0QUFBAVavXo0NGzbgvvvuAwCsWbMG7dq1w759+0zrdGydIAiIDFRj55krOJ6pQecW4gojERGRrRI9IvPjjz/iww8/xOjRo+Hg4IDevXtj3rx5WLRoEdavX9+gMAUFlWtAvLy8AABJSUkoLy/HgAEDTMdERESgRYsWNe4sXJ1Op6sx3aXR2MYIBhf8EhER1Sa6yFy7dg2tW7cGALi7u+PatWsAgF69ejXoqiWDwYBnnnkGcXFxaN++PQAgOzsbSqUSHh4eNY718/NDdnb2Lc+zePFiqNVq0ys4OLjemZqSqiJzggt+iYiITEQXmdatWyMtLQ1A5ejI119/DaBypObvhUOM+Ph4/PXXX9i4cWO9zwEAc+fORUFBgemVnp7eoPM1FVULfk9lF6JCb5A4DRERUdMgushMmDABR44cAQDMmTMHy5cvh6OjI2bMmIFnn322XiGmTp2KrVu3Yvv27QgKCjJt9/f3R1lZGfLz82scn5OTA39//1ueS6VSwd3dvcbLFoR4OcNV5QBdhQHnrtR++jgREZE9Er3Yd8aMGaavBwwYgFOnTiEpKQmhoaHo0KGDqHMZjUZMmzYNW7ZswY4dO9CqVasa+7t27QqFQoGEhASMHj0aAHD69GlcunTJ7p7tJJMJaBfghoMXruN4ZgHC/d2kjkRERCQ50UXm70JCQhASElKvz8bHx2PDhg34/vvv4ebmZlr3olar4eTkBLVajUmTJmHmzJnw8vKCu7s7pk2bhtjYWLu5Yqm6qED1jSKjwYNdpE5DREQkvXoVmYMHD2L79u3Izc2FwVBzvcbSpUvrfJ4VK1YAAO69994a29esWYPx48cDAN555x3IZDKMHj0aOp0OgwYNstvnOUUG8g6/RERE1YkuMosWLcK8efMQHh4OPz8/CIJg2lf967owGo13PcbR0RHLly/H8uXLxUa1Oe1vLPg9kamB0WgU/c+biIjI1oguMu+++y4+/fRT04gJNZ4wP1co5TJoSitw+XoJgr2cpY5EREQkKdFXLclkMsTFxVkiC92FQi5DW39XAJxeIiIiAupRZGbMmMFpHglFBVROL/EOv0RERPWYWpo9ezYeeOABtGnTBpGRkVAoFDX2b9682WzhqLao5u7AIRYZIiIioB5F5umnn8b27dvRr18/NGvWjAtOG1kUr1wiIiIyEV1kPvvsM2zatAkPPPCAJfLQXUT4u0MQgByNDlcKdfBxU0kdiYiISDKi18h4eXmhTZs2lshCdeCickArbxcAHJUhIiISXWRefvllzJ8/H8XFxZbIQ3VQ9QBJrpMhIiJ7J3pq6b333sO5c+fg5+eHli1b1lrsm5ycbLZwdGtRge748UgmTrDIEBGRnRNdZEaOHGmBGCQGF/wSERFVEl1k5s+fb4kcJELV1NKFq8UoLC2Hm6PiLp8gIiKyTaLXyJD0vFyUCFA7AgBOZhVKnIaIiEg6LDJWitNLRERELDJWK5JXLhEREbHIWKubIzIsMkREZL9EFZny8nK0adMGJ0+etFQeqqOqInM2pxC6Cr3EaYiIiKQhqsgoFAqUlpZaKguJ0NzDCR7OClQYjDibo5U6DhERkSRETy3Fx8djyZIlqKiosEQeqiNBELjgl4iI7J7o+8gcPHgQCQkJ+O233xAdHQ0XF5ca+zdv3my2cHRnUYFq/Jl6letkiIjIbokuMh4eHhg9erQlspBIXPBLRET2TnSRWbNmjSVyUD1UFZmTWRroDUbIZYLEiYiIiBqX6CJT5cqVKzh9+jQAIDw8HD4+PmYLRXXTytsVTgo5isv0uHC1CG18XKWORERE1KhEL/YtKirCxIkTERAQgD59+qBPnz4IDAzEpEmTUFxcbImMdBtymYCIADcAnF4iIiL7JLrIzJw5E4mJifjxxx+Rn5+P/Px8fP/990hMTMSsWbMskZHuwLROJoNXLhERkf0RPbW0adMmfPvtt7j33ntN24YOHQonJyc89NBDWLFihTnz0V1E8VEFRERkx0SPyBQXF8PPz6/Wdl9fX04tSaD6vWSMRqPEaYiIiBqX6CITGxuL+fPn17jDb0lJCRYsWIDY2FizhqO7a+vnBrlMwPXicmQV8K7LRERkX0RPLS1btgyDBw9GUFAQOnbsCAA4cuQIHB0d8euvv5o9IN2Zo0KOMF9XnMouxPFMDQI9nKSORERE1GhEF5no6GicPXsW69evx6lTpwAAY8aMwdixY+HkxF+iUogMdL9RZApwf2TtaT8iIiJbVaci06VLFyQkJMDT0xOvvPIKZs+ejcmTJ1s6G9VRVKAam5MzuOCXiIjsTp3WyJw8eRJFRUUAgAULFkCr5dOWm5KqBb8nWGSIiMjO1GlEplOnTpgwYQJ69eoFo9GIt956C66ut76L7EsvvWTWgHR3kTeKTEZ+Ca4XlcHTRSlxIiIiosZRpyKzdu1azJ8/H1u3boUgCPj555/h4FD7o4IgsMhIwN1RgRZezrh0rRgnsjSIC/WWOhIREVGjqFORCQ8Px8aNGwEAMpkMCQkJ8PX1tWgwEicq0B2XrhXjeGYBiwwREdkN0feRMRgMLDFNUPvmvMMvERHZH9FFhpqmSNMdfllkiIjIfrDI2IiqK5fOX9GipEwvcRoiIqLGwSJjI3zdHOHjpoLBCJzM5qgMERHZBxYZGxLF6SUiIrIzoh9RUOXQoUM4efIkAKBdu3aIiYkxWyiqn6hAd+w4fQUnMgukjkJERNQoRI/IXL58Gb1790b37t0xffp0TJ8+Hd27d0evXr1w+fJlUefauXMnhg0bhsDAQAiCgO+++67G/vHjx0MQhBqvwYMHi41sN6ICK69c+iuDIzJERGQfRBeZJ554AuXl5Th58iSuXbuGa9eu4eTJkzAYDHjiiSdEnauoqAgdO3bE8uXLb3vM4MGDkZWVZXp9+eWXYiPbjaqppdPZhSjXGyROQ0REZHmip5YSExOxZ88ehIeHm7aFh4fj/fffR+/evUWda8iQIRgyZMgdj1GpVPD396/zOXU6HXQ6nem9RmM/oxPBns5wUzmgUFeB1Fwt2gW4Sx2JiIjIokSPyAQHB6O8vLzWdr1ej8DAQLOEqm7Hjh3w9fVFeHg4nnrqKVy9evWOxy9evBhqtdr0Cg4ONnumpkomE9COC36JiMiOiC4yb775JqZNm4ZDhw6Zth06dAjTp0/HW2+9ZdZwgwcPxueff46EhAQsWbIEiYmJGDJkCPT6298nZe7cuSgoKDC90tPTzZqpqbt55RIX/BIRke0TPbU0fvx4FBcXo0ePHqYHR1ZUVMDBwQETJ07ExIkTTcdeu3atQeEeeeQR09fR0dHo0KED2rRpgx07dqB///63/IxKpYJKpWrQ97VmVQt+OSJDRET2QHSRWbZsmQVi1E3r1q3h7e2N1NTU2xYZe1c1InMyUwODwQiZTJA4ERERkeWILjKPP/64JXLUyeXLl3H16lUEBARIlqGpC/V1hdJBhkJdBdKvFyOkmYvUkYiIiCymXnf2PXfuHObNm4cxY8YgNzcXAPDzzz/j+PHjos6j1WqRkpKClJQUAEBaWhpSUlJw6dIlaLVaPPvss9i3bx8uXLiAhIQEjBgxAqGhoRg0aFB9YtsFhVyGcD83AJxeIiIi2ye6yCQmJiI6Ohr79+/H5s2bodVqAQBHjhzB/PnzRZ3r0KFD6Ny5Mzp37gwAmDlzJjp37oyXXnoJcrkcR48exfDhw9G2bVtMmjQJXbt2xa5du+x6DUxdcMEvERHZC9FTS3PmzMHChQsxc+ZMuLm5mbbfd999+OCDD0Sd695774XRaLzt/l9//VVsPAKfuURERPZD9IjMsWPHMGrUqFrbfX19kZeXZ5ZQ1DCRvHKJiIjshOgi4+HhgaysrFrbDx8+jObNm5slFDVMuwA3yATgSqEOuYWlUschIiKyGNFF5pFHHsHzzz+P7OxsCIIAg8GAP//8E7Nnz8a4ceMskZFEclY6oLWPKwCOyhARkW0TXWQWLVqEiIgIBAcHQ6vVIjIyEn369EHPnj0xb948S2SkeqhaJ3OCRYaIiGyY6MW+SqUSn3zyCV566SUcO3YMWq0WnTt3RlhYmCXyUT1FBbrj+5RMXrlEREQ2TfSIzCuvvILi4mIEBwdj6NCheOihhxAWFoaSkhK88sorlshI9cBHFRARkT0QXWQWLFhgundMdcXFxViwYIFZQlHDVU0tXbxaDE1p7aeVExER2QLRRcZoNEIQaj+/58iRI/Dy8jJLKGo4D2clmns4AeA6GSIisl11XiPj6ekJQRAgCALatm1bo8zo9XpotVpMmTLFIiGpfiID3ZGRX4LjmRrc07qZ1HGIiIjMrs5FZtmyZTAajZg4cSIWLFgAtVpt2qdUKtGyZUvExsZaJCTVT1SgO7adyOGCXyIisll1LjJVT71u1aoV4uLi4OAg+oInamRVC345tURERLZK9BoZNzc3nDx50vT++++/x8iRI/HCCy+grKzMrOGoYaoW/J7N1aK0XC9xGiIiIvMTXWT+85//4MyZMwCA8+fP4+GHH4azszO++eYbPPfcc2YPSPUXoHaEp7MCeoMRZ3IKpY5DRERkdqKLzJkzZ9CpUycAwDfffIO+fftiw4YNWLt2LTZt2mTufNQAgiDwfjJERGTT6nX5tcFgAAD8/vvvGDp0KAAgODiYT79ugqqml7jgl4iIbJHoIhMTE4OFCxdi3bp1SExMxAMPPAAASEtLg5+fn9kDUsNEmooMR2SIiMj2iC4yy5YtQ3JyMqZOnYr//ve/CA0NBQB8++236Nmzp9kDUsNUTS2dyiqE3mCUOA0REZF5ib6GukOHDjh27Fit7W+++SbkcrlZQpH5tPJ2gZNCjpJyPdLytAj1dZM6EhERkdmIHpG5HUdHRygUCnOdjsxELhPQLqCyvHB6iYiIbI3Zigw1Xe2b88olIiKyTSwydoBXLhERka1ikbED1e8lYzRywS8REdkOUUWmvLwcbdq0qfGIAmr6wvxc4SATkF9cjsyCUqnjEBERmY2oIqNQKFBayl+E1kblIEeYX+WC378yOL1ERES2Q/TUUnx8PJYsWYKKigpL5CELieKN8YiIyAaJvo/MwYMHkZCQgN9++w3R0dFwcXGpsX/z5s1mC0fmExXojm+TgBNc8EtERDZEdJHx8PDA6NGjLZGFLIgPjyQiIlskusisWbPGEjnIwqpuipdVUIprRWXwclFKnIiIiKjh6nX5dUVFBX7//Xd89NFHKCwsBABkZmZCq9WaNRyZj5ujAi2bOQPg/WSIiMh2iB6RuXjxIgYPHoxLly5Bp9Ph/vvvh5ubG5YsWQKdToeVK1daIieZQVSgGheuFuN4pga9w3ykjkNERNRgokdkpk+fjpiYGFy/fh1OTk6m7aNGjUJCQoJZw5F5RfLKJSIisjGiR2R27dqFPXv2QKmsucaiZcuWyMjIMFswMj8+qoCIiGyN6BEZg8EAvV5fa/vly5fh5uZmllBkGVVXLqXlFaFIx/sAERGR9RNdZAYOHIhly5aZ3guCAK1Wi/nz52Po0KHmzEZm5uOmgq+bCkYjcCqb00tERGT9RBeZt99+G3/++SciIyNRWlqKRx991DSttGTJEktkJDPiHX6JiMiWiF4jExQUhCNHjmDjxo04evQotFotJk2ahLFjx9ZY/EtNU1SgGttPX8HxDBYZIiKyfqKLDAA4ODjgscceM3cWagSmEZksLvglIiLrV68ic/r0abz//vs4efIkAKBdu3aYOnUqIiIizBqOzK9988oFv2eytSjXG6CQ1+ueiERERE2C6N9imzZtQvv27ZGUlISOHTuiY8eOSE5ORnR0NDZt2mSJjGRGQZ5OcHd0QJnegLM5vBMzERFZN9FF5rnnnsPcuXOxd+9eLF26FEuXLsWePXvwwgsv4LnnnhN1rp07d2LYsGEIDAyEIAj47rvvauw3Go146aWXEBAQACcnJwwYMABnz54VG5mqEQSh2o3xOL1ERETWTXSRycrKwrhx42ptf+yxx5CVlSXqXEVFRejYsSOWL19+y/1vvPEG3nvvPaxcuRL79++Hi4sLBg0ahNLSUrGxqRo+CZuIiGyF6DUy9957L3bt2oXQ0NAa23fv3o3evXuLOteQIUMwZMiQW+4zGo1YtmwZ5s2bhxEjRgAAPv/8c/j5+eG7777DI488IjY63cA7/BIRka0QXWSGDx+O559/HklJSbjnnnsAAPv27cM333yDBQsW4IcffqhxbH2lpaUhOzsbAwYMMG1Tq9Xo0aMH9u7de9sio9PpoNPpTO81Go46/F3ViMyJTA0MBiNkMkHiRERERPUjusj83//9HwDgww8/xIcffnjLfUDlWoxbPcqgrrKzswEAfn5+Nbb7+fmZ9t3K4sWLsWDBgnp/X3vQxscFKgcZisr0uHitGK28XaSOREREVC/1etZSXV4NKTENMXfuXBQUFJhe6enpkuRoyhzkMkT4Vz4Xi9NLRERkzZrsTUT8/f0BADk5OTW25+TkmPbdikqlgru7e40X1RbJBb9ERGQDmmyRadWqFfz9/ZGQkGDaptFosH//fsTGxkqYzDbwmUtERGQL6nVnX3PRarVITU01vU9LS0NKSgq8vLzQokULPPPMM1i4cCHCwsLQqlUrvPjiiwgMDMTIkSOlC20jqorMicwCGI1GCAIX/BIRkfWRtMgcOnQI/fr1M72fOXMmAODxxx/H2rVr8dxzz6GoqAhPPvkk8vPz0atXL/zyyy9wdHSUKrLNiPB3h0wA8rRlyC3Uwc+d/0yJiMj6CEaj0Sh1CEvSaDRQq9UoKCjgepm/uX9pIs7mavHp+BjcF+F39w8QERE1krr+/ha9RkYulyM3N7fW9qtXr0Iul4s9HUnItE4mg+tkiIjIOokuMrcbwNHpdFAqlQ0ORI2HjyogIiJrV+c1Mu+99x6AyhvdrVq1Cq6urqZ9er0eO3fuREREhPkTksWYRmSyeC8ZIiKyTnUuMu+88w6AyhGZlStX1phGUiqVaNmyJVauXGn+hGQxVU/BTr9WgoKScqidFBInIiIiEqfORSYtLQ0A0K9fP2zevBmenp4WC0WNw8NZieYeTsjIL8GJTA1i2zSTOhIREZEootfIbN++nSXGhrRvXjkq81cGp5eIiMj6iL6PjF6vx9q1a5GQkIDc3FwYDIYa+//44w+zhSPL69LCE78ez8EH21MRF+ptmm4iIiKyBqKLzPTp07F27Vo88MADaN++Pe8Ia+UeuycEvx7PRvKlfPx79X589Z97EOrrJnUsIiKiOhF9Qzxvb298/vnnGDp0qKUymRVviHd3BSXlGLtqH/7K0MDPXYWv/xOLkGYuUsciIiI7ZrEb4imVSoSGhjYoHDUtaicFPp/YA239XJGj0eHRT/YjI79E6lhERER3JbrIzJo1C+++++5tb4xH1snLRYkvnuiBVt4uyMgvwdhP9iFXUyp1LCIiojsSPbU0atQobN++HV5eXoiKioJCUfPeI5s3bzZrwIbi1JI4mfkl+NfKvcjIL0GYryu++k8svFx4x2YiImpcFpta8vDwwKhRo9C3b194e3tDrVbXeJF1C/RwwpeT74Gfuwpnc7X49+r9KCgplzoWERHRLfHp13RLqblaPPzRXlwtKkPnFh5YN6kHXFWiL3IjIiKqF4uNyABARUUFfv/9d3z00UcoLCwEAGRmZkKr1dYvLTU5ob6u+OKJHlA7KXD4Uj6e+OwgSsv1UsciIiKqQXSRuXjxIqKjozFixAjEx8fjypUrAIAlS5Zg9uzZZg9I0mkX4I7PJ3aHq8oB+85fw3/WJUFXwTJDRERNh+giM336dMTExOD69etwcnIybR81ahQSEhLMGo6k1zHYA2smdIOTQo7EM1cwbcNhlOsNd/8gERFRIxBdZHbt2oV58+ZBqax5JUvLli2RkZFhtmDUdHRr6YVPxsVA6SDDbydyMOvrI9AbbHppFRERWQnRRcZgMECvrz29cPnyZbi58db2tqpXmDdWPtYFDjIBPxzJxNzNR2FgmSEiIomJLjIDBw7EsmXLTO8FQYBWq8X8+fOt5rEFVD/3RfjhvTGdIROArw9dxoIfj/PGiEREJCnRl19fvnwZgwYNgtFoxNmzZxETE4OzZ8/C29sbO3fuhK+vr6Wy1gsvvza/zcmXMeubIzAagf/0bY05gyP48FAiIjKruv7+rtd9ZCoqKrBx40YcPXoUWq0WXbp0wdixY2ss/m0qWGQsY8P+S3hhyzEAwIwBbTF9QJjEiYiIyJbU9fd3ve5w5uDggMcee6ze4cj6PdqjBUrK9Xh16wm88/sZOClleLJPG6ljERGRnalXkcnMzMTu3buRm5sLg6HmpbhPP/20WYJR0zepVyuUluvx5q+nseinU3BSyPHv2JZSxyIiIjsiusisXbsW//nPf6BUKtGsWbMaayMEQWCRsTPx/UJRXFaB5dvP4cXvj0OlkOOhmGCpYxERkZ0QvUYmODgYU6ZMwdy5cyGT1esJB42Ka2Qsz2g04tWtJ/Hpn2mQCcC7j3TGsI6BUsciIiIrZrFnLRUXF+ORRx6xihJDjUMQBLz4j3YY070FDEZgxlcp+O14ttSxiIjIDohuI5MmTcI333xjiSxkxQRBwGsj22NU5+aoMBgxdcNhJJ65InUsIiKycaKnlvR6Pf7xj3+gpKQE0dHRUCgUNfYvXbrUrAEbilNLjatCb8C0Lw/j57+y4aiQYe2E7rindTOpYxERkZWx2OXXixcvxq+//orw8HAAqLXYl+ybg1yGdx/pDN0XSfjjVC4mrT2IdU/0QJcWnlJHIyIiGyR6RMbT0xPvvPMOxo8fb6FI5sURGWmUlusx6bOD+DP1KtwdHbBh8j1o31wtdSwiIrISFlvsq1KpEBcX16BwZPscFXJ8Mi4GMSGe0JRWYNynB3A2p1DqWEREZGNEF5np06fj/ffft0QWsjHOSgd8OqEbOgSpca2oDI+u2o+0vCKpYxERkQ0RPbU0atQo/PHHH2jWrBmioqJqLfbdvHmzWQM2FKeWpJdfXIZHPt6HU9mFCFQ74uspsQjydJY6FhERNWEWm1ry8PDAgw8+iL59+8Lb2xtqtbrGi+jvPJyVWDepB1r7uCCzoBRjV+1HjqZU6lhERGQD6vX0a2vCEZmmI7ugFP/6aA/Sr5Ug1NcVXz15D5q5qqSORURETZDFRmQAoKKiAr///js++ugjFBZWLuDMzMyEVqutX1qyC/5qR2x44h4EqB2RmqvFY6sPoKC4XOpYRERkxUQXmYsXLyI6OhojRoxAfHw8rlypvHvrkiVLMHv2bLMHJNsS7OWM9U/0gLerCiezNBi35gAKS1lmiIiofup11VJMTAyuX78OJycn0/ZRo0YhISHBrOHINrX2ccX6J3rA01mBI+n5mLT2EErK9FLHIiIiKyS6yOzatQvz5s2DUqmssb1ly5bIyMgwWzCybeH+bvh8Yg+4qRxw4MI1PLnuEErLWWaIiEgc0UXGYDBAr6/9C+fy5ctwc3MzS6gqL7/8MgRBqPGKiIgw6/cg6UQHqbF2Yjc4K+XYdTYPUzcko1xvkDoWERFZEdFFZuDAgVi2bJnpvSAI0Gq1mD9/PoYOHWrObACAqKgoZGVlmV67d+82+/cg6XQN8cKqx2OgcpDh95O5eOarFOgNNn0hHRERmZHoh0a+/fbbGDRoECIjI1FaWopHH30UZ8+ehbe3N7788kvzB3RwgL+/v9nPS01HzzbeWPnvrnjy80P439EsODrI8eY/O0Am40NIiYjozkQXmaCgIBw5cgQbN27E0aNHodVqMWnSJIwdO7bG4l9zOXv2LAIDA+Ho6IjY2FgsXrwYLVq0uO3xOp0OOp3O9F6j0Zg9E5lfv3BfvD+mC+I3JGNT8mU4KWV4dUR7PlGdiIjuqEnfEO/nn3+GVqtFeHg4srKysGDBAmRkZOCvv/667Xqcl19+GQsWLKi1nTfEsw7fp2Tgma9SYDQCk3u3wgtD27HMEBHZobreEE90kfnhhx9ufSJBgKOjI0JDQ9GqVStxaesoPz8fISEhWLp0KSZNmnTLY241IhMcHMwiY0W+OngJz286BgB4un8YZt7fVuJERETU2OpaZERPLY0cORKCIODv/adqmyAI6NWrF7777jt4enqKT34HHh4eaNu2LVJTU297jEqlgkrF295bs4e7tUBJmR4v/3gC7yWchZNCjqfubSN1LCIiaoJEX7W0bds2dOvWDdu2bUNBQQEKCgqwbds29OjRA1u3bsXOnTtx9epVi9zlV6vV4ty5cwgICDD7ualpGR/XCs8PrrzUfskvp7D2zzSJExERUVMkekRm+vTp+Pjjj9GzZ0/Ttv79+8PR0RFPPvkkjh8/jmXLlmHixIkNDjd79mwMGzYMISEhyMzMxPz58yGXyzFmzJgGn5uavqfubYOSsgq890cqXv7xBJyUcjzc7fYLvYmIyP6ILjLnzp275VyVu7s7zp8/DwAICwtDXl5eg8NdvnwZY8aMwdWrV+Hj44NevXph37598PHxafC5yTrMuL8tSsr1+GRXGuZsPgZHhRwjOjWXOhYRETURootM165d8eyzz+Lzzz83FYorV67gueeeQ7du3QBUXjIdHBzc4HAbN25s8DnIugmCgBeGtkNJuR5f7LuEmV8fgcpBjsHteW8hIiKqxxqZ1atXIy0tDUFBQQgNDUVoaCiCgoJw4cIFrFq1CkDlWpZ58+aZPSzZJ0EQ8Mrw9hjdJQh6gxHTvkzG9tO5UsciIqImoF73kTEYDPjtt99w5swZAEB4eDjuv/9+yGSie5HF1fXyLWr69AYjnt54GP87mgWVgwxrJnRDzzbeUsciIiILsNh9ZKwNi4xtKdcb8NQXyfj9ZA6clXKsm9QdXUO8pI5FRERmZtEiU1RUhMTERFy6dAllZWU19j399NPi01oQi4ztKS3XY/Lnh7DrbB7cVA7YMPkeRAeppY5FRERmZLEic/jwYQwdOhTFxcUoKiqCl5cX8vLy4OzsDF9fX9OVS00Fi4xtKinT4/E1B3Ag7Ro8nBX46slYhPvf+rEVRERkfer6+1v0opYZM2Zg2LBhuH79OpycnLBv3z5cvHgRXbt2xVtvvdWg0ER15aSU49Px3dAx2AP5xeUYu2o/zl/RSh2LiIgamegik5KSglmzZkEmk0Eul0On0yE4OBhvvPEGXnjhBUtkJLolV5UDPp/QHZEB7sjT6jB21X4cSLuGCr1B6mhERNRIRBcZhUJhujrJ19cXly5dAgCo1Wqkp6ebNx3RXaidFVg3qTtCfV2RVVCKhz7ai86vbsN/1h3Cun0XcfFqkdQRiYjIgkTfEK9z5844ePAgwsLC0LdvX7z00kvIy8vDunXr0L59e0tkJLqjZq4qbHiiB1776SR2nL6CgpJy/Ho8B78ezwEABHs5oXeYD3qHeqNnG2+onRUSJyYiInMRvdj30KFDKCwsRL9+/ZCbm4tx48Zhz549CAsLw6effoqOHTtaKmu9cLGvfdEbjPgrowC7zl7BrrN5SL50HeX6m/8TlwlAhyAP9A7zRu8wH3Ru4QGFvOnd/4iIyN7xPjI3sMjYtyJdBfanXcXOM3nYnZqH1NyaC4JdlHLEtmmGXqHe6N3WB629XSAIgkRpiYioCovMDSwyVF1WQQl2nc3D7rOVxeZaUc37IAWqHdE7zAe9wrwRF+oNLxelREmJiOybxYpM586db/lfrIIgwNHREaGhoRg/fjz69esnPrUFsMjQ7RgMRpzI0lQWm9QrOJh2HWXVrngSBKB9oBq9wrzRO8wbXUM8oXKQS5iYiMh+WKzIzJ07FytWrEB0dDS6d+8OADh48CCOHj2K8ePH48SJE0hISMDmzZsxYsSIhv0UZsAiQ3VVUqbHgQvXsOvMFexOzcOp7MIa+50UcvRo7YVeod7o09YHYb6unIYiIrIQixWZyZMno0WLFnjxxRdrbF+4cCEuXryITz75BPPnz8f//vc/HDp0qH7pzYhFhuorV1OK3al52HW28pWn1dXY7+euQlyoN/qE+SAu1Bs+biqJkhIR2R6LFRm1Wo2kpCSEhobW2J6amoquXbuioKAAp06dQrdu3VBYWHibszQeFhkyB6PRiNM5hdh1Jg+7UvOw//xV6Cpq3nivXYD7jauhvNGtpRccFZyGIiKqr7r+/hZ9HxlHR0fs2bOnVpHZs2cPHB0dAQAGg8H0NZEtEAQBEf7uiPB3x+Q+rVFarkfSxevYefYKdp/Nw/FMDU5mVb4+3nkeSgcZerSqnIbqHeaDCH83yGSchiIiMjfRRWbatGmYMmUKkpKS0K1bNwCVa2RWrVplekTBr7/+ik6dOpk1KFFT4qiQIy608somDAHytDr8eWMaavfZPGRrSk1TUot/PgVvVyXibpSa3mHe8HNn0SciMod6XX69fv16fPDBBzh9+jQAIDw8HNOmTcOjjz4KACgpKTFdxSQ1Ti1RYzMajUjN1d4oMlew7/w1lJTraxzT1s8VvUJ90LutN3q08oKzUvR/UxAR2TTeR+YGFhmSmq5Cj+SL+didWjkNdTSjANX/rVPKZegS4mEarWkfqOY0FBHZPYsXmbKyMuTm5sJgqLngsUWLFvU5ncWwyFBTc72oDHvOXTU9RiEjv6TGfk9nBVp5u8DDWQkPZwU8nCr/9HRWQO2shIeTAp439qmdFXBTOfAycCKyORYrMmfPnsXEiROxZ8+eGtuNRiMEQYBer7/NJ6XBIkNNmdFoRFpeEXan5mHnmTzsO38VWl2FqHPIZQI8nCpLjeeNolP9aw9nRa1S5OGsgCsLEBE1YRa7amn8+PFwcHDA1q1bERAQwP8jJGoAQRDQ2scVrX1cMS62Jcr1BvyVUYAcTSnyi8uRX1KO68VlKCguR37xja9Lbn6tqzBAbzDialEZrhaVASiq8/d2kAmVozrVR3iclPC8UXTUzje+rlZ+PJyVcFHK+e89ETUZootMSkoKkpKSEBERYYk8RHZNIZehcwvPOh9fWq43lZr84nIUlJTh+o3Sk19ShvyiG39W23a9uBxlFQZUGIzI05YhTyuuACnkAtRV5cap+miPAp4uSqhvjAJ5Oivh5ugAZ6UDXFRyuKgc4KJ0gJzrf4jIjEQXmcjISOTl5VkiCxGJ5KiQw18th79a3BWCpeV6U/mpfJUhv6Ta19VKT8HfClC53og8ra7WnY7rnlkGF6UDXFQOcFbeKDgqB7hUfa2Uw1nlANfq+6uVIWel/Ma+ymMcFTKOEBHZMdFFZsmSJXjuueewaNEiREdHQ6FQ1NjPdShETZ+jQo4AtRMC1E51/ozRaERpuaGy1NwY6Sm4zfRXZSkqg7a0AkVlehTpKlBhqFyOV1puQGl51VRYw8kEwEXpAGeVvEZBclU5wPlvBcnlxjZXlbxypKj6aFG1YxRymVmyEZHliV7sK5NV/gv+9/8C4mJfIroTXYUexTo9tLoKFJdV/VmBIl1l0Skuq4BWp7/xZwWKdXoUlVWgSHezDJk+d2ObpSjlsmrFSA4nhRwKuQxKB5npT6XpvVB7u1wGhcPNP1V/+2zVZ5S3PWe14+QccSL7ZLHFvtu3b29QMCKyTyoHOVQOcni6KM1yPoPBiJLyqrJTWXSqyo6pAFVtL6v6828F6W9lqezG87PK9AaUFRuQX1xulqwNpZTfpjDVKkdyKKsfV61QVR0jl8ngIBMglwk1/5Tf3C4XBDjIqx9zi8/c5lxy03tZtXNX/14yyITa/zFMVF+ii0zfvn0tkYOISBSZTDBNCcHNPOcs1xtuORJUWq5Hud4A3Y01QpVrhQwoqzBUlp5q78v1VduMKNMbUF7tmFseW2FAmd6Isgp95bn1lVeiVVemN6BMD4uOQjW22sVIBpnw96J06yIlkwmQCYBMECATBAimr3HjfbX9Mtx4X7lNwJ2OqeM5hZrnlMkqjxdQ/Xj8bX/tz9/MAtPxwC32VW2rkR+m7ync6nwAUJUFN38+4cYOoca+6t/7xs8hu3lu2W0+c/N7A57Oysp/FyVQr++6a9cufPTRRzh//jy++eYbNG/eHOvWrUOrVq3Qq1cvc2ckImoUCrkMamcZ1M6Kux9sQXqDsVohqll8qpepmtv+XqQMN4qUEWV6vekzBqMRFQYj9PobfxoMN/40/u1PAyr0xpvHG4yo0FftN9zieCMq9LW3307Fjf31WzJOTc2iUdF4tIc0N8QVXWQ2bdqEf//73xg7diySk5Oh01X+z7CgoACLFi3CTz/9ZPaQRET2pHJ6Rg5HhVzqKA1mqFFsblGA9LW362/3Gf3N7UYYYTBWrs80GI0wGACD0QijsfJPg7Hq/c2vqx9fedydj7m5v/LnqMvxxtt9vsYxtfcBMH1tNML08+HG16Z9uPk9TF+j8uevfH/z85V/3jh/ta9r7K92rpv7qp/nZl7jbb6/wWiEg4S3VRBdZBYuXIiVK1di3Lhx2Lhxo2l7XFwcFi5caNZwRERk3WQyAUrTLznrL2bU9Ii+xvD06dPo06dPre1qtRr5+fnmyERERERUJ6KLjL+/P1JTU2tt3717N1q3bm2WUERERER1IbrITJ48GdOnT8f+/fshCAIyMzOxfv16zJ49G0899ZQlMhIRERHdkug1MnPmzIHBYED//v1RXFyMPn36QKVSYfbs2Zg2bZolMhIRERHdkug7+1YpKytDamoqtFotIiMj4erqau5sZsE7+xIREVkfi93Zt4pSqURkZGR9P05ERETUYHwyGhEREVktFhkiIiKyWlZRZJYvX46WLVvC0dERPXr0wIEDB6SORERERE1Aky8yX331FWbOnIn58+cjOTkZHTt2xKBBg5Cbmyt1NCIiIpJYva9aaiw9evRAt27d8MEHHwAADAYDgoODMW3aNMyZM6fW8TqdzvT8J6By1XNwcDCvWiIiIrIidb1qqUmPyJSVlSEpKQkDBgwwbZPJZBgwYAD27t17y88sXrwYarXa9AoODm6suERERNTImnSRycvLg16vh5+fX43tfn5+yM7OvuVn5s6di4KCAtMrPT29MaISERGRBOp9H5mmSqVSQaVSSR2DiIiIGkGTLjLe3t6Qy+XIycmpsT0nJwf+/v51OkfVEiCNRmP2fERERGQZVb+377aUt0kXGaVSia5duyIhIQEjR44EULnYNyEhAVOnTq3TOQoLCwGAa2WIiIisUGFhIdRq9W33N+kiAwAzZ87E448/jpiYGHTv3h3Lli1DUVERJkyYUKfPBwYGIj09HW5ubhAEwWy5qq6GSk9P59VQTQT/TpoW/n00Lfz7aFr493F3RqMRhYWFCAwMvONxTb7IPPzww7hy5QpeeuklZGdno1OnTvjll19qLQC+HZlMhqCgIIvlc3d35/8Imxj+nTQt/PtoWvj30bTw7+PO7jQSU6XJFxkAmDp1ap2nkoiIiMh+NOnLr4mIiIjuhEWmnlQqFebPn89LvZsQ/p00Lfz7aFr499G08O/DfJr8IwqIiIiIbocjMkRERGS1WGSIiIjIarHIEBERkdVikSEiIiKrxSJTT8uXL0fLli3h6OiIHj164MCBA1JHskuLFy9Gt27d4ObmBl9fX4wcORKnT5+WOhbd8Prrr0MQBDzzzDNSR7FrGRkZeOyxx9CsWTM4OTkhOjoahw4dkjqWXdLr9XjxxRfRqlUrODk5oU2bNnj11Vfv+jwhuj0WmXr46quvMHPmTMyfPx/Jycno2LEjBg0ahNzcXKmj2Z3ExETEx8dj37592LZtG8rLyzFw4EAUFRVJHc3uHTx4EB999BE6dOggdRS7dv36dcTFxUGhUODnn3/GiRMn8Pbbb8PT01PqaHZpyZIlWLFiBT744AOcPHkSS5YswRtvvIH3339f6mhWi5df10OPHj3QrVs3fPDBBwAqH2QZHByMadOmYc6cORKns29XrlyBr68vEhMT0adPH6nj2C2tVosuXbrgww8/xMKFC9GpUycsW7ZM6lh2ac6cOfjzzz+xa9cuqaMQgH/84x/w8/PD6tWrTdtGjx4NJycnfPHFFxIms14ckRGprKwMSUlJGDBggGmbTCbDgAEDsHfvXgmTEQAUFBQAALy8vCROYt/i4+PxwAMP1Pj3hKTxww8/ICYmBv/617/g6+uLzp0745NPPpE6lt3q2bMnEhIScObMGQDAkSNHsHv3bgwZMkTiZNbLKp611JTk5eVBr9fXemiln58fTp06JVEqAipHxp555hnExcWhffv2UsexWxs3bkRycjIOHjwodRQCcP78eaxYsQIzZ87ECy+8gIMHD+Lpp5+GUqnE448/LnU8uzNnzhxoNBpERERALpdDr9fjtddew9ixY6WOZrVYZMhmxMfH46+//sLu3buljmK30tPTMX36dGzbtg2Ojo5SxyFUFvyYmBgsWrQIANC5c2f89ddfWLlyJYuMBL7++musX78eGzZsQFRUFFJSUvDMM88gMDCQfx/1xCIjkre3N+RyOXJycmpsz8nJgb+/v0SpaOrUqdi6dSt27tyJoKAgqePYraSkJOTm5qJLly6mbXq9Hjt37sQHH3wAnU4HuVwuYUL7ExAQgMjIyBrb2rVrh02bNkmUyL49++yzmDNnDh555BEAQHR0NC5evIjFixezyNQT18iIpFQq0bVrVyQkJJi2GQwGJCQkIDY2VsJk9sloNGLq1KnYsmUL/vjjD7Rq1UrqSHatf//+OHbsGFJSUkyvmJgYjB07FikpKSwxEoiLi6t1S4IzZ84gJCREokT2rbi4GDJZzV+9crkcBoNBokTWjyMy9TBz5kw8/vjjiImJQffu3bFs2TIUFRVhwoQJUkezO/Hx8diwYQO+//57uLm5ITs7GwCgVqvh5OQkcTr74+bmVmt9kouLC5o1a8Z1SxKZMWMGevbsiUWLFuGhhx7CgQMH8PHHH+Pjjz+WOppdGjZsGF577TW0aNECUVFROHz4MJYuXYqJEydKHc16Gale3n//fWOLFi2MSqXS2L17d+O+ffukjmSXANzytWbNGqmj0Q19+/Y1Tp8+XeoYdu3HH380tm/f3qhSqYwRERHGjz/+WOpIdkuj0RinT59ubNGihdHR0dHYunVr43//+1+jTqeTOprV4n1kiIiIyGpxjQwRERFZLRYZIiIislosMkRERGS1WGSIiIjIarHIEBERkdVikSEiIiKrxSJDREREVotFhoiIiKwWiwwRERFZLRYZImryxo8fj5EjR0odg4iaIBYZIiIislosMkTUZHz77beIjo6Gk5MTmjVrhgEDBuDZZ5/FZ599hu+//x6CIEAQBOzYsQMAkJ6ejoceeggeHh7w8vLCiBEjcOHCBdP5qkZyFixYAB8fH7i7u2PKlCkoKyuT5gckIrNzkDoAEREAZGVlYcyYMXjjjTcwatQoFBYWYteuXRg3bhwuXboEjUaDNWvWAAC8vLxQXl6OQYMGITY2Frt27YKDgwMWLlyIwYMH4+jRo1AqlQCAhIQEODo6YseOHbhw4QImTJiAZs2a4bXXXpPyxyUiM2GRIaImISsrCxUVFXjwwQcREhICAIiOjgYAODk5QafTwd/f33T8F198AYPBgFWrVkEQBADAmjVr4OHhgR07dmDgwIEAAKVSiU8//RTOzs6IiorCK6+8gmeffRavvvoqZDIOShNZO/5bTERNQseOHdG/f39ER0fjX//6Fz755BNcv379tscfOXIEqampcHNzg6urK1xdXeHl5YXS0lKcO3euxnmdnZ1N72NjY6HVapGenm7Rn4eIGgdHZIioSZDL5di2bRv27NmD3377De+//z7++9//Yv/+/bc8XqvVomvXrli/fn2tfT4+PpaOS0RNBIsMETUZgiAgLi4OcXFxeOmllxASEoItW7ZAqVRCr9fXOLZLly746quv4OvrC3d399ue88iRIygpKYGTkxMAYN++fXB1dUVwcLBFfxYiahycWiKiJmH//v1YtGgRDh06hEuXLmHz5s24cuUK2rVrh5YtW+Lo0aM4ffo08vLyUF5ejrFjx8Lb2xsjRozArl27kJaWhh07duDpp5/G5cuXTectKyvDpEmTcOLECfz000+YP38+pk6dyvUxRDaCIzJE1CS4u7tj586dWLZsGTQaDUJCQvD2229jyJAhiImJwY4dOxATEwOtVovt27fj3nvvxc6dO/H888/jwQcfRGFhIZo3b47+/fvXGKHp378/wsLC0KdPH+h0OowZMwYvv/yydD8oEZmVYDQajVKHICKyhPHjxyM/Px/fffed1FGIyEI4tkpERERWi0WGiIiIrBanloiIiMhqcUSGiIiIrBaLDBEREVktFhkiIiKyWiwyREREZLVYZIiIiMhqscgQERGR1WKRISIiIqvFIkNERERW6/8BXtgl9LvHepgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rewards)\n",
    "plt.ylabel('engagement per step for maximum greedy policy')\n",
    "plt.xlabel('step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can note a couple of things here already:\n",
    "\n",
    "1. The imediate engagement would be high initially when the sweetest item is suggested for the first time.\n",
    "2. As we keep recommending the sweetest items, the user satisfaction significantly tampers off and as a result engagement quickly drops.\n",
    "3. Episodes seem to last for 10 timesteps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise (2 min):\n",
    "Instead of picking the item with the highest feature, pick the item with the lowest feature and see what happens?\n",
    "\n",
    "- What do your observations imply about this environment?\n",
    "- What policy maximizes engagement with the user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "rewards = []\n",
    "done = False\n",
    "while not done:\n",
    "    # TODO (exercise): code here\n",
    "    action = int(min(obs[\"doc\"], key=lambda x: obs[\"doc\"][x]))\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    rewards.append(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'step')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rewards)\n",
    "plt.ylabel('engagement per step for minimum greedy policy')\n",
    "plt.xlabel('step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting some baseline policies\n",
    "Next we will run some simple baselines to get a feeling of the reward we can accumulate in these enviornements using simple policies.\n",
    "\n",
    "- Greedy minimum feature value (recommending the kaliest option)\n",
    "- Greedy maximum feature value (recommending the chocoletiest option)\n",
    "- random policy (recommending random items from the pool)\n",
    "- even argmin (recommmending alternations between argmax and argmin to keep the engagement high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that measures and outputs the random baseline reward.\n",
    "# This computes  the expected accumulated reward per episode, if we act randomly (recommend random items) at each time step.\n",
    "def calc_baseline(baseline_type=\"random\",\n",
    "                  episodes=100):\n",
    "\n",
    "    env_config = {\n",
    "        # The number of possible documents/videos/candidates that we can recommend\n",
    "        # no flattening necessary (see `convert_to_discrete_action_space=False` below)\n",
    "        \"num_candidates\": num_candidates,  \n",
    "        # The number of recommendations that we will be making\n",
    "        \"slate_size\": 1, \n",
    "        # Set to False for re-using the same candidate documents each timestep.\n",
    "        \"resample_documents\": True,\n",
    "        # Use consistent seeds for the environment ...\n",
    "        \"seed\": seed,\n",
    "        # scale rewards with this factor\n",
    "        \"reward_scale\": reward_scale,\n",
    "    }\n",
    "\n",
    "    env = ModifiedLongTermSatisfactionRecSimEnv(env_config)\n",
    "    # Reset the env.\n",
    "    obs = env.reset()\n",
    "\n",
    "    # Number of episodes already done.\n",
    "    num_episodes = 0\n",
    "    # Current episode's accumulated reward.\n",
    "    episode_reward = 0.0\n",
    "    epsiode_satisfaction = []\n",
    "    # Collect all episode rewards here to be able to calculate a random baseline reward.\n",
    "    episode_rewards = []\n",
    "    episode_satisfactions = []\n",
    "    \n",
    "    # Enter while loop (to step through the episode).\n",
    "    time_step = 0\n",
    "    while num_episodes < episodes:\n",
    "        # Produce an action\n",
    "        # TODO: code here\n",
    "        random_action = env.action_space.sample()\n",
    "        argmax_action = int(max(obs['doc'], key=lambda x: obs['doc'][x]))\n",
    "        argmin_action = int(min(obs['doc'], key=lambda x: obs['doc'][x]))\n",
    "\n",
    "        action_dict = {\n",
    "            'argmax': argmax_action, # greedy choc\n",
    "            'argmin': argmin_action, # greedy kale\n",
    "            'random': random_action,\n",
    "        }\n",
    "        # a baseline that performs argmax in even time steps and argmin in odd time steps\n",
    "        action_dict[\"even_argmin\"] = (\n",
    "            action_dict[\"argmin\"] if time_step % 2 == 0 else action_dict[\"argmax\"]\n",
    "        )\n",
    "        action = action_dict[baseline_type]\n",
    "        \n",
    "        # Send the action to the env's `step()` method to receive: obs, reward, done, and info.\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # Accumulate the rewards\n",
    "        episode_reward += reward\n",
    "        \n",
    "        # Append satisfaction to episode_satiscation\n",
    "        epsiode_satisfaction.append(\n",
    "            env.environment._user_model._user_state.satisfaction\n",
    "        )\n",
    "\n",
    "        time_step += 1\n",
    "        # Check, whether the episde is done, if yes, reset and increase episode counter.\n",
    "        if done:\n",
    "            if num_episodes % 99 == 0:\n",
    "                print(f\" {num_episodes} \", end=\"\")\n",
    "            elif num_episodes % 9 == 0:\n",
    "                print(\".\", end=\"\")\n",
    "                \n",
    "            # increment on end of episode\n",
    "            num_episodes += 1\n",
    "            time_step = 0\n",
    "            obs = env.reset()\n",
    "            episode_rewards.append(episode_reward)\n",
    "            episode_reward = 0.0\n",
    "            episode_satisfactions.append(np.mean(epsiode_satisfaction))\n",
    "\n",
    "    # Print out and return mean episode reward (and standard error of the mean).\n",
    "    env_mean_reward = np.mean(episode_rewards)\n",
    "    env_sd_reward = np.std(episode_rewards)\n",
    "\n",
    "    # Print out the satisfaction over the episodes\n",
    "    env_mean_satisfaction = np.mean(episode_satisfactions)\n",
    "    env_sd_satisfaction = np.std(episode_satisfactions)\n",
    "    \n",
    "    print(f\"\\nMean {baseline_type} baseline reward: {env_mean_reward:.2f}+/-{env_sd_reward:.2f}, satisfaction: {env_mean_satisfaction:.2f}+/-{env_sd_satisfaction:.2f}\")\n",
    "\n",
    "    return env_mean_reward, episode_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 .......... 99 .......... 198 .......... 297 .......... 396 .......... 495 .......... 594 .......... 693 .......... 792 .......... 891 .......... 990 .\n",
      "Mean argmin baseline reward: 10.87+/-0.26, satisfaction: 0.91+/-0.00\n",
      " 0 .......... 99 .......... 198 .......... 297 .......... 396 .......... 495 .......... 594 .......... 693 .......... 792 .......... 891 .......... 990 .\n",
      "Mean argmax baseline reward: 56.56+/-1.37, satisfaction: 0.14+/-0.00\n",
      " 0 .......... 99 .......... 198 .......... 297 .......... 396 .......... 495 .......... 594 .......... 693 .......... 792 .......... 891 .......... 990 .\n",
      "Mean random baseline reward: 99.77+/-23.61, satisfaction: 0.55+/-0.01\n",
      " 0 .......... 99 .......... 198 .......... 297 .......... 396 .......... 495 .......... 594 .......... 693 .......... 792 .......... 891 .......... 990 .\n",
      "Mean even_argmin baseline reward: 172.15+/-4.59, satisfaction: 0.57+/-0.00\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 1000\n",
    "kaliest_baseline, _ = calc_baseline(baseline_type=\"argmin\", episodes=num_episodes)\n",
    "sweetest_baseline,  _ = calc_baseline(baseline_type=\"argmax\", episodes=num_episodes)\n",
    "random_baseline, _ = calc_baseline(baseline_type=\"random\", episodes=num_episodes)\n",
    "even_margin_baseline, _ = calc_baseline(baseline_type=\"even_argmin\", episodes=num_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion about the baselines\n",
    "\n",
    "For every baseline we have printed out not only the engagement score of the entire user session but also the average of the satisfaction term over the entire session as well.\n",
    "- **Random policy beats greedy options**\n",
    "- **Alternation between argmax and argmin beats random**\n",
    "\n",
    "The question is whether we automatically learn an optimal policy in this recommendation enviornement?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions (2 min)\n",
    "\n",
    "- Any questions so far?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a contextual bandit on the environement <a class=\"anchor\" id=\"bandits\"></a>\n",
    "\n",
    "Bandit is a classical algorithm used in RecSys that is known to optimize single-step objectives. **They maximize immediate engagement not accumulated engagement over the user session.**\n",
    "\n",
    "Any RL algorithm can be turned into a contextual bandit algorithm if the discount factor of the Markov Decision Process is set to 0.0. This will result in maximizing the immediate reward and hence a bandit solution. \n",
    "\n",
    "In this section, we will use [DQN](https://docs.ray.io/en/latest/rllib/rllib-algorithms.html#dqn) to train an agent both with $\\gamma = 0$ and $\\gamma = 0.99$ to see the difference between a bandit solution and an RL solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the config below we set a few settings:\n",
    "- For the environement, we specify 20 candidates that are randomly re-sampled at each time-step.\n",
    "- We use the torch implementation of the algorithm in RLlib\n",
    "- For evaluation, we rollout 100 complete episodes at the end of each training iteration and compute the average of un-discounted reward over the episode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tune to register the environment\n",
    "tune.register_env(\"modified-lts\", \n",
    "    lambda config: ModifiedLongTermSatisfactionRecSimEnv(config)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.dqn import DQNConfig, DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the environment config\n",
    "env_config = {\n",
    "    \"num_candidates\": num_candidates,  \n",
    "    \"slate_size\": 1, \n",
    "    \"resample_documents\": True,\n",
    "    \"seed\": seed,\n",
    "    \"reward_scale\": reward_scale\n",
    "}\n",
    "\n",
    "bandit_config = DQNConfig()\n",
    "# setup the env\n",
    "bandit_config = bandit_config.environment(env=\"modified-lts\", env_config=env_config)\n",
    "# setup framework to be torch\n",
    "bandit_config = bandit_config.framework(\"torch\")\n",
    "# setup the gamma\n",
    "bandit_config = bandit_config.training(gamma=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_disable_action_flattening': False,\n",
      " '_disable_execution_plan_api': True,\n",
      " '_disable_preprocessor_api': False,\n",
      " '_fake_gpus': False,\n",
      " '_tf_policy_handles_more_than_one_loss': False,\n",
      " 'action_space': None,\n",
      " 'actions_in_input_normalized': False,\n",
      " 'adam_epsilon': 1e-08,\n",
      " 'always_attach_evaluation_results': False,\n",
      " 'batch_mode': 'truncate_episodes',\n",
      " 'before_learn_on_batch': None,\n",
      " 'buffer_size': -1,\n",
      " 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
      " 'clip_actions': False,\n",
      " 'clip_rewards': None,\n",
      " 'collect_metrics_timeout': -1,\n",
      " 'compress_observations': False,\n",
      " 'create_env_on_driver': False,\n",
      " 'custom_eval_function': None,\n",
      " 'custom_resources_per_worker': {},\n",
      " 'disable_env_checking': False,\n",
      " 'double_q': True,\n",
      " 'dueling': True,\n",
      " 'eager_max_retraces': 20,\n",
      " 'eager_tracing': False,\n",
      " 'enable_connectors': False,\n",
      " 'enable_tf1_exec_eagerly': False,\n",
      " 'env': 'modified-lts',\n",
      " 'env_config': {'num_candidates': 20,\n",
      "                'resample_documents': True,\n",
      "                'reward_scale': 1.0,\n",
      "                'seed': 100,\n",
      "                'slate_size': 1},\n",
      " 'env_task_fn': None,\n",
      " 'evaluation_config': {'explore': False},\n",
      " 'evaluation_duration': 10,\n",
      " 'evaluation_duration_unit': 'episodes',\n",
      " 'evaluation_interval': None,\n",
      " 'evaluation_num_episodes': -1,\n",
      " 'evaluation_num_workers': 0,\n",
      " 'evaluation_parallel_to_training': False,\n",
      " 'evaluation_sample_timeout_s': 180.0,\n",
      " 'exploration_config': {'epsilon_timesteps': 10000,\n",
      "                        'final_epsilon': 0.02,\n",
      "                        'initial_epsilon': 1.0,\n",
      "                        'type': 'EpsilonGreedy'},\n",
      " 'explore': True,\n",
      " 'extra_python_environs_for_driver': {},\n",
      " 'extra_python_environs_for_worker': {},\n",
      " 'fake_sampler': False,\n",
      " 'framework': 'torch',\n",
      " 'gamma': 0.0,\n",
      " 'grad_clip': 40,\n",
      " 'hiddens': [256],\n",
      " 'horizon': None,\n",
      " 'ignore_worker_failures': False,\n",
      " 'in_evaluation': False,\n",
      " 'input': 'sampler',\n",
      " 'input_config': {},\n",
      " 'input_evaluation': -1,\n",
      " 'keep_per_episode_custom_metrics': False,\n",
      " 'learning_starts': -1,\n",
      " 'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                           'intra_op_parallelism_threads': 8},\n",
      " 'log_level': 'WARN',\n",
      " 'log_sys_usage': True,\n",
      " 'logger_config': None,\n",
      " 'logger_creator': None,\n",
      " 'lr': 0.0005,\n",
      " 'lr_schedule': None,\n",
      " 'metrics_episode_collection_timeout_s': 60.0,\n",
      " 'metrics_num_episodes_for_smoothing': 100,\n",
      " 'metrics_smoothing_episodes': -1,\n",
      " 'min_iter_time_s': -1,\n",
      " 'min_sample_timesteps_per_iteration': 1000,\n",
      " 'min_sample_timesteps_per_reporting': -1,\n",
      " 'min_time_s_per_iteration': 1,\n",
      " 'min_time_s_per_reporting': -1,\n",
      " 'min_train_timesteps_per_iteration': 0,\n",
      " 'min_train_timesteps_per_reporting': -1,\n",
      " 'model': {'_disable_action_flattening': False,\n",
      "           '_disable_preprocessor_api': False,\n",
      "           '_time_major': False,\n",
      "           '_use_default_native_models': False,\n",
      "           'attention_dim': 64,\n",
      "           'attention_head_dim': 32,\n",
      "           'attention_init_gru_gate_bias': 2.0,\n",
      "           'attention_memory_inference': 50,\n",
      "           'attention_memory_training': 50,\n",
      "           'attention_num_heads': 1,\n",
      "           'attention_num_transformer_units': 1,\n",
      "           'attention_position_wise_mlp_dim': 32,\n",
      "           'attention_use_n_prev_actions': 0,\n",
      "           'attention_use_n_prev_rewards': 0,\n",
      "           'conv_activation': 'relu',\n",
      "           'conv_filters': None,\n",
      "           'custom_action_dist': None,\n",
      "           'custom_model': None,\n",
      "           'custom_model_config': {},\n",
      "           'custom_preprocessor': None,\n",
      "           'dim': 84,\n",
      "           'fcnet_activation': 'tanh',\n",
      "           'fcnet_hiddens': [256, 256],\n",
      "           'framestack': True,\n",
      "           'free_log_std': False,\n",
      "           'grayscale': False,\n",
      "           'lstm_cell_size': 256,\n",
      "           'lstm_use_prev_action': False,\n",
      "           'lstm_use_prev_action_reward': -1,\n",
      "           'lstm_use_prev_reward': False,\n",
      "           'max_seq_len': 20,\n",
      "           'no_final_linear': False,\n",
      "           'post_fcnet_activation': 'relu',\n",
      "           'post_fcnet_hiddens': [],\n",
      "           'use_attention': False,\n",
      "           'use_lstm': False,\n",
      "           'vf_share_layers': True,\n",
      "           'zero_mean': True},\n",
      " 'monitor': -1,\n",
      " 'multiagent': {'count_steps_by': 'env_steps',\n",
      "                'observation_fn': None,\n",
      "                'policies': {},\n",
      "                'policies_to_train': None,\n",
      "                'policy_map_cache': None,\n",
      "                'policy_map_capacity': 100,\n",
      "                'policy_mapping_fn': None,\n",
      "                'replay_mode': 'independent'},\n",
      " 'n_step': 1,\n",
      " 'no_done_at_end': False,\n",
      " 'noisy': False,\n",
      " 'normalize_actions': True,\n",
      " 'num_atoms': 1,\n",
      " 'num_consecutive_worker_failures_tolerance': 100,\n",
      " 'num_cpus_for_driver': 1,\n",
      " 'num_cpus_per_worker': 1,\n",
      " 'num_envs_per_worker': 1,\n",
      " 'num_gpus': 0,\n",
      " 'num_gpus_per_worker': 0,\n",
      " 'num_workers': 0,\n",
      " 'observation_filter': 'NoFilter',\n",
      " 'observation_space': None,\n",
      " 'off_policy_estimation_methods': {},\n",
      " 'optimizer': {},\n",
      " 'output': None,\n",
      " 'output_compress_columns': ['obs', 'new_obs'],\n",
      " 'output_config': {},\n",
      " 'output_max_file_size': 67108864,\n",
      " 'placement_strategy': 'PACK',\n",
      " 'postprocess_inputs': False,\n",
      " 'preprocessor_pref': 'deepmind',\n",
      " 'prioritized_replay': -1,\n",
      " 'prioritized_replay_alpha': -1,\n",
      " 'prioritized_replay_beta': -1,\n",
      " 'prioritized_replay_eps': -1,\n",
      " 'recreate_failed_workers': False,\n",
      " 'remote_env_batch_wait_ms': 0,\n",
      " 'remote_worker_envs': False,\n",
      " 'render_env': False,\n",
      " 'replay_batch_size': -1,\n",
      " 'replay_buffer_config': {'capacity': 50000,\n",
      "                          'prioritized_replay': -1,\n",
      "                          'prioritized_replay_alpha': 0.6,\n",
      "                          'prioritized_replay_beta': 0.4,\n",
      "                          'prioritized_replay_eps': 1e-06,\n",
      "                          'replay_sequence_length': 1,\n",
      "                          'type': 'MultiAgentPrioritizedReplayBuffer',\n",
      "                          'worker_side_prioritization': False},\n",
      " 'replay_sequence_length': None,\n",
      " 'restart_failed_sub_environments': False,\n",
      " 'rollout_fragment_length': 4,\n",
      " 'sample_async': False,\n",
      " 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      " 'sampler_perf_stats_ema_coef': None,\n",
      " 'seed': None,\n",
      " 'shuffle_buffer_size': 0,\n",
      " 'sigma0': 0.5,\n",
      " 'simple_optimizer': -1,\n",
      " 'soft_horizon': False,\n",
      " 'store_buffer_in_checkpoints': False,\n",
      " 'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
      " 'synchronize_filters': True,\n",
      " 'target_network_update_freq': 500,\n",
      " 'tf_session_args': {'allow_soft_placement': True,\n",
      "                     'device_count': {'CPU': 1},\n",
      "                     'gpu_options': {'allow_growth': True},\n",
      "                     'inter_op_parallelism_threads': 2,\n",
      "                     'intra_op_parallelism_threads': 2,\n",
      "                     'log_device_placement': False},\n",
      " 'timesteps_per_iteration': -1,\n",
      " 'train_batch_size': 32,\n",
      " 'training_intensity': None,\n",
      " 'v_max': 10.0,\n",
      " 'v_min': -10.0,\n",
      " 'validate_workers_after_construction': True}\n"
     ]
    }
   ],
   "source": [
    "pprint(bandit_config.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In RLlib we can run training loops in two ways:\n",
    "1. Ad-hoc for-loop via calling algo.train()\n",
    "2. Using `tune.Tuner()` with stopping condition (recommended)\n",
    "\n",
    "The code below shows the differences. Moving forward (and in all scripts) we use the later option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/_private/ray_option_utils.py:266: DeprecationWarning: Setting 'object_store_memory' for actors is deprecated since it doesn't actually reserve the required object store memory. Use object spilling that's enabled by default (https://docs.ray.io/en/releases-2.0.0/ray-core/objects/object-spilling.html) instead to bypass the object store memory size limitation.\n",
      "  warnings.warn(\n",
      "2022-09-14 13:51:20,605\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n",
      "2022-09-14 13:51:20,628\tWARNING deprecation.py:47 -- DeprecationWarning: `ReplayBuffer.add_batch()` has been deprecated. Use `ReplayBuffer.add()` instead. This will raise an error in the future!\n",
      "2022-09-14 13:51:20,637\tWARNING multi_agent_prioritized_replay_buffer.py:220 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n",
      "2022-09-14 13:51:22,533\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "# Ad-hoc for-loop\n",
    "# TODO: Code here\n",
    "num_iterations = 1\n",
    "algo = bandit_config.build()\n",
    "for iter_step in range(num_iterations):\n",
    "    results_bandit = algo.train()\n",
    "algo.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['custom_metrics', 'episode_media', 'num_recreated_workers', 'info', 'sampler_results', 'episode_reward_max', 'episode_reward_min', 'episode_reward_mean', 'episode_len_mean', 'episodes_this_iter', 'policy_reward_min', 'policy_reward_max', 'policy_reward_mean', 'hist_stats', 'sampler_perf', 'num_faulty_episodes', 'num_healthy_workers', 'num_agent_steps_sampled', 'num_agent_steps_trained', 'num_env_steps_sampled', 'num_env_steps_trained', 'num_env_steps_sampled_this_iter', 'num_env_steps_trained_this_iter', 'timesteps_total', 'num_steps_trained_this_iter', 'agent_timesteps_total', 'timers', 'counters', 'done', 'episodes_total', 'training_iteration', 'trial_id', 'experiment_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'timesteps_since_restore', 'iterations_since_restore', 'warmup_time', 'perf'])\n",
      "{'agent_timesteps_total': 1000,\n",
      " 'config': {'_disable_action_flattening': False,\n",
      "            '_disable_execution_plan_api': True,\n",
      "            '_disable_preprocessor_api': False,\n",
      "            '_fake_gpus': False,\n",
      "            '_tf_policy_handles_more_than_one_loss': False,\n",
      "            'action_space': None,\n",
      "            'actions_in_input_normalized': False,\n",
      "            'adam_epsilon': 1e-08,\n",
      "            'always_attach_evaluation_results': False,\n",
      "            'batch_mode': 'truncate_episodes',\n",
      "            'before_learn_on_batch': None,\n",
      "            'buffer_size': -1,\n",
      "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
      "            'clip_actions': False,\n",
      "            'clip_rewards': None,\n",
      "            'collect_metrics_timeout': -1,\n",
      "            'compress_observations': False,\n",
      "            'create_env_on_driver': False,\n",
      "            'custom_eval_function': None,\n",
      "            'custom_resources_per_worker': {},\n",
      "            'disable_env_checking': False,\n",
      "            'double_q': True,\n",
      "            'dueling': True,\n",
      "            'eager_max_retraces': 20,\n",
      "            'eager_tracing': False,\n",
      "            'enable_connectors': False,\n",
      "            'enable_tf1_exec_eagerly': False,\n",
      "            'env': 'modified-lts',\n",
      "            'env_config': {'num_candidates': 20,\n",
      "                           'resample_documents': True,\n",
      "                           'reward_scale': 1.0,\n",
      "                           'seed': 100,\n",
      "                           'slate_size': 1},\n",
      "            'env_task_fn': None,\n",
      "            'evaluation_config': {'_disable_action_flattening': False,\n",
      "                                  '_disable_execution_plan_api': True,\n",
      "                                  '_disable_preprocessor_api': False,\n",
      "                                  '_fake_gpus': False,\n",
      "                                  '_tf_policy_handles_more_than_one_loss': False,\n",
      "                                  'action_space': None,\n",
      "                                  'actions_in_input_normalized': False,\n",
      "                                  'adam_epsilon': 1e-08,\n",
      "                                  'always_attach_evaluation_results': False,\n",
      "                                  'batch_mode': 'truncate_episodes',\n",
      "                                  'before_learn_on_batch': None,\n",
      "                                  'buffer_size': -1,\n",
      "                                  'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
      "                                  'clip_actions': False,\n",
      "                                  'clip_rewards': None,\n",
      "                                  'collect_metrics_timeout': -1,\n",
      "                                  'compress_observations': False,\n",
      "                                  'create_env_on_driver': False,\n",
      "                                  'custom_eval_function': None,\n",
      "                                  'custom_resources_per_worker': {},\n",
      "                                  'disable_env_checking': False,\n",
      "                                  'double_q': True,\n",
      "                                  'dueling': True,\n",
      "                                  'eager_max_retraces': 20,\n",
      "                                  'eager_tracing': False,\n",
      "                                  'enable_connectors': False,\n",
      "                                  'enable_tf1_exec_eagerly': False,\n",
      "                                  'env': 'modified-lts',\n",
      "                                  'env_config': {'num_candidates': 20,\n",
      "                                                 'resample_documents': True,\n",
      "                                                 'reward_scale': 1.0,\n",
      "                                                 'seed': 100,\n",
      "                                                 'slate_size': 1},\n",
      "                                  'env_task_fn': None,\n",
      "                                  'evaluation_config': {'explore': False},\n",
      "                                  'evaluation_duration': 10,\n",
      "                                  'evaluation_duration_unit': 'episodes',\n",
      "                                  'evaluation_interval': None,\n",
      "                                  'evaluation_num_episodes': -1,\n",
      "                                  'evaluation_num_workers': 0,\n",
      "                                  'evaluation_parallel_to_training': False,\n",
      "                                  'evaluation_sample_timeout_s': 180.0,\n",
      "                                  'exploration_config': {'epsilon_timesteps': 10000,\n",
      "                                                         'final_epsilon': 0.02,\n",
      "                                                         'initial_epsilon': 1.0,\n",
      "                                                         'type': 'EpsilonGreedy'},\n",
      "                                  'explore': False,\n",
      "                                  'extra_python_environs_for_driver': {},\n",
      "                                  'extra_python_environs_for_worker': {},\n",
      "                                  'fake_sampler': False,\n",
      "                                  'framework': 'torch',\n",
      "                                  'gamma': 0.0,\n",
      "                                  'grad_clip': 40,\n",
      "                                  'hiddens': [256],\n",
      "                                  'horizon': None,\n",
      "                                  'ignore_worker_failures': False,\n",
      "                                  'in_evaluation': False,\n",
      "                                  'input': 'sampler',\n",
      "                                  'input_config': {},\n",
      "                                  'input_evaluation': -1,\n",
      "                                  'keep_per_episode_custom_metrics': False,\n",
      "                                  'learning_starts': -1,\n",
      "                                  'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                                                            'intra_op_parallelism_threads': 8},\n",
      "                                  'log_level': 'WARN',\n",
      "                                  'log_sys_usage': True,\n",
      "                                  'logger_config': None,\n",
      "                                  'logger_creator': None,\n",
      "                                  'lr': 0.0005,\n",
      "                                  'lr_schedule': None,\n",
      "                                  'metrics_episode_collection_timeout_s': 60.0,\n",
      "                                  'metrics_num_episodes_for_smoothing': 100,\n",
      "                                  'metrics_smoothing_episodes': -1,\n",
      "                                  'min_iter_time_s': -1,\n",
      "                                  'min_sample_timesteps_per_iteration': 1000,\n",
      "                                  'min_sample_timesteps_per_reporting': -1,\n",
      "                                  'min_time_s_per_iteration': 1,\n",
      "                                  'min_time_s_per_reporting': -1,\n",
      "                                  'min_train_timesteps_per_iteration': 0,\n",
      "                                  'min_train_timesteps_per_reporting': -1,\n",
      "                                  'model': {'_disable_action_flattening': False,\n",
      "                                            '_disable_preprocessor_api': False,\n",
      "                                            '_time_major': False,\n",
      "                                            '_use_default_native_models': False,\n",
      "                                            'attention_dim': 64,\n",
      "                                            'attention_head_dim': 32,\n",
      "                                            'attention_init_gru_gate_bias': 2.0,\n",
      "                                            'attention_memory_inference': 50,\n",
      "                                            'attention_memory_training': 50,\n",
      "                                            'attention_num_heads': 1,\n",
      "                                            'attention_num_transformer_units': 1,\n",
      "                                            'attention_position_wise_mlp_dim': 32,\n",
      "                                            'attention_use_n_prev_actions': 0,\n",
      "                                            'attention_use_n_prev_rewards': 0,\n",
      "                                            'conv_activation': 'relu',\n",
      "                                            'conv_filters': None,\n",
      "                                            'custom_action_dist': None,\n",
      "                                            'custom_model': None,\n",
      "                                            'custom_model_config': {},\n",
      "                                            'custom_preprocessor': None,\n",
      "                                            'dim': 84,\n",
      "                                            'fcnet_activation': 'tanh',\n",
      "                                            'fcnet_hiddens': [256, 256],\n",
      "                                            'framestack': True,\n",
      "                                            'free_log_std': False,\n",
      "                                            'grayscale': False,\n",
      "                                            'lstm_cell_size': 256,\n",
      "                                            'lstm_use_prev_action': False,\n",
      "                                            'lstm_use_prev_action_reward': -1,\n",
      "                                            'lstm_use_prev_reward': False,\n",
      "                                            'max_seq_len': 20,\n",
      "                                            'no_final_linear': False,\n",
      "                                            'post_fcnet_activation': 'relu',\n",
      "                                            'post_fcnet_hiddens': [],\n",
      "                                            'use_attention': False,\n",
      "                                            'use_lstm': False,\n",
      "                                            'vf_share_layers': True,\n",
      "                                            'zero_mean': True},\n",
      "                                  'monitor': -1,\n",
      "                                  'multiagent': {'count_steps_by': 'env_steps',\n",
      "                                                 'observation_fn': None,\n",
      "                                                 'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x2b2bd4220>},\n",
      "                                                 'policies_to_train': None,\n",
      "                                                 'policy_map_cache': None,\n",
      "                                                 'policy_map_capacity': 100,\n",
      "                                                 'policy_mapping_fn': None,\n",
      "                                                 'replay_mode': 'independent'},\n",
      "                                  'n_step': 1,\n",
      "                                  'no_done_at_end': False,\n",
      "                                  'noisy': False,\n",
      "                                  'normalize_actions': True,\n",
      "                                  'num_atoms': 1,\n",
      "                                  'num_consecutive_worker_failures_tolerance': 100,\n",
      "                                  'num_cpus_for_driver': 1,\n",
      "                                  'num_cpus_per_worker': 1,\n",
      "                                  'num_envs_per_worker': 1,\n",
      "                                  'num_gpus': 0,\n",
      "                                  'num_gpus_per_worker': 0,\n",
      "                                  'num_workers': 0,\n",
      "                                  'observation_filter': 'NoFilter',\n",
      "                                  'observation_space': None,\n",
      "                                  'off_policy_estimation_methods': {},\n",
      "                                  'optimizer': {},\n",
      "                                  'output': None,\n",
      "                                  'output_compress_columns': ['obs', 'new_obs'],\n",
      "                                  'output_config': {},\n",
      "                                  'output_max_file_size': 67108864,\n",
      "                                  'placement_strategy': 'PACK',\n",
      "                                  'postprocess_inputs': False,\n",
      "                                  'preprocessor_pref': 'deepmind',\n",
      "                                  'prioritized_replay': -1,\n",
      "                                  'prioritized_replay_alpha': -1,\n",
      "                                  'prioritized_replay_beta': -1,\n",
      "                                  'prioritized_replay_eps': -1,\n",
      "                                  'recreate_failed_workers': False,\n",
      "                                  'remote_env_batch_wait_ms': 0,\n",
      "                                  'remote_worker_envs': False,\n",
      "                                  'render_env': False,\n",
      "                                  'replay_batch_size': -1,\n",
      "                                  'replay_buffer_config': {'capacity': 50000,\n",
      "                                                           'prioritized_replay': -1,\n",
      "                                                           'prioritized_replay_alpha': 0.6,\n",
      "                                                           'prioritized_replay_beta': 0.4,\n",
      "                                                           'prioritized_replay_eps': 1e-06,\n",
      "                                                           'replay_mode': 'independent',\n",
      "                                                           'replay_sequence_length': 1,\n",
      "                                                           'type': <class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>,\n",
      "                                                           'worker_side_prioritization': False},\n",
      "                                  'replay_sequence_length': None,\n",
      "                                  'restart_failed_sub_environments': False,\n",
      "                                  'rollout_fragment_length': 4,\n",
      "                                  'sample_async': False,\n",
      "                                  'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      "                                  'sampler_perf_stats_ema_coef': None,\n",
      "                                  'seed': None,\n",
      "                                  'shuffle_buffer_size': 0,\n",
      "                                  'sigma0': 0.5,\n",
      "                                  'simple_optimizer': False,\n",
      "                                  'soft_horizon': False,\n",
      "                                  'store_buffer_in_checkpoints': False,\n",
      "                                  'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
      "                                  'synchronize_filters': True,\n",
      "                                  'target_network_update_freq': 500,\n",
      "                                  'tf_session_args': {'allow_soft_placement': True,\n",
      "                                                      'device_count': {'CPU': 1},\n",
      "                                                      'gpu_options': {'allow_growth': True},\n",
      "                                                      'inter_op_parallelism_threads': 2,\n",
      "                                                      'intra_op_parallelism_threads': 2,\n",
      "                                                      'log_device_placement': False},\n",
      "                                  'timesteps_per_iteration': -1,\n",
      "                                  'train_batch_size': 32,\n",
      "                                  'training_intensity': None,\n",
      "                                  'v_max': 10.0,\n",
      "                                  'v_min': -10.0,\n",
      "                                  'validate_workers_after_construction': True},\n",
      "            'evaluation_duration': 10,\n",
      "            'evaluation_duration_unit': 'episodes',\n",
      "            'evaluation_interval': None,\n",
      "            'evaluation_num_episodes': -1,\n",
      "            'evaluation_num_workers': 0,\n",
      "            'evaluation_parallel_to_training': False,\n",
      "            'evaluation_sample_timeout_s': 180.0,\n",
      "            'exploration_config': {'epsilon_timesteps': 10000,\n",
      "                                   'final_epsilon': 0.02,\n",
      "                                   'initial_epsilon': 1.0,\n",
      "                                   'type': 'EpsilonGreedy'},\n",
      "            'explore': True,\n",
      "            'extra_python_environs_for_driver': {},\n",
      "            'extra_python_environs_for_worker': {},\n",
      "            'fake_sampler': False,\n",
      "            'framework': 'torch',\n",
      "            'gamma': 0.0,\n",
      "            'grad_clip': 40,\n",
      "            'hiddens': [256],\n",
      "            'horizon': None,\n",
      "            'ignore_worker_failures': False,\n",
      "            'in_evaluation': False,\n",
      "            'input': 'sampler',\n",
      "            'input_config': {},\n",
      "            'input_evaluation': -1,\n",
      "            'keep_per_episode_custom_metrics': False,\n",
      "            'learning_starts': -1,\n",
      "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                                      'intra_op_parallelism_threads': 8},\n",
      "            'log_level': 'WARN',\n",
      "            'log_sys_usage': True,\n",
      "            'logger_config': None,\n",
      "            'logger_creator': None,\n",
      "            'lr': 0.0005,\n",
      "            'lr_schedule': None,\n",
      "            'metrics_episode_collection_timeout_s': 60.0,\n",
      "            'metrics_num_episodes_for_smoothing': 100,\n",
      "            'metrics_smoothing_episodes': -1,\n",
      "            'min_iter_time_s': -1,\n",
      "            'min_sample_timesteps_per_iteration': 1000,\n",
      "            'min_sample_timesteps_per_reporting': -1,\n",
      "            'min_time_s_per_iteration': 1,\n",
      "            'min_time_s_per_reporting': -1,\n",
      "            'min_train_timesteps_per_iteration': 0,\n",
      "            'min_train_timesteps_per_reporting': -1,\n",
      "            'model': {'_disable_action_flattening': False,\n",
      "                      '_disable_preprocessor_api': False,\n",
      "                      '_time_major': False,\n",
      "                      '_use_default_native_models': False,\n",
      "                      'attention_dim': 64,\n",
      "                      'attention_head_dim': 32,\n",
      "                      'attention_init_gru_gate_bias': 2.0,\n",
      "                      'attention_memory_inference': 50,\n",
      "                      'attention_memory_training': 50,\n",
      "                      'attention_num_heads': 1,\n",
      "                      'attention_num_transformer_units': 1,\n",
      "                      'attention_position_wise_mlp_dim': 32,\n",
      "                      'attention_use_n_prev_actions': 0,\n",
      "                      'attention_use_n_prev_rewards': 0,\n",
      "                      'conv_activation': 'relu',\n",
      "                      'conv_filters': None,\n",
      "                      'custom_action_dist': None,\n",
      "                      'custom_model': None,\n",
      "                      'custom_model_config': {},\n",
      "                      'custom_preprocessor': None,\n",
      "                      'dim': 84,\n",
      "                      'fcnet_activation': 'tanh',\n",
      "                      'fcnet_hiddens': [256, 256],\n",
      "                      'framestack': True,\n",
      "                      'free_log_std': False,\n",
      "                      'grayscale': False,\n",
      "                      'lstm_cell_size': 256,\n",
      "                      'lstm_use_prev_action': False,\n",
      "                      'lstm_use_prev_action_reward': -1,\n",
      "                      'lstm_use_prev_reward': False,\n",
      "                      'max_seq_len': 20,\n",
      "                      'no_final_linear': False,\n",
      "                      'post_fcnet_activation': 'relu',\n",
      "                      'post_fcnet_hiddens': [],\n",
      "                      'use_attention': False,\n",
      "                      'use_lstm': False,\n",
      "                      'vf_share_layers': True,\n",
      "                      'zero_mean': True},\n",
      "            'monitor': -1,\n",
      "            'multiagent': {'count_steps_by': 'env_steps',\n",
      "                           'observation_fn': None,\n",
      "                           'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x29adb1be0>},\n",
      "                           'policies_to_train': None,\n",
      "                           'policy_map_cache': None,\n",
      "                           'policy_map_capacity': 100,\n",
      "                           'policy_mapping_fn': None,\n",
      "                           'replay_mode': 'independent'},\n",
      "            'n_step': 1,\n",
      "            'no_done_at_end': False,\n",
      "            'noisy': False,\n",
      "            'normalize_actions': True,\n",
      "            'num_atoms': 1,\n",
      "            'num_consecutive_worker_failures_tolerance': 100,\n",
      "            'num_cpus_for_driver': 1,\n",
      "            'num_cpus_per_worker': 1,\n",
      "            'num_envs_per_worker': 1,\n",
      "            'num_gpus': 0,\n",
      "            'num_gpus_per_worker': 0,\n",
      "            'num_workers': 0,\n",
      "            'observation_filter': 'NoFilter',\n",
      "            'observation_space': None,\n",
      "            'off_policy_estimation_methods': {},\n",
      "            'optimizer': {},\n",
      "            'output': None,\n",
      "            'output_compress_columns': ['obs', 'new_obs'],\n",
      "            'output_config': {},\n",
      "            'output_max_file_size': 67108864,\n",
      "            'placement_strategy': 'PACK',\n",
      "            'postprocess_inputs': False,\n",
      "            'preprocessor_pref': 'deepmind',\n",
      "            'prioritized_replay': -1,\n",
      "            'prioritized_replay_alpha': -1,\n",
      "            'prioritized_replay_beta': -1,\n",
      "            'prioritized_replay_eps': -1,\n",
      "            'recreate_failed_workers': False,\n",
      "            'remote_env_batch_wait_ms': 0,\n",
      "            'remote_worker_envs': False,\n",
      "            'render_env': False,\n",
      "            'replay_batch_size': -1,\n",
      "            'replay_buffer_config': {'capacity': 50000,\n",
      "                                     'prioritized_replay': -1,\n",
      "                                     'prioritized_replay_alpha': 0.6,\n",
      "                                     'prioritized_replay_beta': 0.4,\n",
      "                                     'prioritized_replay_eps': 1e-06,\n",
      "                                     'replay_mode': 'independent',\n",
      "                                     'replay_sequence_length': 1,\n",
      "                                     'type': <class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>,\n",
      "                                     'worker_side_prioritization': False},\n",
      "            'replay_sequence_length': None,\n",
      "            'restart_failed_sub_environments': False,\n",
      "            'rollout_fragment_length': 4,\n",
      "            'sample_async': False,\n",
      "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      "            'sampler_perf_stats_ema_coef': None,\n",
      "            'seed': None,\n",
      "            'shuffle_buffer_size': 0,\n",
      "            'sigma0': 0.5,\n",
      "            'simple_optimizer': False,\n",
      "            'soft_horizon': False,\n",
      "            'store_buffer_in_checkpoints': False,\n",
      "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
      "            'synchronize_filters': True,\n",
      "            'target_network_update_freq': 500,\n",
      "            'tf_session_args': {'allow_soft_placement': True,\n",
      "                                'device_count': {'CPU': 1},\n",
      "                                'gpu_options': {'allow_growth': True},\n",
      "                                'inter_op_parallelism_threads': 2,\n",
      "                                'intra_op_parallelism_threads': 2,\n",
      "                                'log_device_placement': False},\n",
      "            'timesteps_per_iteration': -1,\n",
      "            'train_batch_size': 32,\n",
      "            'training_intensity': None,\n",
      "            'v_max': 10.0,\n",
      "            'v_min': -10.0,\n",
      "            'validate_workers_after_construction': True},\n",
      " 'counters': {'last_target_update_ts': 1000,\n",
      "              'num_agent_steps_sampled': 1000,\n",
      "              'num_agent_steps_trained': 32,\n",
      "              'num_env_steps_sampled': 1000,\n",
      "              'num_env_steps_trained': 32,\n",
      "              'num_target_updates': 1},\n",
      " 'custom_metrics': {},\n",
      " 'date': '2022-09-14_13-51-22',\n",
      " 'done': False,\n",
      " 'episode_len_mean': 10.0,\n",
      " 'episode_media': {},\n",
      " 'episode_reward_max': 155.30097372867394,\n",
      " 'episode_reward_mean': 95.27667682111381,\n",
      " 'episode_reward_min': 14.64619139305034,\n",
      " 'episodes_this_iter': 100,\n",
      " 'episodes_total': 100,\n",
      " 'experiment_id': '1bb14595ded74289b6b3e8ab808197ca',\n",
      " 'hist_stats': {'episode_lengths': [10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10],\n",
      "                'episode_reward': [107.73131637916258,\n",
      "                                   121.12616169786399,\n",
      "                                   55.6356226613589,\n",
      "                                   116.12297080509049,\n",
      "                                   116.33285200512995,\n",
      "                                   77.04105597584541,\n",
      "                                   85.34253049549898,\n",
      "                                   102.800856101365,\n",
      "                                   120.02930412350622,\n",
      "                                   92.14648026822604,\n",
      "                                   100.34489627522422,\n",
      "                                   109.21099905866471,\n",
      "                                   122.97744728279422,\n",
      "                                   81.05572359999877,\n",
      "                                   114.49737450333119,\n",
      "                                   86.93018651590593,\n",
      "                                   129.21031753728346,\n",
      "                                   112.2853196025372,\n",
      "                                   130.97636742204344,\n",
      "                                   89.11383319781031,\n",
      "                                   86.14717405705306,\n",
      "                                   107.26021801780917,\n",
      "                                   78.9641656568486,\n",
      "                                   126.33865664892537,\n",
      "                                   97.46511714113973,\n",
      "                                   98.88994446552164,\n",
      "                                   88.93643053309191,\n",
      "                                   85.74615363261466,\n",
      "                                   105.42746888274449,\n",
      "                                   71.06595153658625,\n",
      "                                   99.06319502208723,\n",
      "                                   82.6962849391252,\n",
      "                                   118.87139890064041,\n",
      "                                   66.43558388184789,\n",
      "                                   73.64113265859763,\n",
      "                                   62.130293250199166,\n",
      "                                   124.00189554761201,\n",
      "                                   50.22437072238969,\n",
      "                                   141.86441233584776,\n",
      "                                   155.30097372867394,\n",
      "                                   60.29336953094787,\n",
      "                                   129.96916448085068,\n",
      "                                   70.0825737564321,\n",
      "                                   98.92757100597302,\n",
      "                                   108.83462569953667,\n",
      "                                   135.9390347294239,\n",
      "                                   127.0823722551843,\n",
      "                                   50.0644685060385,\n",
      "                                   62.79167043233718,\n",
      "                                   98.95880483457393,\n",
      "                                   77.89728252669475,\n",
      "                                   93.0113511121601,\n",
      "                                   75.09508996906713,\n",
      "                                   131.05962493516375,\n",
      "                                   89.66977384412422,\n",
      "                                   104.52275858442997,\n",
      "                                   101.19136050593995,\n",
      "                                   85.62824683640346,\n",
      "                                   87.30922826646832,\n",
      "                                   73.94127880749645,\n",
      "                                   70.4088245929354,\n",
      "                                   78.01211270385701,\n",
      "                                   102.66746131435902,\n",
      "                                   78.54538501601303,\n",
      "                                   95.09524696773849,\n",
      "                                   110.96672062672528,\n",
      "                                   85.82476436850476,\n",
      "                                   66.4038037064634,\n",
      "                                   84.1456215886439,\n",
      "                                   138.23159793891537,\n",
      "                                   86.46934523386082,\n",
      "                                   94.93465907530734,\n",
      "                                   109.48903626006934,\n",
      "                                   79.11353249910762,\n",
      "                                   71.248525015852,\n",
      "                                   106.7604186089796,\n",
      "                                   86.48192080297012,\n",
      "                                   64.45202932219708,\n",
      "                                   126.36135684992321,\n",
      "                                   86.69230254738072,\n",
      "                                   112.54448447381665,\n",
      "                                   103.13782556393423,\n",
      "                                   115.368379299434,\n",
      "                                   119.734377186157,\n",
      "                                   66.53820102958099,\n",
      "                                   93.75643695915754,\n",
      "                                   134.8354182253464,\n",
      "                                   78.36513253914303,\n",
      "                                   110.86954813397847,\n",
      "                                   87.00713562429084,\n",
      "                                   97.04831798077794,\n",
      "                                   83.64420944005077,\n",
      "                                   76.55856417169038,\n",
      "                                   69.32530794904322,\n",
      "                                   124.53603619087392,\n",
      "                                   86.51107909375196,\n",
      "                                   95.61654196271216,\n",
      "                                   70.96130291430053,\n",
      "                                   14.64619139305034,\n",
      "                                   110.7064392532451]},\n",
      " 'hostname': 'Kouroshs-MacBook-Pro-13',\n",
      " 'info': {'last_target_update_ts': 1000,\n",
      "          'learner': {'default_policy': {'custom_metrics': {},\n",
      "                                         'learner_stats': {'allreduce_latency': 0.0,\n",
      "                                                           'cur_lr': 0.0005,\n",
      "                                                           'grad_gnorm': 40.0,\n",
      "                                                           'max_q': 1.1129904985427856,\n",
      "                                                           'mean_q': -0.030595846474170685,\n",
      "                                                           'min_q': -0.8129396438598633},\n",
      "                                         'mean_td_error': -9.967382431030273,\n",
      "                                         'model': {},\n",
      "                                         'num_agent_steps_trained': 32.0,\n",
      "                                         'td_error': array([ -1.7777545,  -3.7771614,  -0.9626526, -36.223763 , -14.322636 ,\n",
      "        -6.2399664, -32.756954 , -26.448507 ,  -2.5040762,  -9.519612 ,\n",
      "        -1.5875537,  -4.4200625,  -4.199381 ,  -1.6595187, -17.96696  ,\n",
      "        -1.7421147, -12.5235   ,  -1.6417409,  -5.6508427, -13.043986 ,\n",
      "        -2.368597 ,  -4.2747793,  -1.8386664,  -1.6519091,  -5.602425 ,\n",
      "       -11.301262 , -20.03695  ,  -5.602425 , -26.448507 ,  -1.9773688,\n",
      "       -37.380535 ,  -1.5040684], dtype=float32)}},\n",
      "          'num_agent_steps_sampled': 1000,\n",
      "          'num_agent_steps_trained': 32,\n",
      "          'num_env_steps_sampled': 1000,\n",
      "          'num_env_steps_trained': 32,\n",
      "          'num_target_updates': 1},\n",
      " 'iterations_since_restore': 1,\n",
      " 'node_ip': '127.0.0.1',\n",
      " 'num_agent_steps_sampled': 1000,\n",
      " 'num_agent_steps_trained': 32,\n",
      " 'num_env_steps_sampled': 1000,\n",
      " 'num_env_steps_sampled_this_iter': 1000,\n",
      " 'num_env_steps_trained': 32,\n",
      " 'num_env_steps_trained_this_iter': 32,\n",
      " 'num_faulty_episodes': 0,\n",
      " 'num_healthy_workers': 0,\n",
      " 'num_recreated_workers': 0,\n",
      " 'num_steps_trained_this_iter': 32,\n",
      " 'perf': {'cpu_util_percent': 31.166666666666668,\n",
      "          'ram_util_percent': 83.23333333333333},\n",
      " 'pid': 82158,\n",
      " 'policy_reward_max': {},\n",
      " 'policy_reward_mean': {},\n",
      " 'policy_reward_min': {},\n",
      " 'sampler_perf': {'mean_action_processing_ms': 0.026262961662970808,\n",
      "                  'mean_env_render_ms': 0.0,\n",
      "                  'mean_env_wait_ms': 0.18471580642563,\n",
      "                  'mean_inference_ms': 0.6939926585712872,\n",
      "                  'mean_raw_obs_processing_ms': 0.9061042126361191},\n",
      " 'sampler_results': {'custom_metrics': {},\n",
      "                     'episode_len_mean': 10.0,\n",
      "                     'episode_media': {},\n",
      "                     'episode_reward_max': 155.30097372867394,\n",
      "                     'episode_reward_mean': 95.27667682111381,\n",
      "                     'episode_reward_min': 14.64619139305034,\n",
      "                     'episodes_this_iter': 100,\n",
      "                     'hist_stats': {'episode_lengths': [10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10],\n",
      "                                    'episode_reward': [107.73131637916258,\n",
      "                                                       121.12616169786399,\n",
      "                                                       55.6356226613589,\n",
      "                                                       116.12297080509049,\n",
      "                                                       116.33285200512995,\n",
      "                                                       77.04105597584541,\n",
      "                                                       85.34253049549898,\n",
      "                                                       102.800856101365,\n",
      "                                                       120.02930412350622,\n",
      "                                                       92.14648026822604,\n",
      "                                                       100.34489627522422,\n",
      "                                                       109.21099905866471,\n",
      "                                                       122.97744728279422,\n",
      "                                                       81.05572359999877,\n",
      "                                                       114.49737450333119,\n",
      "                                                       86.93018651590593,\n",
      "                                                       129.21031753728346,\n",
      "                                                       112.2853196025372,\n",
      "                                                       130.97636742204344,\n",
      "                                                       89.11383319781031,\n",
      "                                                       86.14717405705306,\n",
      "                                                       107.26021801780917,\n",
      "                                                       78.9641656568486,\n",
      "                                                       126.33865664892537,\n",
      "                                                       97.46511714113973,\n",
      "                                                       98.88994446552164,\n",
      "                                                       88.93643053309191,\n",
      "                                                       85.74615363261466,\n",
      "                                                       105.42746888274449,\n",
      "                                                       71.06595153658625,\n",
      "                                                       99.06319502208723,\n",
      "                                                       82.6962849391252,\n",
      "                                                       118.87139890064041,\n",
      "                                                       66.43558388184789,\n",
      "                                                       73.64113265859763,\n",
      "                                                       62.130293250199166,\n",
      "                                                       124.00189554761201,\n",
      "                                                       50.22437072238969,\n",
      "                                                       141.86441233584776,\n",
      "                                                       155.30097372867394,\n",
      "                                                       60.29336953094787,\n",
      "                                                       129.96916448085068,\n",
      "                                                       70.0825737564321,\n",
      "                                                       98.92757100597302,\n",
      "                                                       108.83462569953667,\n",
      "                                                       135.9390347294239,\n",
      "                                                       127.0823722551843,\n",
      "                                                       50.0644685060385,\n",
      "                                                       62.79167043233718,\n",
      "                                                       98.95880483457393,\n",
      "                                                       77.89728252669475,\n",
      "                                                       93.0113511121601,\n",
      "                                                       75.09508996906713,\n",
      "                                                       131.05962493516375,\n",
      "                                                       89.66977384412422,\n",
      "                                                       104.52275858442997,\n",
      "                                                       101.19136050593995,\n",
      "                                                       85.62824683640346,\n",
      "                                                       87.30922826646832,\n",
      "                                                       73.94127880749645,\n",
      "                                                       70.4088245929354,\n",
      "                                                       78.01211270385701,\n",
      "                                                       102.66746131435902,\n",
      "                                                       78.54538501601303,\n",
      "                                                       95.09524696773849,\n",
      "                                                       110.96672062672528,\n",
      "                                                       85.82476436850476,\n",
      "                                                       66.4038037064634,\n",
      "                                                       84.1456215886439,\n",
      "                                                       138.23159793891537,\n",
      "                                                       86.46934523386082,\n",
      "                                                       94.93465907530734,\n",
      "                                                       109.48903626006934,\n",
      "                                                       79.11353249910762,\n",
      "                                                       71.248525015852,\n",
      "                                                       106.7604186089796,\n",
      "                                                       86.48192080297012,\n",
      "                                                       64.45202932219708,\n",
      "                                                       126.36135684992321,\n",
      "                                                       86.69230254738072,\n",
      "                                                       112.54448447381665,\n",
      "                                                       103.13782556393423,\n",
      "                                                       115.368379299434,\n",
      "                                                       119.734377186157,\n",
      "                                                       66.53820102958099,\n",
      "                                                       93.75643695915754,\n",
      "                                                       134.8354182253464,\n",
      "                                                       78.36513253914303,\n",
      "                                                       110.86954813397847,\n",
      "                                                       87.00713562429084,\n",
      "                                                       97.04831798077794,\n",
      "                                                       83.64420944005077,\n",
      "                                                       76.55856417169038,\n",
      "                                                       69.32530794904322,\n",
      "                                                       124.53603619087392,\n",
      "                                                       86.51107909375196,\n",
      "                                                       95.61654196271216,\n",
      "                                                       70.96130291430053,\n",
      "                                                       14.64619139305034,\n",
      "                                                       110.7064392532451]},\n",
      "                     'num_faulty_episodes': 0,\n",
      "                     'policy_reward_max': {},\n",
      "                     'policy_reward_mean': {},\n",
      "                     'policy_reward_min': {},\n",
      "                     'sampler_perf': {'mean_action_processing_ms': 0.026262961662970808,\n",
      "                                      'mean_env_render_ms': 0.0,\n",
      "                                      'mean_env_wait_ms': 0.18471580642563,\n",
      "                                      'mean_inference_ms': 0.6939926585712872,\n",
      "                                      'mean_raw_obs_processing_ms': 0.9061042126361191}},\n",
      " 'time_since_restore': 1.965472936630249,\n",
      " 'time_this_iter_s': 1.965472936630249,\n",
      " 'time_total_s': 1.965472936630249,\n",
      " 'timers': {'learn_throughput': 1051.122,\n",
      "            'learn_time_ms': 30.444,\n",
      "            'load_throughput': 355073.354,\n",
      "            'load_time_ms': 0.09,\n",
      "            'synch_weights_time_ms': 0.014,\n",
      "            'training_iteration_time_ms': 11.248},\n",
      " 'timestamp': 1663188682,\n",
      " 'timesteps_since_restore': 0,\n",
      " 'timesteps_total': 1000,\n",
      " 'training_iteration': 1,\n",
      " 'trial_id': 'default',\n",
      " 'warmup_time': 0.10462594032287598}\n"
     ]
    }
   ],
   "source": [
    "# print the results\n",
    "print(results_bandit.keys())\n",
    "pprint(results_bandit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-09-14 13:51:37 (running for 00:00:14.93)<br>Memory usage on this node: 13.3/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/8.32 GiB heap, 0.0/2.0 GiB objects<br>Result logdir: /Users/kourosh/dev/anyscale_academy/ray-rllib/acm_recsys_tutorial_2022/results_notebook/online_rl/bandits_dqn/DQN_2022-09-14_13-51-22<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  num_recreated_wor...</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_modified-lts_fddb1_00000</td><td>TERMINATED</td><td>127.0.0.1:85528</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.95171</td><td style=\"text-align: right;\">1000</td><td style=\"text-align: right;\"> 104.517</td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">             148.705</td><td style=\"text-align: right;\">             47.7873</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/util/placement_group.py:78: DeprecationWarning: placement_group parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return bundle_reservation_check.options(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/actor.py:637: DeprecationWarning: placement_group parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/actor.py:637: DeprecationWarning: placement_group_bundle_index parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/actor.py:637: DeprecationWarning: placement_group_capture_child_tasks parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   _ATTRVALUE_LISTVALUE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   import imp\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:36: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   'nearest': pil_image.NEAREST,\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:37: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   'bilinear': pil_image.BILINEAR,\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:38: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   'bicubic': pil_image.BICUBIC,\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:39: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   'hamming': pil_image.HAMMING,\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:40: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   'box': pil_image.BOX,\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:41: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   'lanczos': pil_image.LANCZOS,\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow_probability/__init__.py:58: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow_probability/python/mcmc/sample_halton_sequence.py:374: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\u001b[2m\u001b[36m(pid=85528)\u001b[0m   sieve = np.ones(n // 3 + (n % 6 == 2), dtype=np.bool)\n",
      "\u001b[2m\u001b[36m(DQN pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/gin/tf/__init__.py:48: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(DQN pid=85528)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(DQN pid=85528)\u001b[0m 2022-09-14 13:51:35,572\tWARNING deprecation.py:47 -- DeprecationWarning: `ray.rllib.algorithms.dqn.dqn.DEFAULT_CONFIG` has been deprecated. Use `ray.rllib.algorithms.dqn.dqn.DQNConfig(...)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=85528)\u001b[0m 2022-09-14 13:51:35,572\tWARNING deprecation.py:47 -- DeprecationWarning: `config['multiagent']['replay_mode']` has been deprecated. config['replay_buffer_config']['replay_mode'] This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=85528)\u001b[0m 2022-09-14 13:51:35,573\tINFO simple_q.py:293 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DQN pid=85528)\u001b[0m 2022-09-14 13:51:35,574\tINFO algorithm.py:351 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(DQN pid=85528)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/_private/ray_option_utils.py:266: DeprecationWarning: Setting 'object_store_memory' for actors is deprecated since it doesn't actually reserve the required object store memory. Use object spilling that's enabled by default (https://docs.ray.io/en/releases-2.0.0/ray-core/objects/object-spilling.html) instead to bypass the object store memory size limitation.\n",
      "\u001b[2m\u001b[36m(DQN pid=85528)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(DQN pid=85528)\u001b[0m 2022-09-14 13:51:35,580\tWARNING env.py:142 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(DQN pid=85528)\u001b[0m 2022-09-14 13:51:35,606\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(DQN pid=85528)\u001b[0m 2022-09-14 13:51:35,629\tWARNING deprecation.py:47 -- DeprecationWarning: `ReplayBuffer.add_batch()` has been deprecated. Use `ReplayBuffer.add()` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=85528)\u001b[0m 2022-09-14 13:51:35,638\tWARNING multi_agent_prioritized_replay_buffer.py:220 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_modified-lts_fddb1_00000:\n",
      "  agent_timesteps_total: 1000\n",
      "  counters:\n",
      "    last_target_update_ts: 1000\n",
      "    num_agent_steps_sampled: 1000\n",
      "    num_agent_steps_trained: 32\n",
      "    num_env_steps_sampled: 1000\n",
      "    num_env_steps_trained: 32\n",
      "    num_target_updates: 1\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-14_13-51-37\n",
      "  done: true\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 148.70485027849423\n",
      "  episode_reward_mean: 104.51659080890425\n",
      "  episode_reward_min: 47.787271093477614\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: 7c127f8ed2524900a50a94bc521402c0\n",
      "  hostname: Kouroshs-MacBook-Pro-13\n",
      "  info:\n",
      "    last_target_update_ts: 1000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 40.0\n",
      "          max_q: 0.34848907589912415\n",
      "          mean_q: -0.573158860206604\n",
      "          min_q: -1.5805246829986572\n",
      "        mean_td_error: -8.816120147705078\n",
      "        model: {}\n",
      "        num_agent_steps_trained: 32.0\n",
      "        td_error: [-27.696687698364258, -4.558911323547363, -1.6549324989318848, -10.772257804870605,\n",
      "          -30.34419059753418, -13.06277847290039, -1.5288293361663818, -6.828502178192139,\n",
      "          -0.8221192359924316, -1.2460825443267822, -31.463613510131836, -1.9326225519180298,\n",
      "          -1.8079124689102173, -5.293304443359375, -16.601726531982422, -35.865264892578125,\n",
      "          -1.7130883932113647, -11.753196716308594, -2.127303123474121, -3.0780763626098633,\n",
      "          -7.4194111824035645, -2.3247716426849365, -1.5285396575927734, -1.8679202795028687,\n",
      "          -25.061378479003906, -1.6382107734680176, -11.546520233154297, -2.0100855827331543,\n",
      "          -2.6037518978118896, -6.747955799102783, -5.233675003051758, -3.9821949005126953]\n",
      "    num_agent_steps_sampled: 1000\n",
      "    num_agent_steps_trained: 32\n",
      "    num_env_steps_sampled: 1000\n",
      "    num_env_steps_trained: 32\n",
      "    num_target_updates: 1\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 1000\n",
      "  num_agent_steps_trained: 32\n",
      "  num_env_steps_sampled: 1000\n",
      "  num_env_steps_sampled_this_iter: 1000\n",
      "  num_env_steps_trained: 32\n",
      "  num_env_steps_trained_this_iter: 32\n",
      "  num_faulty_episodes: 0\n",
      "  num_healthy_workers: 0\n",
      "  num_recreated_workers: 0\n",
      "  num_steps_trained_this_iter: 32\n",
      "  perf:\n",
      "    cpu_util_percent: 56.23333333333333\n",
      "    ram_util_percent: 83.16666666666667\n",
      "  pid: 85528\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030349184583117073\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.19970926252397503\n",
      "    mean_inference_ms: 0.7152173902604964\n",
      "    mean_raw_obs_processing_ms: 0.8663969201879665\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 148.70485027849423\n",
      "    episode_reward_mean: 104.51659080890425\n",
      "    episode_reward_min: 47.787271093477614\n",
      "    episodes_this_iter: 100\n",
      "    hist_stats:\n",
      "      episode_lengths: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "      episode_reward: [47.787271093477614, 91.23871636785044, 98.31720690642426, 80.34252043394243,\n",
      "        70.73738092218053, 93.74084557014595, 81.02369588290227, 107.63328530378557,\n",
      "        95.39813485267685, 68.17310018000184, 127.43627851064811, 113.45005750102077,\n",
      "        80.08796222106687, 103.20697227924104, 89.46643317189782, 125.98427276566609,\n",
      "        65.02665408162662, 107.86614048060845, 90.55675136336188, 148.70485027849423,\n",
      "        111.21443007155533, 62.691814149433455, 131.48845679908862, 131.8807377087847,\n",
      "        83.96646919516564, 96.12486068375415, 87.20456042543874, 119.36880777777515,\n",
      "        80.92531710024045, 114.22300879203691, 120.45421442927929, 104.7287757391915,\n",
      "        56.730080846371195, 101.65787901138691, 103.31737328841844, 92.23891255989929,\n",
      "        134.10180901679348, 81.59855237810723, 132.01040476617007, 106.13074488011414,\n",
      "        84.37478916042666, 131.64102422169347, 118.80328590379906, 77.35145754847994,\n",
      "        122.33322702822161, 137.4700378721568, 117.34823769008194, 117.78915237933242,\n",
      "        110.65687249444363, 121.69154310718297, 70.3467398684753, 142.4229611211825,\n",
      "        127.14604514981967, 102.31742208923303, 106.07369756218573, 104.36853050456754,\n",
      "        122.33628838176097, 125.59349357551072, 83.70655507094641, 112.26781648991036,\n",
      "        109.06296456487995, 49.64343767679563, 101.31067094480039, 126.25235033417607,\n",
      "        119.90658463795465, 105.28369127847542, 101.47817112482836, 110.02610756452607,\n",
      "        104.56731566151555, 139.49377519774754, 108.7219576154429, 85.63781668263142,\n",
      "        109.21169508726311, 123.72972197360647, 96.54728885609413, 95.40626438942678,\n",
      "        109.8038844918646, 96.07209604800646, 100.33660548939793, 122.39753836781283,\n",
      "        108.54161596700298, 99.78017586842553, 71.20215550945696, 105.81750636664613,\n",
      "        144.86174833114302, 118.17045602457283, 120.66467425380617, 140.98676313217692,\n",
      "        99.85699709691418, 70.0308158266632, 132.1445962002779, 107.2373703877544, 115.78327357542688,\n",
      "        87.43501381197724, 120.41608469223443, 71.68609245395348, 121.46568565048784,\n",
      "        101.58798531809263, 114.35821364636763, 110.46700178436413]\n",
      "    num_faulty_episodes: 0\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.030349184583117073\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.19970926252397503\n",
      "      mean_inference_ms: 0.7152173902604964\n",
      "      mean_raw_obs_processing_ms: 0.8663969201879665\n",
      "  time_since_restore: 1.9517138004302979\n",
      "  time_this_iter_s: 1.9517138004302979\n",
      "  time_total_s: 1.9517138004302979\n",
      "  timers:\n",
      "    learn_throughput: 7764.983\n",
      "    learn_time_ms: 4.121\n",
      "    load_throughput: 438620.026\n",
      "    load_time_ms: 0.073\n",
      "    synch_weights_time_ms: 0.013\n",
      "    training_iteration_time_ms: 7.023\n",
      "  timestamp: 1663188697\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1000\n",
      "  training_iteration: 1\n",
      "  trial_id: fddb1_00000\n",
      "  warmup_time: 0.045000314712524414\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQN pid=85528)\u001b[0m 2022-09-14 13:51:37,558\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n",
      "2022-09-14 13:51:38,568\tINFO tune.py:758 -- Total run time: 15.73 seconds (14.90 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "# Using tune.Tuner(param_space=..., run_config=air.RunConfig)\n",
    "# air.RunConfig(local_dir=..., stop=...)\n",
    "# TODO: Code here\n",
    "tuner = tune.Tuner(\n",
    "    DQN,\n",
    "    param_space=bandit_config.to_dict(),\n",
    "    run_config=air.RunConfig(\n",
    "        local_dir='./results_notebook/online_rl/bandits_dqn',\n",
    "        stop={\"training_iteration\": 1},\n",
    "    )\n",
    ")\n",
    "results_bandit = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ray.tune.result_grid.ResultGrid at 0x2b2fefb80>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_bandit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_timesteps_total': 1000,\n",
      " 'config': {'_disable_action_flattening': False,\n",
      "            '_disable_execution_plan_api': True,\n",
      "            '_disable_preprocessor_api': False,\n",
      "            '_fake_gpus': False,\n",
      "            '_tf_policy_handles_more_than_one_loss': False,\n",
      "            'action_space': None,\n",
      "            'actions_in_input_normalized': False,\n",
      "            'adam_epsilon': 1e-08,\n",
      "            'always_attach_evaluation_results': False,\n",
      "            'batch_mode': 'truncate_episodes',\n",
      "            'before_learn_on_batch': None,\n",
      "            'buffer_size': -1,\n",
      "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
      "            'clip_actions': False,\n",
      "            'clip_rewards': None,\n",
      "            'collect_metrics_timeout': -1,\n",
      "            'compress_observations': False,\n",
      "            'create_env_on_driver': False,\n",
      "            'custom_eval_function': None,\n",
      "            'custom_resources_per_worker': {},\n",
      "            'disable_env_checking': False,\n",
      "            'double_q': True,\n",
      "            'dueling': True,\n",
      "            'eager_max_retraces': 20,\n",
      "            'eager_tracing': False,\n",
      "            'enable_connectors': False,\n",
      "            'enable_tf1_exec_eagerly': False,\n",
      "            'env': 'modified-lts',\n",
      "            'env_config': {'num_candidates': 20,\n",
      "                           'resample_documents': True,\n",
      "                           'reward_scale': 1.0,\n",
      "                           'seed': 100,\n",
      "                           'slate_size': 1},\n",
      "            'env_task_fn': None,\n",
      "            'evaluation_config': {'_disable_action_flattening': False,\n",
      "                                  '_disable_execution_plan_api': True,\n",
      "                                  '_disable_preprocessor_api': False,\n",
      "                                  '_fake_gpus': False,\n",
      "                                  '_tf_policy_handles_more_than_one_loss': False,\n",
      "                                  'action_space': None,\n",
      "                                  'actions_in_input_normalized': False,\n",
      "                                  'adam_epsilon': 1e-08,\n",
      "                                  'always_attach_evaluation_results': False,\n",
      "                                  'batch_mode': 'truncate_episodes',\n",
      "                                  'before_learn_on_batch': None,\n",
      "                                  'buffer_size': -1,\n",
      "                                  'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
      "                                  'clip_actions': False,\n",
      "                                  'clip_rewards': None,\n",
      "                                  'collect_metrics_timeout': -1,\n",
      "                                  'compress_observations': False,\n",
      "                                  'create_env_on_driver': False,\n",
      "                                  'custom_eval_function': None,\n",
      "                                  'custom_resources_per_worker': {},\n",
      "                                  'disable_env_checking': False,\n",
      "                                  'double_q': True,\n",
      "                                  'dueling': True,\n",
      "                                  'eager_max_retraces': 20,\n",
      "                                  'eager_tracing': False,\n",
      "                                  'enable_connectors': False,\n",
      "                                  'enable_tf1_exec_eagerly': False,\n",
      "                                  'env': 'modified-lts',\n",
      "                                  'env_config': {'num_candidates': 20,\n",
      "                                                 'resample_documents': True,\n",
      "                                                 'reward_scale': 1.0,\n",
      "                                                 'seed': 100,\n",
      "                                                 'slate_size': 1},\n",
      "                                  'env_task_fn': None,\n",
      "                                  'evaluation_config': {'explore': False},\n",
      "                                  'evaluation_duration': 10,\n",
      "                                  'evaluation_duration_unit': 'episodes',\n",
      "                                  'evaluation_interval': None,\n",
      "                                  'evaluation_num_episodes': -1,\n",
      "                                  'evaluation_num_workers': 0,\n",
      "                                  'evaluation_parallel_to_training': False,\n",
      "                                  'evaluation_sample_timeout_s': 180.0,\n",
      "                                  'exploration_config': {'epsilon_timesteps': 10000,\n",
      "                                                         'final_epsilon': 0.02,\n",
      "                                                         'initial_epsilon': 1.0,\n",
      "                                                         'type': 'EpsilonGreedy'},\n",
      "                                  'explore': False,\n",
      "                                  'extra_python_environs_for_driver': {},\n",
      "                                  'extra_python_environs_for_worker': {},\n",
      "                                  'fake_sampler': False,\n",
      "                                  'framework': 'torch',\n",
      "                                  'gamma': 0.0,\n",
      "                                  'grad_clip': 40,\n",
      "                                  'hiddens': [256],\n",
      "                                  'horizon': None,\n",
      "                                  'ignore_worker_failures': False,\n",
      "                                  'in_evaluation': False,\n",
      "                                  'input': 'sampler',\n",
      "                                  'input_config': {},\n",
      "                                  'input_evaluation': -1,\n",
      "                                  'keep_per_episode_custom_metrics': False,\n",
      "                                  'learning_starts': -1,\n",
      "                                  'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                                                            'intra_op_parallelism_threads': 8},\n",
      "                                  'log_level': 'WARN',\n",
      "                                  'log_sys_usage': True,\n",
      "                                  'logger_config': None,\n",
      "                                  'logger_creator': None,\n",
      "                                  'lr': 0.0005,\n",
      "                                  'lr_schedule': None,\n",
      "                                  'metrics_episode_collection_timeout_s': 60.0,\n",
      "                                  'metrics_num_episodes_for_smoothing': 100,\n",
      "                                  'metrics_smoothing_episodes': -1,\n",
      "                                  'min_iter_time_s': -1,\n",
      "                                  'min_sample_timesteps_per_iteration': 1000,\n",
      "                                  'min_sample_timesteps_per_reporting': -1,\n",
      "                                  'min_time_s_per_iteration': 1,\n",
      "                                  'min_time_s_per_reporting': -1,\n",
      "                                  'min_train_timesteps_per_iteration': 0,\n",
      "                                  'min_train_timesteps_per_reporting': -1,\n",
      "                                  'model': {'_disable_action_flattening': False,\n",
      "                                            '_disable_preprocessor_api': False,\n",
      "                                            '_time_major': False,\n",
      "                                            '_use_default_native_models': False,\n",
      "                                            'attention_dim': 64,\n",
      "                                            'attention_head_dim': 32,\n",
      "                                            'attention_init_gru_gate_bias': 2.0,\n",
      "                                            'attention_memory_inference': 50,\n",
      "                                            'attention_memory_training': 50,\n",
      "                                            'attention_num_heads': 1,\n",
      "                                            'attention_num_transformer_units': 1,\n",
      "                                            'attention_position_wise_mlp_dim': 32,\n",
      "                                            'attention_use_n_prev_actions': 0,\n",
      "                                            'attention_use_n_prev_rewards': 0,\n",
      "                                            'conv_activation': 'relu',\n",
      "                                            'conv_filters': None,\n",
      "                                            'custom_action_dist': None,\n",
      "                                            'custom_model': None,\n",
      "                                            'custom_model_config': {},\n",
      "                                            'custom_preprocessor': None,\n",
      "                                            'dim': 84,\n",
      "                                            'fcnet_activation': 'tanh',\n",
      "                                            'fcnet_hiddens': [256, 256],\n",
      "                                            'framestack': True,\n",
      "                                            'free_log_std': False,\n",
      "                                            'grayscale': False,\n",
      "                                            'lstm_cell_size': 256,\n",
      "                                            'lstm_use_prev_action': False,\n",
      "                                            'lstm_use_prev_action_reward': -1,\n",
      "                                            'lstm_use_prev_reward': False,\n",
      "                                            'max_seq_len': 20,\n",
      "                                            'no_final_linear': False,\n",
      "                                            'post_fcnet_activation': 'relu',\n",
      "                                            'post_fcnet_hiddens': [],\n",
      "                                            'use_attention': False,\n",
      "                                            'use_lstm': False,\n",
      "                                            'vf_share_layers': True,\n",
      "                                            'zero_mean': True},\n",
      "                                  'monitor': -1,\n",
      "                                  'multiagent': {'count_steps_by': 'env_steps',\n",
      "                                                 'observation_fn': None,\n",
      "                                                 'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x3580287f0>},\n",
      "                                                 'policies_to_train': None,\n",
      "                                                 'policy_map_cache': None,\n",
      "                                                 'policy_map_capacity': 100,\n",
      "                                                 'policy_mapping_fn': None,\n",
      "                                                 'replay_mode': 'independent'},\n",
      "                                  'n_step': 1,\n",
      "                                  'no_done_at_end': False,\n",
      "                                  'noisy': False,\n",
      "                                  'normalize_actions': True,\n",
      "                                  'num_atoms': 1,\n",
      "                                  'num_consecutive_worker_failures_tolerance': 100,\n",
      "                                  'num_cpus_for_driver': 1,\n",
      "                                  'num_cpus_per_worker': 1,\n",
      "                                  'num_envs_per_worker': 1,\n",
      "                                  'num_gpus': 0,\n",
      "                                  'num_gpus_per_worker': 0,\n",
      "                                  'num_workers': 0,\n",
      "                                  'observation_filter': 'NoFilter',\n",
      "                                  'observation_space': None,\n",
      "                                  'off_policy_estimation_methods': {},\n",
      "                                  'optimizer': {},\n",
      "                                  'output': None,\n",
      "                                  'output_compress_columns': ['obs', 'new_obs'],\n",
      "                                  'output_config': {},\n",
      "                                  'output_max_file_size': 67108864,\n",
      "                                  'placement_strategy': 'PACK',\n",
      "                                  'postprocess_inputs': False,\n",
      "                                  'preprocessor_pref': 'deepmind',\n",
      "                                  'prioritized_replay': -1,\n",
      "                                  'prioritized_replay_alpha': -1,\n",
      "                                  'prioritized_replay_beta': -1,\n",
      "                                  'prioritized_replay_eps': -1,\n",
      "                                  'recreate_failed_workers': False,\n",
      "                                  'remote_env_batch_wait_ms': 0,\n",
      "                                  'remote_worker_envs': False,\n",
      "                                  'render_env': False,\n",
      "                                  'replay_batch_size': -1,\n",
      "                                  'replay_buffer_config': {'capacity': 50000,\n",
      "                                                           'prioritized_replay': -1,\n",
      "                                                           'prioritized_replay_alpha': 0.6,\n",
      "                                                           'prioritized_replay_beta': 0.4,\n",
      "                                                           'prioritized_replay_eps': 1e-06,\n",
      "                                                           'replay_mode': 'independent',\n",
      "                                                           'replay_sequence_length': 1,\n",
      "                                                           'type': <class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>,\n",
      "                                                           'worker_side_prioritization': False},\n",
      "                                  'replay_sequence_length': None,\n",
      "                                  'restart_failed_sub_environments': False,\n",
      "                                  'rollout_fragment_length': 4,\n",
      "                                  'sample_async': False,\n",
      "                                  'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      "                                  'sampler_perf_stats_ema_coef': None,\n",
      "                                  'seed': None,\n",
      "                                  'shuffle_buffer_size': 0,\n",
      "                                  'sigma0': 0.5,\n",
      "                                  'simple_optimizer': False,\n",
      "                                  'soft_horizon': False,\n",
      "                                  'store_buffer_in_checkpoints': False,\n",
      "                                  'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
      "                                  'synchronize_filters': True,\n",
      "                                  'target_network_update_freq': 500,\n",
      "                                  'tf_session_args': {'allow_soft_placement': True,\n",
      "                                                      'device_count': {'CPU': 1},\n",
      "                                                      'gpu_options': {'allow_growth': True},\n",
      "                                                      'inter_op_parallelism_threads': 2,\n",
      "                                                      'intra_op_parallelism_threads': 2,\n",
      "                                                      'log_device_placement': False},\n",
      "                                  'timesteps_per_iteration': -1,\n",
      "                                  'train_batch_size': 32,\n",
      "                                  'training_intensity': None,\n",
      "                                  'v_max': 10.0,\n",
      "                                  'v_min': -10.0,\n",
      "                                  'validate_workers_after_construction': True},\n",
      "            'evaluation_duration': 10,\n",
      "            'evaluation_duration_unit': 'episodes',\n",
      "            'evaluation_interval': None,\n",
      "            'evaluation_num_episodes': -1,\n",
      "            'evaluation_num_workers': 0,\n",
      "            'evaluation_parallel_to_training': False,\n",
      "            'evaluation_sample_timeout_s': 180.0,\n",
      "            'exploration_config': {'epsilon_timesteps': 10000,\n",
      "                                   'final_epsilon': 0.02,\n",
      "                                   'initial_epsilon': 1.0,\n",
      "                                   'type': 'EpsilonGreedy'},\n",
      "            'explore': True,\n",
      "            'extra_python_environs_for_driver': {},\n",
      "            'extra_python_environs_for_worker': {},\n",
      "            'fake_sampler': False,\n",
      "            'framework': 'torch',\n",
      "            'gamma': 0.0,\n",
      "            'grad_clip': 40,\n",
      "            'hiddens': [256],\n",
      "            'horizon': None,\n",
      "            'ignore_worker_failures': False,\n",
      "            'in_evaluation': False,\n",
      "            'input': 'sampler',\n",
      "            'input_config': {},\n",
      "            'input_evaluation': -1,\n",
      "            'keep_per_episode_custom_metrics': False,\n",
      "            'learning_starts': -1,\n",
      "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                                      'intra_op_parallelism_threads': 8},\n",
      "            'log_level': 'WARN',\n",
      "            'log_sys_usage': True,\n",
      "            'logger_config': None,\n",
      "            'logger_creator': None,\n",
      "            'lr': 0.0005,\n",
      "            'lr_schedule': None,\n",
      "            'metrics_episode_collection_timeout_s': 60.0,\n",
      "            'metrics_num_episodes_for_smoothing': 100,\n",
      "            'metrics_smoothing_episodes': -1,\n",
      "            'min_iter_time_s': -1,\n",
      "            'min_sample_timesteps_per_iteration': 1000,\n",
      "            'min_sample_timesteps_per_reporting': -1,\n",
      "            'min_time_s_per_iteration': 1,\n",
      "            'min_time_s_per_reporting': -1,\n",
      "            'min_train_timesteps_per_iteration': 0,\n",
      "            'min_train_timesteps_per_reporting': -1,\n",
      "            'model': {'_disable_action_flattening': False,\n",
      "                      '_disable_preprocessor_api': False,\n",
      "                      '_time_major': False,\n",
      "                      '_use_default_native_models': False,\n",
      "                      'attention_dim': 64,\n",
      "                      'attention_head_dim': 32,\n",
      "                      'attention_init_gru_gate_bias': 2.0,\n",
      "                      'attention_memory_inference': 50,\n",
      "                      'attention_memory_training': 50,\n",
      "                      'attention_num_heads': 1,\n",
      "                      'attention_num_transformer_units': 1,\n",
      "                      'attention_position_wise_mlp_dim': 32,\n",
      "                      'attention_use_n_prev_actions': 0,\n",
      "                      'attention_use_n_prev_rewards': 0,\n",
      "                      'conv_activation': 'relu',\n",
      "                      'conv_filters': None,\n",
      "                      'custom_action_dist': None,\n",
      "                      'custom_model': None,\n",
      "                      'custom_model_config': {},\n",
      "                      'custom_preprocessor': None,\n",
      "                      'dim': 84,\n",
      "                      'fcnet_activation': 'tanh',\n",
      "                      'fcnet_hiddens': [256, 256],\n",
      "                      'framestack': True,\n",
      "                      'free_log_std': False,\n",
      "                      'grayscale': False,\n",
      "                      'lstm_cell_size': 256,\n",
      "                      'lstm_use_prev_action': False,\n",
      "                      'lstm_use_prev_action_reward': -1,\n",
      "                      'lstm_use_prev_reward': False,\n",
      "                      'max_seq_len': 20,\n",
      "                      'no_final_linear': False,\n",
      "                      'post_fcnet_activation': 'relu',\n",
      "                      'post_fcnet_hiddens': [],\n",
      "                      'use_attention': False,\n",
      "                      'use_lstm': False,\n",
      "                      'vf_share_layers': True,\n",
      "                      'zero_mean': True},\n",
      "            'monitor': -1,\n",
      "            'multiagent': {'count_steps_by': 'env_steps',\n",
      "                           'observation_fn': None,\n",
      "                           'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x3590c7af0>},\n",
      "                           'policies_to_train': None,\n",
      "                           'policy_map_cache': None,\n",
      "                           'policy_map_capacity': 100,\n",
      "                           'policy_mapping_fn': None,\n",
      "                           'replay_mode': 'independent'},\n",
      "            'n_step': 1,\n",
      "            'no_done_at_end': False,\n",
      "            'noisy': False,\n",
      "            'normalize_actions': True,\n",
      "            'num_atoms': 1,\n",
      "            'num_consecutive_worker_failures_tolerance': 100,\n",
      "            'num_cpus_for_driver': 1,\n",
      "            'num_cpus_per_worker': 1,\n",
      "            'num_envs_per_worker': 1,\n",
      "            'num_gpus': 0,\n",
      "            'num_gpus_per_worker': 0,\n",
      "            'num_workers': 0,\n",
      "            'observation_filter': 'NoFilter',\n",
      "            'observation_space': None,\n",
      "            'off_policy_estimation_methods': {},\n",
      "            'optimizer': {},\n",
      "            'output': None,\n",
      "            'output_compress_columns': ['obs', 'new_obs'],\n",
      "            'output_config': {},\n",
      "            'output_max_file_size': 67108864,\n",
      "            'placement_strategy': 'PACK',\n",
      "            'postprocess_inputs': False,\n",
      "            'preprocessor_pref': 'deepmind',\n",
      "            'prioritized_replay': -1,\n",
      "            'prioritized_replay_alpha': -1,\n",
      "            'prioritized_replay_beta': -1,\n",
      "            'prioritized_replay_eps': -1,\n",
      "            'recreate_failed_workers': False,\n",
      "            'remote_env_batch_wait_ms': 0,\n",
      "            'remote_worker_envs': False,\n",
      "            'render_env': False,\n",
      "            'replay_batch_size': -1,\n",
      "            'replay_buffer_config': {'capacity': 50000,\n",
      "                                     'prioritized_replay': -1,\n",
      "                                     'prioritized_replay_alpha': 0.6,\n",
      "                                     'prioritized_replay_beta': 0.4,\n",
      "                                     'prioritized_replay_eps': 1e-06,\n",
      "                                     'replay_mode': 'independent',\n",
      "                                     'replay_sequence_length': 1,\n",
      "                                     'type': <class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>,\n",
      "                                     'worker_side_prioritization': False},\n",
      "            'replay_sequence_length': None,\n",
      "            'restart_failed_sub_environments': False,\n",
      "            'rollout_fragment_length': 4,\n",
      "            'sample_async': False,\n",
      "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      "            'sampler_perf_stats_ema_coef': None,\n",
      "            'seed': None,\n",
      "            'shuffle_buffer_size': 0,\n",
      "            'sigma0': 0.5,\n",
      "            'simple_optimizer': False,\n",
      "            'soft_horizon': False,\n",
      "            'store_buffer_in_checkpoints': False,\n",
      "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
      "            'synchronize_filters': True,\n",
      "            'target_network_update_freq': 500,\n",
      "            'tf_session_args': {'allow_soft_placement': True,\n",
      "                                'device_count': {'CPU': 1},\n",
      "                                'gpu_options': {'allow_growth': True},\n",
      "                                'inter_op_parallelism_threads': 2,\n",
      "                                'intra_op_parallelism_threads': 2,\n",
      "                                'log_device_placement': False},\n",
      "            'timesteps_per_iteration': -1,\n",
      "            'train_batch_size': 32,\n",
      "            'training_intensity': None,\n",
      "            'v_max': 10.0,\n",
      "            'v_min': -10.0,\n",
      "            'validate_workers_after_construction': True},\n",
      " 'counters': {'last_target_update_ts': 1000,\n",
      "              'num_agent_steps_sampled': 1000,\n",
      "              'num_agent_steps_trained': 32,\n",
      "              'num_env_steps_sampled': 1000,\n",
      "              'num_env_steps_trained': 32,\n",
      "              'num_target_updates': 1},\n",
      " 'custom_metrics': {},\n",
      " 'date': '2022-09-14_13-51-37',\n",
      " 'done': True,\n",
      " 'episode_len_mean': 10.0,\n",
      " 'episode_media': {},\n",
      " 'episode_reward_max': 148.70485027849423,\n",
      " 'episode_reward_mean': 104.51659080890425,\n",
      " 'episode_reward_min': 47.787271093477614,\n",
      " 'episodes_this_iter': 100,\n",
      " 'episodes_total': 100,\n",
      " 'experiment_id': '7c127f8ed2524900a50a94bc521402c0',\n",
      " 'experiment_tag': '0',\n",
      " 'hist_stats': {'episode_lengths': [10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10],\n",
      "                'episode_reward': [47.787271093477614,\n",
      "                                   91.23871636785044,\n",
      "                                   98.31720690642426,\n",
      "                                   80.34252043394243,\n",
      "                                   70.73738092218053,\n",
      "                                   93.74084557014595,\n",
      "                                   81.02369588290227,\n",
      "                                   107.63328530378557,\n",
      "                                   95.39813485267685,\n",
      "                                   68.17310018000184,\n",
      "                                   127.43627851064811,\n",
      "                                   113.45005750102077,\n",
      "                                   80.08796222106687,\n",
      "                                   103.20697227924104,\n",
      "                                   89.46643317189782,\n",
      "                                   125.98427276566609,\n",
      "                                   65.02665408162662,\n",
      "                                   107.86614048060845,\n",
      "                                   90.55675136336188,\n",
      "                                   148.70485027849423,\n",
      "                                   111.21443007155533,\n",
      "                                   62.691814149433455,\n",
      "                                   131.48845679908862,\n",
      "                                   131.8807377087847,\n",
      "                                   83.96646919516564,\n",
      "                                   96.12486068375415,\n",
      "                                   87.20456042543874,\n",
      "                                   119.36880777777515,\n",
      "                                   80.92531710024045,\n",
      "                                   114.22300879203691,\n",
      "                                   120.45421442927929,\n",
      "                                   104.7287757391915,\n",
      "                                   56.730080846371195,\n",
      "                                   101.65787901138691,\n",
      "                                   103.31737328841844,\n",
      "                                   92.23891255989929,\n",
      "                                   134.10180901679348,\n",
      "                                   81.59855237810723,\n",
      "                                   132.01040476617007,\n",
      "                                   106.13074488011414,\n",
      "                                   84.37478916042666,\n",
      "                                   131.64102422169347,\n",
      "                                   118.80328590379906,\n",
      "                                   77.35145754847994,\n",
      "                                   122.33322702822161,\n",
      "                                   137.4700378721568,\n",
      "                                   117.34823769008194,\n",
      "                                   117.78915237933242,\n",
      "                                   110.65687249444363,\n",
      "                                   121.69154310718297,\n",
      "                                   70.3467398684753,\n",
      "                                   142.4229611211825,\n",
      "                                   127.14604514981967,\n",
      "                                   102.31742208923303,\n",
      "                                   106.07369756218573,\n",
      "                                   104.36853050456754,\n",
      "                                   122.33628838176097,\n",
      "                                   125.59349357551072,\n",
      "                                   83.70655507094641,\n",
      "                                   112.26781648991036,\n",
      "                                   109.06296456487995,\n",
      "                                   49.64343767679563,\n",
      "                                   101.31067094480039,\n",
      "                                   126.25235033417607,\n",
      "                                   119.90658463795465,\n",
      "                                   105.28369127847542,\n",
      "                                   101.47817112482836,\n",
      "                                   110.02610756452607,\n",
      "                                   104.56731566151555,\n",
      "                                   139.49377519774754,\n",
      "                                   108.7219576154429,\n",
      "                                   85.63781668263142,\n",
      "                                   109.21169508726311,\n",
      "                                   123.72972197360647,\n",
      "                                   96.54728885609413,\n",
      "                                   95.40626438942678,\n",
      "                                   109.8038844918646,\n",
      "                                   96.07209604800646,\n",
      "                                   100.33660548939793,\n",
      "                                   122.39753836781283,\n",
      "                                   108.54161596700298,\n",
      "                                   99.78017586842553,\n",
      "                                   71.20215550945696,\n",
      "                                   105.81750636664613,\n",
      "                                   144.86174833114302,\n",
      "                                   118.17045602457283,\n",
      "                                   120.66467425380617,\n",
      "                                   140.98676313217692,\n",
      "                                   99.85699709691418,\n",
      "                                   70.0308158266632,\n",
      "                                   132.1445962002779,\n",
      "                                   107.2373703877544,\n",
      "                                   115.78327357542688,\n",
      "                                   87.43501381197724,\n",
      "                                   120.41608469223443,\n",
      "                                   71.68609245395348,\n",
      "                                   121.46568565048784,\n",
      "                                   101.58798531809263,\n",
      "                                   114.35821364636763,\n",
      "                                   110.46700178436413]},\n",
      " 'hostname': 'Kouroshs-MacBook-Pro-13',\n",
      " 'info': {'last_target_update_ts': 1000,\n",
      "          'learner': {'default_policy': {'custom_metrics': {},\n",
      "                                         'learner_stats': {'allreduce_latency': 0.0,\n",
      "                                                           'cur_lr': 0.0005,\n",
      "                                                           'grad_gnorm': 40.0,\n",
      "                                                           'max_q': 0.34848907589912415,\n",
      "                                                           'mean_q': -0.573158860206604,\n",
      "                                                           'min_q': -1.5805246829986572},\n",
      "                                         'mean_td_error': -8.816120147705078,\n",
      "                                         'model': {},\n",
      "                                         'num_agent_steps_trained': 32.0,\n",
      "                                         'td_error': array([-27.696688  ,  -4.5589113 ,  -1.6549325 , -10.772258  ,\n",
      "       -30.34419   , -13.062778  ,  -1.5288293 ,  -6.828502  ,\n",
      "        -0.82211924,  -1.2460825 , -31.463614  ,  -1.9326226 ,\n",
      "        -1.8079125 ,  -5.2933044 , -16.601727  , -35.865265  ,\n",
      "        -1.7130884 , -11.753197  ,  -2.1273031 ,  -3.0780764 ,\n",
      "        -7.419411  ,  -2.3247716 ,  -1.5285397 ,  -1.8679203 ,\n",
      "       -25.061378  ,  -1.6382108 , -11.54652   ,  -2.0100856 ,\n",
      "        -2.603752  ,  -6.747956  ,  -5.233675  ,  -3.982195  ],\n",
      "      dtype=float32)}},\n",
      "          'num_agent_steps_sampled': 1000,\n",
      "          'num_agent_steps_trained': 32,\n",
      "          'num_env_steps_sampled': 1000,\n",
      "          'num_env_steps_trained': 32,\n",
      "          'num_target_updates': 1},\n",
      " 'iterations_since_restore': 1,\n",
      " 'node_ip': '127.0.0.1',\n",
      " 'num_agent_steps_sampled': 1000,\n",
      " 'num_agent_steps_trained': 32,\n",
      " 'num_env_steps_sampled': 1000,\n",
      " 'num_env_steps_sampled_this_iter': 1000,\n",
      " 'num_env_steps_trained': 32,\n",
      " 'num_env_steps_trained_this_iter': 32,\n",
      " 'num_faulty_episodes': 0,\n",
      " 'num_healthy_workers': 0,\n",
      " 'num_recreated_workers': 0,\n",
      " 'num_steps_trained_this_iter': 32,\n",
      " 'perf': {'cpu_util_percent': 56.23333333333333,\n",
      "          'ram_util_percent': 83.16666666666667},\n",
      " 'pid': 85528,\n",
      " 'policy_reward_max': {},\n",
      " 'policy_reward_mean': {},\n",
      " 'policy_reward_min': {},\n",
      " 'sampler_perf': {'mean_action_processing_ms': 0.030349184583117073,\n",
      "                  'mean_env_render_ms': 0.0,\n",
      "                  'mean_env_wait_ms': 0.19970926252397503,\n",
      "                  'mean_inference_ms': 0.7152173902604964,\n",
      "                  'mean_raw_obs_processing_ms': 0.8663969201879665},\n",
      " 'sampler_results': {'custom_metrics': {},\n",
      "                     'episode_len_mean': 10.0,\n",
      "                     'episode_media': {},\n",
      "                     'episode_reward_max': 148.70485027849423,\n",
      "                     'episode_reward_mean': 104.51659080890425,\n",
      "                     'episode_reward_min': 47.787271093477614,\n",
      "                     'episodes_this_iter': 100,\n",
      "                     'hist_stats': {'episode_lengths': [10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10],\n",
      "                                    'episode_reward': [47.787271093477614,\n",
      "                                                       91.23871636785044,\n",
      "                                                       98.31720690642426,\n",
      "                                                       80.34252043394243,\n",
      "                                                       70.73738092218053,\n",
      "                                                       93.74084557014595,\n",
      "                                                       81.02369588290227,\n",
      "                                                       107.63328530378557,\n",
      "                                                       95.39813485267685,\n",
      "                                                       68.17310018000184,\n",
      "                                                       127.43627851064811,\n",
      "                                                       113.45005750102077,\n",
      "                                                       80.08796222106687,\n",
      "                                                       103.20697227924104,\n",
      "                                                       89.46643317189782,\n",
      "                                                       125.98427276566609,\n",
      "                                                       65.02665408162662,\n",
      "                                                       107.86614048060845,\n",
      "                                                       90.55675136336188,\n",
      "                                                       148.70485027849423,\n",
      "                                                       111.21443007155533,\n",
      "                                                       62.691814149433455,\n",
      "                                                       131.48845679908862,\n",
      "                                                       131.8807377087847,\n",
      "                                                       83.96646919516564,\n",
      "                                                       96.12486068375415,\n",
      "                                                       87.20456042543874,\n",
      "                                                       119.36880777777515,\n",
      "                                                       80.92531710024045,\n",
      "                                                       114.22300879203691,\n",
      "                                                       120.45421442927929,\n",
      "                                                       104.7287757391915,\n",
      "                                                       56.730080846371195,\n",
      "                                                       101.65787901138691,\n",
      "                                                       103.31737328841844,\n",
      "                                                       92.23891255989929,\n",
      "                                                       134.10180901679348,\n",
      "                                                       81.59855237810723,\n",
      "                                                       132.01040476617007,\n",
      "                                                       106.13074488011414,\n",
      "                                                       84.37478916042666,\n",
      "                                                       131.64102422169347,\n",
      "                                                       118.80328590379906,\n",
      "                                                       77.35145754847994,\n",
      "                                                       122.33322702822161,\n",
      "                                                       137.4700378721568,\n",
      "                                                       117.34823769008194,\n",
      "                                                       117.78915237933242,\n",
      "                                                       110.65687249444363,\n",
      "                                                       121.69154310718297,\n",
      "                                                       70.3467398684753,\n",
      "                                                       142.4229611211825,\n",
      "                                                       127.14604514981967,\n",
      "                                                       102.31742208923303,\n",
      "                                                       106.07369756218573,\n",
      "                                                       104.36853050456754,\n",
      "                                                       122.33628838176097,\n",
      "                                                       125.59349357551072,\n",
      "                                                       83.70655507094641,\n",
      "                                                       112.26781648991036,\n",
      "                                                       109.06296456487995,\n",
      "                                                       49.64343767679563,\n",
      "                                                       101.31067094480039,\n",
      "                                                       126.25235033417607,\n",
      "                                                       119.90658463795465,\n",
      "                                                       105.28369127847542,\n",
      "                                                       101.47817112482836,\n",
      "                                                       110.02610756452607,\n",
      "                                                       104.56731566151555,\n",
      "                                                       139.49377519774754,\n",
      "                                                       108.7219576154429,\n",
      "                                                       85.63781668263142,\n",
      "                                                       109.21169508726311,\n",
      "                                                       123.72972197360647,\n",
      "                                                       96.54728885609413,\n",
      "                                                       95.40626438942678,\n",
      "                                                       109.8038844918646,\n",
      "                                                       96.07209604800646,\n",
      "                                                       100.33660548939793,\n",
      "                                                       122.39753836781283,\n",
      "                                                       108.54161596700298,\n",
      "                                                       99.78017586842553,\n",
      "                                                       71.20215550945696,\n",
      "                                                       105.81750636664613,\n",
      "                                                       144.86174833114302,\n",
      "                                                       118.17045602457283,\n",
      "                                                       120.66467425380617,\n",
      "                                                       140.98676313217692,\n",
      "                                                       99.85699709691418,\n",
      "                                                       70.0308158266632,\n",
      "                                                       132.1445962002779,\n",
      "                                                       107.2373703877544,\n",
      "                                                       115.78327357542688,\n",
      "                                                       87.43501381197724,\n",
      "                                                       120.41608469223443,\n",
      "                                                       71.68609245395348,\n",
      "                                                       121.46568565048784,\n",
      "                                                       101.58798531809263,\n",
      "                                                       114.35821364636763,\n",
      "                                                       110.46700178436413]},\n",
      "                     'num_faulty_episodes': 0,\n",
      "                     'policy_reward_max': {},\n",
      "                     'policy_reward_mean': {},\n",
      "                     'policy_reward_min': {},\n",
      "                     'sampler_perf': {'mean_action_processing_ms': 0.030349184583117073,\n",
      "                                      'mean_env_render_ms': 0.0,\n",
      "                                      'mean_env_wait_ms': 0.19970926252397503,\n",
      "                                      'mean_inference_ms': 0.7152173902604964,\n",
      "                                      'mean_raw_obs_processing_ms': 0.8663969201879665}},\n",
      " 'time_since_restore': 1.9517138004302979,\n",
      " 'time_this_iter_s': 1.9517138004302979,\n",
      " 'time_total_s': 1.9517138004302979,\n",
      " 'timers': {'learn_throughput': 7764.983,\n",
      "            'learn_time_ms': 4.121,\n",
      "            'load_throughput': 438620.026,\n",
      "            'load_time_ms': 0.073,\n",
      "            'synch_weights_time_ms': 0.013,\n",
      "            'training_iteration_time_ms': 7.023},\n",
      " 'timestamp': 1663188697,\n",
      " 'timesteps_since_restore': 0,\n",
      " 'timesteps_total': 1000,\n",
      " 'training_iteration': 1,\n",
      " 'trial_id': 'fddb1_00000',\n",
      " 'warmup_time': 0.045000314712524414}\n"
     ]
    }
   ],
   "source": [
    "pprint(results_bandit[0].metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune collects these results from every iteration and puts them in the output directory where the other logging artifcats are stored. \n",
    "\n",
    "To run this experiment longer until it's trained you can run the following command to launch the bandit experiment:\n",
    "\n",
    "\n",
    "```bash\n",
    "python tutorial_scripts/run_online_rl.py --seed 0 --gamma 0.0 --exp_name bandits --timesteps 10_000\n",
    "```\n",
    "\n",
    "This script take 5 minutes to run. It will create experiment artifacts under `./results_scripts/` which includes the checkpoints as well as tensorboard and tabular logs. You can later inspect this folder to monitor your experiments.\n",
    "\n",
    "The suggested way is to use tensorboard to monitor the metrics of your run and look for `episode_reward_mean`.\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir \"./results_scripts\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_recreated_workers</th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_faulty_episodes</th>\n",
       "      <th>num_healthy_workers</th>\n",
       "      <th>num_agent_steps_sampled</th>\n",
       "      <th>num_agent_steps_trained</th>\n",
       "      <th>...</th>\n",
       "      <th>sampler_results/sampler_perf/mean_env_render_ms</th>\n",
       "      <th>info/learner/default_policy/td_error</th>\n",
       "      <th>info/learner/default_policy/mean_td_error</th>\n",
       "      <th>info/learner/default_policy/num_agent_steps_trained</th>\n",
       "      <th>info/learner/default_policy/learner_stats/allreduce_latency</th>\n",
       "      <th>info/learner/default_policy/learner_stats/grad_gnorm</th>\n",
       "      <th>info/learner/default_policy/learner_stats/mean_q</th>\n",
       "      <th>info/learner/default_policy/learner_stats/min_q</th>\n",
       "      <th>info/learner/default_policy/learner_stats/max_q</th>\n",
       "      <th>info/learner/default_policy/learner_stats/cur_lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>148.857003</td>\n",
       "      <td>49.961654</td>\n",
       "      <td>99.196947</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[  0.08130693 -32.68208     -1.0544746  ... -1...</td>\n",
       "      <td>-9.532643</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.246236</td>\n",
       "      <td>-15.835198</td>\n",
       "      <td>12.509801</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>164.508217</td>\n",
       "      <td>47.330177</td>\n",
       "      <td>90.888174</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>103424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ -1.8469124  16.100851    9.935776  ...  -1.9...</td>\n",
       "      <td>-0.777455</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.398451</td>\n",
       "      <td>18.016447</td>\n",
       "      <td>-0.041102</td>\n",
       "      <td>34.083656</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>138.941288</td>\n",
       "      <td>49.432686</td>\n",
       "      <td>90.029635</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>205824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-44.404617   10.898367   -6.5983086 ...   0.6...</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.137737</td>\n",
       "      <td>18.794142</td>\n",
       "      <td>0.265299</td>\n",
       "      <td>37.528831</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>134.897282</td>\n",
       "      <td>48.772781</td>\n",
       "      <td>84.447781</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>308224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[  5.808758  -7.011381  15.66174  ...  19.2326...</td>\n",
       "      <td>1.042608</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.974737</td>\n",
       "      <td>18.521561</td>\n",
       "      <td>-0.137503</td>\n",
       "      <td>43.737011</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>132.915997</td>\n",
       "      <td>50.388054</td>\n",
       "      <td>79.881542</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>410624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-9.4627047e-01  1.3871456e+01  2.1535740e+01 ...</td>\n",
       "      <td>-1.572562</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.103477</td>\n",
       "      <td>16.533539</td>\n",
       "      <td>0.174857</td>\n",
       "      <td>41.704906</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>129.994191</td>\n",
       "      <td>45.816119</td>\n",
       "      <td>72.226485</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6000</td>\n",
       "      <td>513024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ -0.88962173  -1.2075796    4.9222107  ...   ...</td>\n",
       "      <td>-0.332741</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.404050</td>\n",
       "      <td>15.443865</td>\n",
       "      <td>0.233130</td>\n",
       "      <td>40.797157</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>127.072062</td>\n",
       "      <td>45.225444</td>\n",
       "      <td>68.567125</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7000</td>\n",
       "      <td>615424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.24402452  1.4774995   0.76649    ... 11.97...</td>\n",
       "      <td>-4.165147</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.414696</td>\n",
       "      <td>13.171873</td>\n",
       "      <td>0.276638</td>\n",
       "      <td>38.906605</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>118.294968</td>\n",
       "      <td>45.378952</td>\n",
       "      <td>63.249971</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>717824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 10.909027     7.082692     7.3703156  ... -1...</td>\n",
       "      <td>-1.795620</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.062077</td>\n",
       "      <td>14.493250</td>\n",
       "      <td>0.279899</td>\n",
       "      <td>43.621899</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>90.902905</td>\n",
       "      <td>46.080421</td>\n",
       "      <td>56.779350</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9000</td>\n",
       "      <td>820224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 14.707781     0.06545544 -13.176308   ...  1...</td>\n",
       "      <td>-0.146196</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.508381</td>\n",
       "      <td>14.477367</td>\n",
       "      <td>0.231801</td>\n",
       "      <td>43.665577</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>76.037433</td>\n",
       "      <td>45.661611</td>\n",
       "      <td>53.756603</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>922624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[  3.4783533  -2.6205335   0.9006934 ...   6.8...</td>\n",
       "      <td>-0.587912</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.168987</td>\n",
       "      <td>12.877733</td>\n",
       "      <td>0.679283</td>\n",
       "      <td>45.145042</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>72.217257</td>\n",
       "      <td>45.581448</td>\n",
       "      <td>52.690020</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11000</td>\n",
       "      <td>1025024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ -9.01165    -4.159134   -7.916232  ... -56.3...</td>\n",
       "      <td>-1.149156</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.654643</td>\n",
       "      <td>12.171491</td>\n",
       "      <td>-1.379480</td>\n",
       "      <td>41.205154</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>71.728065</td>\n",
       "      <td>45.669041</td>\n",
       "      <td>53.213761</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12000</td>\n",
       "      <td>1127424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 0.67962384 -0.06494701  8.85545    ...  7.55...</td>\n",
       "      <td>0.737157</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.270066</td>\n",
       "      <td>13.855407</td>\n",
       "      <td>0.684018</td>\n",
       "      <td>45.224060</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>64.735608</td>\n",
       "      <td>47.113025</td>\n",
       "      <td>53.270334</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13000</td>\n",
       "      <td>1229824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ -0.25348127 -41.574276     1.922559   ...   ...</td>\n",
       "      <td>-1.183170</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.113058</td>\n",
       "      <td>11.615423</td>\n",
       "      <td>0.717183</td>\n",
       "      <td>46.346764</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>69.982044</td>\n",
       "      <td>45.688028</td>\n",
       "      <td>54.442020</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14000</td>\n",
       "      <td>1332224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[  4.874438   -1.8305607   0.8711748 ...  11.2...</td>\n",
       "      <td>1.586377</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.374706</td>\n",
       "      <td>13.939721</td>\n",
       "      <td>-0.065624</td>\n",
       "      <td>49.871910</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>81.209531</td>\n",
       "      <td>46.685566</td>\n",
       "      <td>55.272741</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15000</td>\n",
       "      <td>1434624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[  5.5722904    1.2895355    7.466584   ...   ...</td>\n",
       "      <td>0.034017</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.554944</td>\n",
       "      <td>11.629099</td>\n",
       "      <td>0.502012</td>\n",
       "      <td>48.686363</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>76.663782</td>\n",
       "      <td>46.840776</td>\n",
       "      <td>55.652827</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16000</td>\n",
       "      <td>1537024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.6556758  1.8287566  7.954074   ... 0.091212...</td>\n",
       "      <td>-1.998481</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.724813</td>\n",
       "      <td>10.662794</td>\n",
       "      <td>0.068202</td>\n",
       "      <td>48.045498</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>80.066623</td>\n",
       "      <td>46.759041</td>\n",
       "      <td>55.524876</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17000</td>\n",
       "      <td>1639424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 5.1050148e+00 -4.5107603e-03  2.3342848e+00 ...</td>\n",
       "      <td>-0.067832</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.850351</td>\n",
       "      <td>11.697859</td>\n",
       "      <td>0.068989</td>\n",
       "      <td>47.437889</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>83.177342</td>\n",
       "      <td>46.210138</td>\n",
       "      <td>55.979137</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18000</td>\n",
       "      <td>1741824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.27483177 -2.0096369   3.9182355  ... 13.74...</td>\n",
       "      <td>-0.787489</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.450926</td>\n",
       "      <td>10.381654</td>\n",
       "      <td>-0.470145</td>\n",
       "      <td>45.642307</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>83.457536</td>\n",
       "      <td>48.233616</td>\n",
       "      <td>55.420597</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19000</td>\n",
       "      <td>1844224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ -4.248621     0.43227804   0.47565675 ...   ...</td>\n",
       "      <td>-0.855444</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.483238</td>\n",
       "      <td>10.545372</td>\n",
       "      <td>-0.389024</td>\n",
       "      <td>43.713223</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>83.255427</td>\n",
       "      <td>48.235632</td>\n",
       "      <td>56.286730</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>1946624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ -1.8522081   8.499422   12.197313  ... -22.8...</td>\n",
       "      <td>-0.151320</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.730842</td>\n",
       "      <td>11.557020</td>\n",
       "      <td>-0.834266</td>\n",
       "      <td>51.538326</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>78.097271</td>\n",
       "      <td>50.361330</td>\n",
       "      <td>56.001785</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21000</td>\n",
       "      <td>2049024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 10.179953  -35.008896    1.4445977 ...  -0.6...</td>\n",
       "      <td>-1.499709</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.761689</td>\n",
       "      <td>9.655149</td>\n",
       "      <td>-0.673707</td>\n",
       "      <td>48.022087</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>69.834134</td>\n",
       "      <td>50.026480</td>\n",
       "      <td>55.676211</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22000</td>\n",
       "      <td>2151424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-13.676615    3.7126598   3.6381688 ...  -2.9...</td>\n",
       "      <td>0.107176</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.866289</td>\n",
       "      <td>11.053155</td>\n",
       "      <td>-0.265543</td>\n",
       "      <td>51.361637</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>69.779297</td>\n",
       "      <td>47.887541</td>\n",
       "      <td>55.732795</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "      <td>2253824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[  1.35921      2.6271968    1.5852265  ... -3...</td>\n",
       "      <td>-0.672244</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.359235</td>\n",
       "      <td>9.856972</td>\n",
       "      <td>-0.917923</td>\n",
       "      <td>53.659718</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>87.564845</td>\n",
       "      <td>49.901360</td>\n",
       "      <td>55.815580</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24000</td>\n",
       "      <td>2356224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[  1.2033621    1.2829072   -0.677117   ...   ...</td>\n",
       "      <td>-1.078374</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.771350</td>\n",
       "      <td>9.904694</td>\n",
       "      <td>-1.135212</td>\n",
       "      <td>53.830666</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>80.641988</td>\n",
       "      <td>48.200624</td>\n",
       "      <td>55.970355</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25000</td>\n",
       "      <td>2458624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[  0.458153    -0.17178726 -36.4488     ...  -...</td>\n",
       "      <td>-1.186148</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.457865</td>\n",
       "      <td>9.349145</td>\n",
       "      <td>-1.221530</td>\n",
       "      <td>49.153381</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>66.837071</td>\n",
       "      <td>48.383122</td>\n",
       "      <td>56.388415</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26000</td>\n",
       "      <td>2561024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.25758052 -2.7192278  -1.5600634  ...  4.93...</td>\n",
       "      <td>-1.130995</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.919761</td>\n",
       "      <td>9.352964</td>\n",
       "      <td>-0.232620</td>\n",
       "      <td>57.947506</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>68.038177</td>\n",
       "      <td>46.937752</td>\n",
       "      <td>56.108121</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27000</td>\n",
       "      <td>2663424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.9596062   2.6285806  -5.882188   ... -0.19...</td>\n",
       "      <td>-0.147397</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.622108</td>\n",
       "      <td>10.668340</td>\n",
       "      <td>-0.337734</td>\n",
       "      <td>55.037617</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>75.161622</td>\n",
       "      <td>49.545237</td>\n",
       "      <td>56.459821</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28000</td>\n",
       "      <td>2765824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 0.1741389  1.5327911 -1.0859172 ... -1.22349...</td>\n",
       "      <td>-1.422228</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.494023</td>\n",
       "      <td>9.330950</td>\n",
       "      <td>-1.169915</td>\n",
       "      <td>59.358978</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>73.924277</td>\n",
       "      <td>46.770882</td>\n",
       "      <td>56.621147</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29000</td>\n",
       "      <td>2868224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.1070708  11.770968    1.1013768  ...  0.69...</td>\n",
       "      <td>-0.537835</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.862209</td>\n",
       "      <td>9.164739</td>\n",
       "      <td>-0.793543</td>\n",
       "      <td>51.203438</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>79.676128</td>\n",
       "      <td>47.809361</td>\n",
       "      <td>56.885386</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30000</td>\n",
       "      <td>2970624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-19.051239    -0.2597494   -4.561411   ...   ...</td>\n",
       "      <td>-0.744182</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.524508</td>\n",
       "      <td>9.503153</td>\n",
       "      <td>-0.756109</td>\n",
       "      <td>59.082062</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>74.124723</td>\n",
       "      <td>49.687368</td>\n",
       "      <td>56.879691</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31000</td>\n",
       "      <td>3073024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.9870031   1.1960202  -0.83932805 ... -0.05...</td>\n",
       "      <td>-1.067708</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.308852</td>\n",
       "      <td>8.738939</td>\n",
       "      <td>-0.853909</td>\n",
       "      <td>47.935421</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>77.098764</td>\n",
       "      <td>49.306325</td>\n",
       "      <td>56.640238</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32000</td>\n",
       "      <td>3175424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 0.27721643  0.82572305 -0.02563262 ... -0.12...</td>\n",
       "      <td>-0.915631</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.364350</td>\n",
       "      <td>9.086431</td>\n",
       "      <td>-1.495298</td>\n",
       "      <td>48.690308</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>73.744758</td>\n",
       "      <td>51.037717</td>\n",
       "      <td>56.508528</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33000</td>\n",
       "      <td>3277824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 0.3802812 -5.7206507 -3.0257072 ...  0.77484...</td>\n",
       "      <td>-0.835654</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.745737</td>\n",
       "      <td>8.793969</td>\n",
       "      <td>-1.177927</td>\n",
       "      <td>53.721397</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>84.006079</td>\n",
       "      <td>47.373085</td>\n",
       "      <td>57.664184</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34000</td>\n",
       "      <td>3380224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 9.174057   1.5938154 -0.9848096 ... -2.02267...</td>\n",
       "      <td>0.102620</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.318543</td>\n",
       "      <td>9.441277</td>\n",
       "      <td>-0.940971</td>\n",
       "      <td>61.828312</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>83.358827</td>\n",
       "      <td>50.269973</td>\n",
       "      <td>56.920761</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35000</td>\n",
       "      <td>3482624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-3.54975128e+00 -5.04954147e+00 -1.25388565e+...</td>\n",
       "      <td>-0.579089</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.206085</td>\n",
       "      <td>8.934761</td>\n",
       "      <td>-0.966193</td>\n",
       "      <td>57.213398</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>86.020155</td>\n",
       "      <td>50.872090</td>\n",
       "      <td>57.445627</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36000</td>\n",
       "      <td>3585024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 2.165514   -0.35741258  5.0310707  ...  6.41...</td>\n",
       "      <td>-0.401935</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.602608</td>\n",
       "      <td>8.920285</td>\n",
       "      <td>-1.046370</td>\n",
       "      <td>62.771378</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>91.433260</td>\n",
       "      <td>49.082687</td>\n",
       "      <td>56.751123</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37000</td>\n",
       "      <td>3687424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 0.8002925  -1.1678371   0.16828537 ... -0.35...</td>\n",
       "      <td>0.204935</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.201797</td>\n",
       "      <td>9.592368</td>\n",
       "      <td>-0.668387</td>\n",
       "      <td>53.017555</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>81.381197</td>\n",
       "      <td>47.514388</td>\n",
       "      <td>56.788419</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38000</td>\n",
       "      <td>3789824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.35526133 -0.53310084  5.10726    ...  0.20...</td>\n",
       "      <td>-0.275301</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.589692</td>\n",
       "      <td>8.851565</td>\n",
       "      <td>-1.153511</td>\n",
       "      <td>61.386543</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>75.313010</td>\n",
       "      <td>48.105326</td>\n",
       "      <td>57.180578</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39000</td>\n",
       "      <td>3892224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 1.1651549   2.6985283  -0.3911749  ... -0.26...</td>\n",
       "      <td>0.182121</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.264544</td>\n",
       "      <td>9.825369</td>\n",
       "      <td>-0.400916</td>\n",
       "      <td>71.046722</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>67.113544</td>\n",
       "      <td>51.299578</td>\n",
       "      <td>57.108286</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40000</td>\n",
       "      <td>3994624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.17662132 -0.56799173  5.411066   ...  0.56...</td>\n",
       "      <td>-0.149961</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.733242</td>\n",
       "      <td>8.341745</td>\n",
       "      <td>-0.592524</td>\n",
       "      <td>60.975723</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>73.489909</td>\n",
       "      <td>47.687303</td>\n",
       "      <td>57.288121</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41000</td>\n",
       "      <td>4097024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 0.8779361 -2.019677  -3.5170097 ...  1.62991...</td>\n",
       "      <td>-0.316527</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.775574</td>\n",
       "      <td>8.734725</td>\n",
       "      <td>-0.950870</td>\n",
       "      <td>65.985733</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>81.772401</td>\n",
       "      <td>49.968129</td>\n",
       "      <td>57.517235</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42000</td>\n",
       "      <td>4199424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ -0.20525122   0.4975767    1.2209172  ...   ...</td>\n",
       "      <td>-0.017954</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.976462</td>\n",
       "      <td>9.450397</td>\n",
       "      <td>-0.941013</td>\n",
       "      <td>71.980942</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>89.218543</td>\n",
       "      <td>48.809527</td>\n",
       "      <td>57.905380</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43000</td>\n",
       "      <td>4301824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 1.1105506   1.1565566   3.1153793  ...  4.83...</td>\n",
       "      <td>0.373318</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.743515</td>\n",
       "      <td>9.289961</td>\n",
       "      <td>-0.841498</td>\n",
       "      <td>67.689224</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>74.767920</td>\n",
       "      <td>50.122718</td>\n",
       "      <td>56.803475</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44000</td>\n",
       "      <td>4404224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 1.9488754   4.3784027  -0.15159988 ...  3.38...</td>\n",
       "      <td>-0.169193</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.696795</td>\n",
       "      <td>9.323828</td>\n",
       "      <td>-0.322785</td>\n",
       "      <td>63.899086</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>82.336357</td>\n",
       "      <td>46.171144</td>\n",
       "      <td>58.107222</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45000</td>\n",
       "      <td>4506624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ -6.3456097  11.481762  -21.673662  ...  -4.9...</td>\n",
       "      <td>-0.942893</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.193322</td>\n",
       "      <td>7.430641</td>\n",
       "      <td>-0.181708</td>\n",
       "      <td>57.474747</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>70.191814</td>\n",
       "      <td>49.483594</td>\n",
       "      <td>57.117635</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46000</td>\n",
       "      <td>4609024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 2.3266788e+00  5.2837276e-01  9.6931458e-03 ...</td>\n",
       "      <td>-0.418834</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.374490</td>\n",
       "      <td>8.198449</td>\n",
       "      <td>-0.830371</td>\n",
       "      <td>64.207275</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>79.684695</td>\n",
       "      <td>51.508729</td>\n",
       "      <td>57.616279</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47000</td>\n",
       "      <td>4711424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.47949243  0.41796613  0.57161784 ...  0.89...</td>\n",
       "      <td>-0.795342</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.282938</td>\n",
       "      <td>8.031837</td>\n",
       "      <td>-0.305132</td>\n",
       "      <td>69.861687</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>72.364893</td>\n",
       "      <td>48.012897</td>\n",
       "      <td>56.892992</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>48000</td>\n",
       "      <td>4813824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 1.5137401   1.1290069   0.7753334  ... -0.71...</td>\n",
       "      <td>-0.403758</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.641539</td>\n",
       "      <td>7.549159</td>\n",
       "      <td>-0.327079</td>\n",
       "      <td>56.245564</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>77.692718</td>\n",
       "      <td>51.513998</td>\n",
       "      <td>57.409537</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49000</td>\n",
       "      <td>4916224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 0.4972546   0.80511796  0.36939752 ... -0.16...</td>\n",
       "      <td>-0.066340</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.894305</td>\n",
       "      <td>8.761932</td>\n",
       "      <td>-0.164048</td>\n",
       "      <td>53.815144</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49 rows  98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_recreated_workers  episode_reward_max  episode_reward_min  \\\n",
       "0                       0          148.857003           49.961654   \n",
       "1                       0          164.508217           47.330177   \n",
       "2                       0          138.941288           49.432686   \n",
       "3                       0          134.897282           48.772781   \n",
       "4                       0          132.915997           50.388054   \n",
       "5                       0          129.994191           45.816119   \n",
       "6                       0          127.072062           45.225444   \n",
       "7                       0          118.294968           45.378952   \n",
       "8                       0           90.902905           46.080421   \n",
       "9                       0           76.037433           45.661611   \n",
       "10                      0           72.217257           45.581448   \n",
       "11                      0           71.728065           45.669041   \n",
       "12                      0           64.735608           47.113025   \n",
       "13                      0           69.982044           45.688028   \n",
       "14                      0           81.209531           46.685566   \n",
       "15                      0           76.663782           46.840776   \n",
       "16                      0           80.066623           46.759041   \n",
       "17                      0           83.177342           46.210138   \n",
       "18                      0           83.457536           48.233616   \n",
       "19                      0           83.255427           48.235632   \n",
       "20                      0           78.097271           50.361330   \n",
       "21                      0           69.834134           50.026480   \n",
       "22                      0           69.779297           47.887541   \n",
       "23                      0           87.564845           49.901360   \n",
       "24                      0           80.641988           48.200624   \n",
       "25                      0           66.837071           48.383122   \n",
       "26                      0           68.038177           46.937752   \n",
       "27                      0           75.161622           49.545237   \n",
       "28                      0           73.924277           46.770882   \n",
       "29                      0           79.676128           47.809361   \n",
       "30                      0           74.124723           49.687368   \n",
       "31                      0           77.098764           49.306325   \n",
       "32                      0           73.744758           51.037717   \n",
       "33                      0           84.006079           47.373085   \n",
       "34                      0           83.358827           50.269973   \n",
       "35                      0           86.020155           50.872090   \n",
       "36                      0           91.433260           49.082687   \n",
       "37                      0           81.381197           47.514388   \n",
       "38                      0           75.313010           48.105326   \n",
       "39                      0           67.113544           51.299578   \n",
       "40                      0           73.489909           47.687303   \n",
       "41                      0           81.772401           49.968129   \n",
       "42                      0           89.218543           48.809527   \n",
       "43                      0           74.767920           50.122718   \n",
       "44                      0           82.336357           46.171144   \n",
       "45                      0           70.191814           49.483594   \n",
       "46                      0           79.684695           51.508729   \n",
       "47                      0           72.364893           48.012897   \n",
       "48                      0           77.692718           51.513998   \n",
       "\n",
       "    episode_reward_mean  episode_len_mean  episodes_this_iter  \\\n",
       "0             99.196947              10.0                 100   \n",
       "1             90.888174              10.0                 100   \n",
       "2             90.029635              10.0                 100   \n",
       "3             84.447781              10.0                 100   \n",
       "4             79.881542              10.0                 100   \n",
       "5             72.226485              10.0                 100   \n",
       "6             68.567125              10.0                 100   \n",
       "7             63.249971              10.0                 100   \n",
       "8             56.779350              10.0                 100   \n",
       "9             53.756603              10.0                 100   \n",
       "10            52.690020              10.0                 100   \n",
       "11            53.213761              10.0                 100   \n",
       "12            53.270334              10.0                 100   \n",
       "13            54.442020              10.0                 100   \n",
       "14            55.272741              10.0                 100   \n",
       "15            55.652827              10.0                 100   \n",
       "16            55.524876              10.0                 100   \n",
       "17            55.979137              10.0                 100   \n",
       "18            55.420597              10.0                 100   \n",
       "19            56.286730              10.0                 100   \n",
       "20            56.001785              10.0                 100   \n",
       "21            55.676211              10.0                 100   \n",
       "22            55.732795              10.0                 100   \n",
       "23            55.815580              10.0                 100   \n",
       "24            55.970355              10.0                 100   \n",
       "25            56.388415              10.0                 100   \n",
       "26            56.108121              10.0                 100   \n",
       "27            56.459821              10.0                 100   \n",
       "28            56.621147              10.0                 100   \n",
       "29            56.885386              10.0                 100   \n",
       "30            56.879691              10.0                 100   \n",
       "31            56.640238              10.0                 100   \n",
       "32            56.508528              10.0                 100   \n",
       "33            57.664184              10.0                 100   \n",
       "34            56.920761              10.0                 100   \n",
       "35            57.445627              10.0                 100   \n",
       "36            56.751123              10.0                 100   \n",
       "37            56.788419              10.0                 100   \n",
       "38            57.180578              10.0                 100   \n",
       "39            57.108286              10.0                 100   \n",
       "40            57.288121              10.0                 100   \n",
       "41            57.517235              10.0                 100   \n",
       "42            57.905380              10.0                 100   \n",
       "43            56.803475              10.0                 100   \n",
       "44            58.107222              10.0                 100   \n",
       "45            57.117635              10.0                 100   \n",
       "46            57.616279              10.0                 100   \n",
       "47            56.892992              10.0                 100   \n",
       "48            57.409537              10.0                 100   \n",
       "\n",
       "    num_faulty_episodes  num_healthy_workers  num_agent_steps_sampled  \\\n",
       "0                     0                    1                     1000   \n",
       "1                     0                    1                     2000   \n",
       "2                     0                    1                     3000   \n",
       "3                     0                    1                     4000   \n",
       "4                     0                    1                     5000   \n",
       "5                     0                    1                     6000   \n",
       "6                     0                    1                     7000   \n",
       "7                     0                    1                     8000   \n",
       "8                     0                    1                     9000   \n",
       "9                     0                    1                    10000   \n",
       "10                    0                    1                    11000   \n",
       "11                    0                    1                    12000   \n",
       "12                    0                    1                    13000   \n",
       "13                    0                    1                    14000   \n",
       "14                    0                    1                    15000   \n",
       "15                    0                    1                    16000   \n",
       "16                    0                    1                    17000   \n",
       "17                    0                    1                    18000   \n",
       "18                    0                    1                    19000   \n",
       "19                    0                    1                    20000   \n",
       "20                    0                    1                    21000   \n",
       "21                    0                    1                    22000   \n",
       "22                    0                    1                    23000   \n",
       "23                    0                    1                    24000   \n",
       "24                    0                    1                    25000   \n",
       "25                    0                    1                    26000   \n",
       "26                    0                    1                    27000   \n",
       "27                    0                    1                    28000   \n",
       "28                    0                    1                    29000   \n",
       "29                    0                    1                    30000   \n",
       "30                    0                    1                    31000   \n",
       "31                    0                    1                    32000   \n",
       "32                    0                    1                    33000   \n",
       "33                    0                    1                    34000   \n",
       "34                    0                    1                    35000   \n",
       "35                    0                    1                    36000   \n",
       "36                    0                    1                    37000   \n",
       "37                    0                    1                    38000   \n",
       "38                    0                    1                    39000   \n",
       "39                    0                    1                    40000   \n",
       "40                    0                    1                    41000   \n",
       "41                    0                    1                    42000   \n",
       "42                    0                    1                    43000   \n",
       "43                    0                    1                    44000   \n",
       "44                    0                    1                    45000   \n",
       "45                    0                    1                    46000   \n",
       "46                    0                    1                    47000   \n",
       "47                    0                    1                    48000   \n",
       "48                    0                    1                    49000   \n",
       "\n",
       "    num_agent_steps_trained  ...  \\\n",
       "0                      1024  ...   \n",
       "1                    103424  ...   \n",
       "2                    205824  ...   \n",
       "3                    308224  ...   \n",
       "4                    410624  ...   \n",
       "5                    513024  ...   \n",
       "6                    615424  ...   \n",
       "7                    717824  ...   \n",
       "8                    820224  ...   \n",
       "9                    922624  ...   \n",
       "10                  1025024  ...   \n",
       "11                  1127424  ...   \n",
       "12                  1229824  ...   \n",
       "13                  1332224  ...   \n",
       "14                  1434624  ...   \n",
       "15                  1537024  ...   \n",
       "16                  1639424  ...   \n",
       "17                  1741824  ...   \n",
       "18                  1844224  ...   \n",
       "19                  1946624  ...   \n",
       "20                  2049024  ...   \n",
       "21                  2151424  ...   \n",
       "22                  2253824  ...   \n",
       "23                  2356224  ...   \n",
       "24                  2458624  ...   \n",
       "25                  2561024  ...   \n",
       "26                  2663424  ...   \n",
       "27                  2765824  ...   \n",
       "28                  2868224  ...   \n",
       "29                  2970624  ...   \n",
       "30                  3073024  ...   \n",
       "31                  3175424  ...   \n",
       "32                  3277824  ...   \n",
       "33                  3380224  ...   \n",
       "34                  3482624  ...   \n",
       "35                  3585024  ...   \n",
       "36                  3687424  ...   \n",
       "37                  3789824  ...   \n",
       "38                  3892224  ...   \n",
       "39                  3994624  ...   \n",
       "40                  4097024  ...   \n",
       "41                  4199424  ...   \n",
       "42                  4301824  ...   \n",
       "43                  4404224  ...   \n",
       "44                  4506624  ...   \n",
       "45                  4609024  ...   \n",
       "46                  4711424  ...   \n",
       "47                  4813824  ...   \n",
       "48                  4916224  ...   \n",
       "\n",
       "    sampler_results/sampler_perf/mean_env_render_ms  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                               0.0   \n",
       "3                                               0.0   \n",
       "4                                               0.0   \n",
       "5                                               0.0   \n",
       "6                                               0.0   \n",
       "7                                               0.0   \n",
       "8                                               0.0   \n",
       "9                                               0.0   \n",
       "10                                              0.0   \n",
       "11                                              0.0   \n",
       "12                                              0.0   \n",
       "13                                              0.0   \n",
       "14                                              0.0   \n",
       "15                                              0.0   \n",
       "16                                              0.0   \n",
       "17                                              0.0   \n",
       "18                                              0.0   \n",
       "19                                              0.0   \n",
       "20                                              0.0   \n",
       "21                                              0.0   \n",
       "22                                              0.0   \n",
       "23                                              0.0   \n",
       "24                                              0.0   \n",
       "25                                              0.0   \n",
       "26                                              0.0   \n",
       "27                                              0.0   \n",
       "28                                              0.0   \n",
       "29                                              0.0   \n",
       "30                                              0.0   \n",
       "31                                              0.0   \n",
       "32                                              0.0   \n",
       "33                                              0.0   \n",
       "34                                              0.0   \n",
       "35                                              0.0   \n",
       "36                                              0.0   \n",
       "37                                              0.0   \n",
       "38                                              0.0   \n",
       "39                                              0.0   \n",
       "40                                              0.0   \n",
       "41                                              0.0   \n",
       "42                                              0.0   \n",
       "43                                              0.0   \n",
       "44                                              0.0   \n",
       "45                                              0.0   \n",
       "46                                              0.0   \n",
       "47                                              0.0   \n",
       "48                                              0.0   \n",
       "\n",
       "                 info/learner/default_policy/td_error  \\\n",
       "0   [  0.08130693 -32.68208     -1.0544746  ... -1...   \n",
       "1   [ -1.8469124  16.100851    9.935776  ...  -1.9...   \n",
       "2   [-44.404617   10.898367   -6.5983086 ...   0.6...   \n",
       "3   [  5.808758  -7.011381  15.66174  ...  19.2326...   \n",
       "4   [-9.4627047e-01  1.3871456e+01  2.1535740e+01 ...   \n",
       "5   [ -0.88962173  -1.2075796    4.9222107  ...   ...   \n",
       "6   [-0.24402452  1.4774995   0.76649    ... 11.97...   \n",
       "7   [ 10.909027     7.082692     7.3703156  ... -1...   \n",
       "8   [ 14.707781     0.06545544 -13.176308   ...  1...   \n",
       "9   [  3.4783533  -2.6205335   0.9006934 ...   6.8...   \n",
       "10  [ -9.01165    -4.159134   -7.916232  ... -56.3...   \n",
       "11  [ 0.67962384 -0.06494701  8.85545    ...  7.55...   \n",
       "12  [ -0.25348127 -41.574276     1.922559   ...   ...   \n",
       "13  [  4.874438   -1.8305607   0.8711748 ...  11.2...   \n",
       "14  [  5.5722904    1.2895355    7.466584   ...   ...   \n",
       "15  [1.6556758  1.8287566  7.954074   ... 0.091212...   \n",
       "16  [ 5.1050148e+00 -4.5107603e-03  2.3342848e+00 ...   \n",
       "17  [-0.27483177 -2.0096369   3.9182355  ... 13.74...   \n",
       "18  [ -4.248621     0.43227804   0.47565675 ...   ...   \n",
       "19  [ -1.8522081   8.499422   12.197313  ... -22.8...   \n",
       "20  [ 10.179953  -35.008896    1.4445977 ...  -0.6...   \n",
       "21  [-13.676615    3.7126598   3.6381688 ...  -2.9...   \n",
       "22  [  1.35921      2.6271968    1.5852265  ... -3...   \n",
       "23  [  1.2033621    1.2829072   -0.677117   ...   ...   \n",
       "24  [  0.458153    -0.17178726 -36.4488     ...  -...   \n",
       "25  [-0.25758052 -2.7192278  -1.5600634  ...  4.93...   \n",
       "26  [-0.9596062   2.6285806  -5.882188   ... -0.19...   \n",
       "27  [ 0.1741389  1.5327911 -1.0859172 ... -1.22349...   \n",
       "28  [-0.1070708  11.770968    1.1013768  ...  0.69...   \n",
       "29  [-19.051239    -0.2597494   -4.561411   ...   ...   \n",
       "30  [-0.9870031   1.1960202  -0.83932805 ... -0.05...   \n",
       "31  [ 0.27721643  0.82572305 -0.02563262 ... -0.12...   \n",
       "32  [ 0.3802812 -5.7206507 -3.0257072 ...  0.77484...   \n",
       "33  [ 9.174057   1.5938154 -0.9848096 ... -2.02267...   \n",
       "34  [-3.54975128e+00 -5.04954147e+00 -1.25388565e+...   \n",
       "35  [ 2.165514   -0.35741258  5.0310707  ...  6.41...   \n",
       "36  [ 0.8002925  -1.1678371   0.16828537 ... -0.35...   \n",
       "37  [-0.35526133 -0.53310084  5.10726    ...  0.20...   \n",
       "38  [ 1.1651549   2.6985283  -0.3911749  ... -0.26...   \n",
       "39  [-0.17662132 -0.56799173  5.411066   ...  0.56...   \n",
       "40  [ 0.8779361 -2.019677  -3.5170097 ...  1.62991...   \n",
       "41  [ -0.20525122   0.4975767    1.2209172  ...   ...   \n",
       "42  [ 1.1105506   1.1565566   3.1153793  ...  4.83...   \n",
       "43  [ 1.9488754   4.3784027  -0.15159988 ...  3.38...   \n",
       "44  [ -6.3456097  11.481762  -21.673662  ...  -4.9...   \n",
       "45  [ 2.3266788e+00  5.2837276e-01  9.6931458e-03 ...   \n",
       "46  [-0.47949243  0.41796613  0.57161784 ...  0.89...   \n",
       "47  [ 1.5137401   1.1290069   0.7753334  ... -0.71...   \n",
       "48  [ 0.4972546   0.80511796  0.36939752 ... -0.16...   \n",
       "\n",
       "    info/learner/default_policy/mean_td_error  \\\n",
       "0                                   -9.532643   \n",
       "1                                   -0.777455   \n",
       "2                                    0.015193   \n",
       "3                                    1.042608   \n",
       "4                                   -1.572562   \n",
       "5                                   -0.332741   \n",
       "6                                   -4.165147   \n",
       "7                                   -1.795620   \n",
       "8                                   -0.146196   \n",
       "9                                   -0.587912   \n",
       "10                                  -1.149156   \n",
       "11                                   0.737157   \n",
       "12                                  -1.183170   \n",
       "13                                   1.586377   \n",
       "14                                   0.034017   \n",
       "15                                  -1.998481   \n",
       "16                                  -0.067832   \n",
       "17                                  -0.787489   \n",
       "18                                  -0.855444   \n",
       "19                                  -0.151320   \n",
       "20                                  -1.499709   \n",
       "21                                   0.107176   \n",
       "22                                  -0.672244   \n",
       "23                                  -1.078374   \n",
       "24                                  -1.186148   \n",
       "25                                  -1.130995   \n",
       "26                                  -0.147397   \n",
       "27                                  -1.422228   \n",
       "28                                  -0.537835   \n",
       "29                                  -0.744182   \n",
       "30                                  -1.067708   \n",
       "31                                  -0.915631   \n",
       "32                                  -0.835654   \n",
       "33                                   0.102620   \n",
       "34                                  -0.579089   \n",
       "35                                  -0.401935   \n",
       "36                                   0.204935   \n",
       "37                                  -0.275301   \n",
       "38                                   0.182121   \n",
       "39                                  -0.149961   \n",
       "40                                  -0.316527   \n",
       "41                                  -0.017954   \n",
       "42                                   0.373318   \n",
       "43                                  -0.169193   \n",
       "44                                  -0.942893   \n",
       "45                                  -0.418834   \n",
       "46                                  -0.795342   \n",
       "47                                  -0.403758   \n",
       "48                                  -0.066340   \n",
       "\n",
       "    info/learner/default_policy/num_agent_steps_trained  \\\n",
       "0                                              1024.0     \n",
       "1                                              1024.0     \n",
       "2                                              1024.0     \n",
       "3                                              1024.0     \n",
       "4                                              1024.0     \n",
       "5                                              1024.0     \n",
       "6                                              1024.0     \n",
       "7                                              1024.0     \n",
       "8                                              1024.0     \n",
       "9                                              1024.0     \n",
       "10                                             1024.0     \n",
       "11                                             1024.0     \n",
       "12                                             1024.0     \n",
       "13                                             1024.0     \n",
       "14                                             1024.0     \n",
       "15                                             1024.0     \n",
       "16                                             1024.0     \n",
       "17                                             1024.0     \n",
       "18                                             1024.0     \n",
       "19                                             1024.0     \n",
       "20                                             1024.0     \n",
       "21                                             1024.0     \n",
       "22                                             1024.0     \n",
       "23                                             1024.0     \n",
       "24                                             1024.0     \n",
       "25                                             1024.0     \n",
       "26                                             1024.0     \n",
       "27                                             1024.0     \n",
       "28                                             1024.0     \n",
       "29                                             1024.0     \n",
       "30                                             1024.0     \n",
       "31                                             1024.0     \n",
       "32                                             1024.0     \n",
       "33                                             1024.0     \n",
       "34                                             1024.0     \n",
       "35                                             1024.0     \n",
       "36                                             1024.0     \n",
       "37                                             1024.0     \n",
       "38                                             1024.0     \n",
       "39                                             1024.0     \n",
       "40                                             1024.0     \n",
       "41                                             1024.0     \n",
       "42                                             1024.0     \n",
       "43                                             1024.0     \n",
       "44                                             1024.0     \n",
       "45                                             1024.0     \n",
       "46                                             1024.0     \n",
       "47                                             1024.0     \n",
       "48                                             1024.0     \n",
       "\n",
       "    info/learner/default_policy/learner_stats/allreduce_latency  \\\n",
       "0                                                 0.0             \n",
       "1                                                 0.0             \n",
       "2                                                 0.0             \n",
       "3                                                 0.0             \n",
       "4                                                 0.0             \n",
       "5                                                 0.0             \n",
       "6                                                 0.0             \n",
       "7                                                 0.0             \n",
       "8                                                 0.0             \n",
       "9                                                 0.0             \n",
       "10                                                0.0             \n",
       "11                                                0.0             \n",
       "12                                                0.0             \n",
       "13                                                0.0             \n",
       "14                                                0.0             \n",
       "15                                                0.0             \n",
       "16                                                0.0             \n",
       "17                                                0.0             \n",
       "18                                                0.0             \n",
       "19                                                0.0             \n",
       "20                                                0.0             \n",
       "21                                                0.0             \n",
       "22                                                0.0             \n",
       "23                                                0.0             \n",
       "24                                                0.0             \n",
       "25                                                0.0             \n",
       "26                                                0.0             \n",
       "27                                                0.0             \n",
       "28                                                0.0             \n",
       "29                                                0.0             \n",
       "30                                                0.0             \n",
       "31                                                0.0             \n",
       "32                                                0.0             \n",
       "33                                                0.0             \n",
       "34                                                0.0             \n",
       "35                                                0.0             \n",
       "36                                                0.0             \n",
       "37                                                0.0             \n",
       "38                                                0.0             \n",
       "39                                                0.0             \n",
       "40                                                0.0             \n",
       "41                                                0.0             \n",
       "42                                                0.0             \n",
       "43                                                0.0             \n",
       "44                                                0.0             \n",
       "45                                                0.0             \n",
       "46                                                0.0             \n",
       "47                                                0.0             \n",
       "48                                                0.0             \n",
       "\n",
       "    info/learner/default_policy/learner_stats/grad_gnorm  \\\n",
       "0                                           40.000000      \n",
       "1                                            3.398451      \n",
       "2                                            6.137737      \n",
       "3                                            8.974737      \n",
       "4                                            3.103477      \n",
       "5                                            2.404050      \n",
       "6                                           12.414696      \n",
       "7                                            5.062077      \n",
       "8                                            3.508381      \n",
       "9                                            2.168987      \n",
       "10                                           2.654643      \n",
       "11                                          12.270066      \n",
       "12                                           4.113058      \n",
       "13                                          21.374706      \n",
       "14                                           4.554944      \n",
       "15                                           7.724813      \n",
       "16                                          10.850351      \n",
       "17                                           2.450926      \n",
       "18                                           2.483238      \n",
       "19                                           5.730842      \n",
       "20                                           4.761689      \n",
       "21                                           4.866289      \n",
       "22                                           3.359235      \n",
       "23                                           5.771350      \n",
       "24                                           5.457865      \n",
       "25                                           4.919761      \n",
       "26                                           3.622108      \n",
       "27                                           6.494023      \n",
       "28                                           3.862209      \n",
       "29                                           4.524508      \n",
       "30                                           5.308852      \n",
       "31                                           6.364350      \n",
       "32                                           4.745737      \n",
       "33                                           7.318543      \n",
       "34                                           5.206085      \n",
       "35                                           4.602608      \n",
       "36                                           6.201797      \n",
       "37                                           3.589692      \n",
       "38                                          13.264544      \n",
       "39                                           4.733242      \n",
       "40                                           4.775574      \n",
       "41                                           4.976462      \n",
       "42                                          12.743515      \n",
       "43                                           4.696795      \n",
       "44                                          10.193322      \n",
       "45                                           3.374490      \n",
       "46                                          10.282938      \n",
       "47                                          10.641539      \n",
       "48                                           3.894305      \n",
       "\n",
       "    info/learner/default_policy/learner_stats/mean_q  \\\n",
       "0                                           0.246236   \n",
       "1                                          18.016447   \n",
       "2                                          18.794142   \n",
       "3                                          18.521561   \n",
       "4                                          16.533539   \n",
       "5                                          15.443865   \n",
       "6                                          13.171873   \n",
       "7                                          14.493250   \n",
       "8                                          14.477367   \n",
       "9                                          12.877733   \n",
       "10                                         12.171491   \n",
       "11                                         13.855407   \n",
       "12                                         11.615423   \n",
       "13                                         13.939721   \n",
       "14                                         11.629099   \n",
       "15                                         10.662794   \n",
       "16                                         11.697859   \n",
       "17                                         10.381654   \n",
       "18                                         10.545372   \n",
       "19                                         11.557020   \n",
       "20                                          9.655149   \n",
       "21                                         11.053155   \n",
       "22                                          9.856972   \n",
       "23                                          9.904694   \n",
       "24                                          9.349145   \n",
       "25                                          9.352964   \n",
       "26                                         10.668340   \n",
       "27                                          9.330950   \n",
       "28                                          9.164739   \n",
       "29                                          9.503153   \n",
       "30                                          8.738939   \n",
       "31                                          9.086431   \n",
       "32                                          8.793969   \n",
       "33                                          9.441277   \n",
       "34                                          8.934761   \n",
       "35                                          8.920285   \n",
       "36                                          9.592368   \n",
       "37                                          8.851565   \n",
       "38                                          9.825369   \n",
       "39                                          8.341745   \n",
       "40                                          8.734725   \n",
       "41                                          9.450397   \n",
       "42                                          9.289961   \n",
       "43                                          9.323828   \n",
       "44                                          7.430641   \n",
       "45                                          8.198449   \n",
       "46                                          8.031837   \n",
       "47                                          7.549159   \n",
       "48                                          8.761932   \n",
       "\n",
       "    info/learner/default_policy/learner_stats/min_q  \\\n",
       "0                                        -15.835198   \n",
       "1                                         -0.041102   \n",
       "2                                          0.265299   \n",
       "3                                         -0.137503   \n",
       "4                                          0.174857   \n",
       "5                                          0.233130   \n",
       "6                                          0.276638   \n",
       "7                                          0.279899   \n",
       "8                                          0.231801   \n",
       "9                                          0.679283   \n",
       "10                                        -1.379480   \n",
       "11                                         0.684018   \n",
       "12                                         0.717183   \n",
       "13                                        -0.065624   \n",
       "14                                         0.502012   \n",
       "15                                         0.068202   \n",
       "16                                         0.068989   \n",
       "17                                        -0.470145   \n",
       "18                                        -0.389024   \n",
       "19                                        -0.834266   \n",
       "20                                        -0.673707   \n",
       "21                                        -0.265543   \n",
       "22                                        -0.917923   \n",
       "23                                        -1.135212   \n",
       "24                                        -1.221530   \n",
       "25                                        -0.232620   \n",
       "26                                        -0.337734   \n",
       "27                                        -1.169915   \n",
       "28                                        -0.793543   \n",
       "29                                        -0.756109   \n",
       "30                                        -0.853909   \n",
       "31                                        -1.495298   \n",
       "32                                        -1.177927   \n",
       "33                                        -0.940971   \n",
       "34                                        -0.966193   \n",
       "35                                        -1.046370   \n",
       "36                                        -0.668387   \n",
       "37                                        -1.153511   \n",
       "38                                        -0.400916   \n",
       "39                                        -0.592524   \n",
       "40                                        -0.950870   \n",
       "41                                        -0.941013   \n",
       "42                                        -0.841498   \n",
       "43                                        -0.322785   \n",
       "44                                        -0.181708   \n",
       "45                                        -0.830371   \n",
       "46                                        -0.305132   \n",
       "47                                        -0.327079   \n",
       "48                                        -0.164048   \n",
       "\n",
       "    info/learner/default_policy/learner_stats/max_q  \\\n",
       "0                                         12.509801   \n",
       "1                                         34.083656   \n",
       "2                                         37.528831   \n",
       "3                                         43.737011   \n",
       "4                                         41.704906   \n",
       "5                                         40.797157   \n",
       "6                                         38.906605   \n",
       "7                                         43.621899   \n",
       "8                                         43.665577   \n",
       "9                                         45.145042   \n",
       "10                                        41.205154   \n",
       "11                                        45.224060   \n",
       "12                                        46.346764   \n",
       "13                                        49.871910   \n",
       "14                                        48.686363   \n",
       "15                                        48.045498   \n",
       "16                                        47.437889   \n",
       "17                                        45.642307   \n",
       "18                                        43.713223   \n",
       "19                                        51.538326   \n",
       "20                                        48.022087   \n",
       "21                                        51.361637   \n",
       "22                                        53.659718   \n",
       "23                                        53.830666   \n",
       "24                                        49.153381   \n",
       "25                                        57.947506   \n",
       "26                                        55.037617   \n",
       "27                                        59.358978   \n",
       "28                                        51.203438   \n",
       "29                                        59.082062   \n",
       "30                                        47.935421   \n",
       "31                                        48.690308   \n",
       "32                                        53.721397   \n",
       "33                                        61.828312   \n",
       "34                                        57.213398   \n",
       "35                                        62.771378   \n",
       "36                                        53.017555   \n",
       "37                                        61.386543   \n",
       "38                                        71.046722   \n",
       "39                                        60.975723   \n",
       "40                                        65.985733   \n",
       "41                                        71.980942   \n",
       "42                                        67.689224   \n",
       "43                                        63.899086   \n",
       "44                                        57.474747   \n",
       "45                                        64.207275   \n",
       "46                                        69.861687   \n",
       "47                                        56.245564   \n",
       "48                                        53.815144   \n",
       "\n",
       "    info/learner/default_policy/learner_stats/cur_lr  \n",
       "0                                             0.0003  \n",
       "1                                             0.0003  \n",
       "2                                             0.0003  \n",
       "3                                             0.0003  \n",
       "4                                             0.0003  \n",
       "5                                             0.0003  \n",
       "6                                             0.0003  \n",
       "7                                             0.0003  \n",
       "8                                             0.0003  \n",
       "9                                             0.0003  \n",
       "10                                            0.0003  \n",
       "11                                            0.0003  \n",
       "12                                            0.0003  \n",
       "13                                            0.0003  \n",
       "14                                            0.0003  \n",
       "15                                            0.0003  \n",
       "16                                            0.0003  \n",
       "17                                            0.0003  \n",
       "18                                            0.0003  \n",
       "19                                            0.0003  \n",
       "20                                            0.0003  \n",
       "21                                            0.0003  \n",
       "22                                            0.0003  \n",
       "23                                            0.0003  \n",
       "24                                            0.0003  \n",
       "25                                            0.0003  \n",
       "26                                            0.0003  \n",
       "27                                            0.0003  \n",
       "28                                            0.0003  \n",
       "29                                            0.0003  \n",
       "30                                            0.0003  \n",
       "31                                            0.0003  \n",
       "32                                            0.0003  \n",
       "33                                            0.0003  \n",
       "34                                            0.0003  \n",
       "35                                            0.0003  \n",
       "36                                            0.0003  \n",
       "37                                            0.0003  \n",
       "38                                            0.0003  \n",
       "39                                            0.0003  \n",
       "40                                            0.0003  \n",
       "41                                            0.0003  \n",
       "42                                            0.0003  \n",
       "43                                            0.0003  \n",
       "44                                            0.0003  \n",
       "45                                            0.0003  \n",
       "46                                            0.0003  \n",
       "47                                            0.0003  \n",
       "48                                            0.0003  \n",
       "\n",
       "[49 rows x 98 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the trained results and plot the metrics in notebook\n",
    "import pandas as pd\n",
    "\n",
    "# Load the results from the progress.csv in the result folder of your running script\n",
    "df = pd.read_csv(\"saved_runs/bandits/progress.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Bandits training performance')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB7qklEQVR4nO3dd3hT5dsH8G+aNmnSvQfQAZS2ILuAzDIqRZQlKkstisKPKQIOVLbKEJEl8IoKiriQoYKAgAzZZe9VWsroANqmu2mT5/2j9EAoLW1Im47v57py0ZzznHPunIbk7jNlQggBIiIioirKwtwBEBEREZUlJjtERERUpTHZISIioiqNyQ4RERFVaUx2iIiIqEpjskNERERVGpMdIiIiqtKY7BAREVGVxmSHiIiIqjQmO0QV1NSpUyGTyQy2+fn5YfDgweYJyAR27doFmUyGXbt2lfrYmJgYyGQyrFy50uRxVUSrVq1CUFAQrKys4OjoaO5wiCo1JjtU7a1cuRIymczg4e7ujk6dOmHz5s3mDq9Y586dw9SpUxETE2Oycy5ZsqTaJBQV1YULFzB48GDUqVMHy5cvx9dff23ukIgqNUtzB0BUUUyfPh3+/v4QQiAhIQErV65E9+7d8ddff+H55583d3gAgIsXL8LC4v7fKOfOncO0adPQsWNH+Pn5meQaS5Ysgaura5nUIHXo0AFZWVlQKBSlPtbX1xdZWVmwsrIyeVwVza5du6DX67FgwQLUrVvX3OEQVXpMdojuefbZZxESEiI9HzJkCDw8PPDzzz9XmGRHqVSaOwQDGRkZsLGxKXF5CwsLWFtbG3UtmUxm9LGVRcH9TExMBACTNl9lZmZCrVab7HxElQmbsYiK4OjoCJVKBUtLw78J5s6dizZt2sDFxQUqlQrNmzfH77//Xuh4mUyGUaNGYcOGDXjqqaegVCrRoEEDbNmypVDZvXv3okWLFrC2tkadOnXwf//3f4+M6cE+OytXrsRLL70EAOjUqZPUBFfQH+bIkSMIDw+Hq6srVCoV/P398cYbbxT7mv38/HD27Fns3r1bOl/Hjh2l68lkMuzevRsjRoyAu7s7atasCQC4du0aRowYgcDAQKhUKri4uOCll14q1Lz2qD47HTt2xFNPPYVz586hU6dOUKvVqFGjBubMmWNw7KP67AwePBi2tra4efMmevfuDVtbW7i5uWHChAnQ6XQGx9+9exevvvoq7O3t4ejoiIiICJw8ebJE/YAKXvuePXswbNgwuLi4wN7eHq+99hqSk5MLld+8eTPat28PGxsb2NnZ4bnnnsPZs2cNyhTEHhUVhe7du8POzg6DBg2Cn58fpkyZAgBwc3ODTCbD1KlTpeOWLFmCBg0aQKlUwtvbGyNHjkRKSorBuQvu6dGjR9GhQweo1Wp8+OGH0j2cO3cuvvrqK9SuXRtqtRpdu3bF9evXIYTAjBkzULNmTahUKvTq1QtJSUkG5/7jjz/w3HPPwdvbG0qlEnXq1MGMGTMK3e+S/l4BIDs7G1OnTkW9evVgbW0NLy8vvPDCC4iKipLK6PV6zJ8/Hw0aNIC1tTU8PDwwbNiwR95/ooexZofoHo1Ggzt37kAIgcTERCxatAjp6el45ZVXDMotWLAAPXv2xKBBg6DVavHLL7/gpZdewsaNG/Hcc88ZlN27dy/WrVuHESNGwM7ODgsXLkTfvn0RGxsLFxcXAMDp06fRtWtXuLm5YerUqcjLy8OUKVPg4eFRbLwdOnTAmDFjsHDhQnz44YcIDg4GAAQHByMxMVE65wcffABHR0fExMRg3bp1xZ5z/vz5GD16NGxtbfHRRx8BQKE4RowYATc3N0yePBkZGRkAgMjISOzfvx/9+/dHzZo1ERMTg6VLl6Jjx444d+7cY2sUkpOT0a1bN7zwwgt4+eWX8fvvv+P9999Hw4YN8eyzzxZ7rE6nQ3h4OFq1aoW5c+di+/bt+OKLL1CnTh0MHz4cQP4XZY8ePXD48GEMHz4cQUFB+OOPPxAREVHsuR82atQoODo6YurUqbh48SKWLl2Ka9euSUkckN+xOCIiAuHh4Zg9ezYyMzOxdOlStGvXDsePHzdobszLy0N4eDjatWuHuXPnQq1WY/Dgwfjhhx+wfv16LF26FLa2tmjUqBGA/E7r06ZNQ1hYGIYPHy7FEBkZiX379hk08d29exfPPvss+vfvj1deecXg97h69WpotVqMHj0aSUlJmDNnDl5++WV07twZu3btwvvvv48rV65g0aJFmDBhAr777jvp2JUrV8LW1hbjxo2Dra0t/v33X0yePBmpqan4/PPPS/171el0eP7557Fjxw70798fb7/9NtLS0rBt2zacOXMGderUAQAMGzYMK1euxOuvv44xY8YgOjoaixcvxvHjxwu9dqJCBFE1t2LFCgGg0EOpVIqVK1cWKp+ZmWnwXKvViqeeekp07tzZYDsAoVAoxJUrV6RtJ0+eFADEokWLpG29e/cW1tbW4tq1a9K2c+fOCblcLh7+L+rr6ysiIiKk52vWrBEAxM6dOw3KrV+/XgAQkZGRJb4PBRo0aCBCQ0MLbS+4T+3atRN5eXkG+x6+J0IIceDAAQFA/PDDD9K2nTt3Foo3NDS0ULmcnBzh6ekp+vbtK22Ljo4WAMSKFSukbREREQKAmD59usG1mzZtKpo3by49X7t2rQAg5s+fL23T6XSic+fOhc75KAWvvXnz5kKr1Urb58yZIwCIP/74QwghRFpamnB0dBRvvfWWwfHx8fHCwcHBYHtB7B988EGh602ZMkUAELdv35a2JSYmCoVCIbp27Sp0Op20ffHixQKA+O6776RtBfd02bJlBuctuIdubm4iJSVF2j5x4kQBQDRu3Fjk5uZK2wcMGCAUCoXIzs6Wtj3qdz1s2DChVqsNypX09/rdd98JAGLevHmFzqvX64UQQvz3338CgFi9erXB/i1btjxyO9HD2IxFdM9XX32Fbdu2Ydu2bfjxxx/RqVMnvPnmm4VqQ1QqlfRzcnIyNBoN2rdvj2PHjhU6Z1hYmPSXKQA0atQI9vb2uHr1KoD8v2q3bt2K3r17w8fHRyoXHByM8PBwo19LQV+PjRs3Ijc31+jzPMpbb70FuVxusO3Be5Kbm4u7d++ibt26cHR0fOR9eZitra1BDZpCoUDLli2l+/Q4//vf/wyet2/f3uDYLVu2wMrKCm+99Za0zcLCAiNHjizR+QsMHTrUoAZh+PDhsLS0xN9//w0A2LZtG1JSUjBgwADcuXNHesjlcrRq1Qo7d+4sdM6C2qfH2b59O7RaLcaOHWvQSf2tt96Cvb09Nm3aZFBeqVTi9ddff+S5XnrpJTg4OEjPW7VqBQB45ZVXDJptW7VqBa1Wi5s3b0rbHvxdp6Wl4c6dO2jfvj0yMzNx4cIFg+uU5Pe6du1auLq6YvTo0YXiLKgtW7NmDRwcHPDMM88Y3NfmzZvD1tb2kfeV6EFsxiK6p2XLlgYdlAcMGICmTZti1KhReP7556URRBs3bsQnn3yCEydOICcnRyr/8Jw4AAwSmAJOTk5SP4Pbt28jKysLAQEBhcoFBgZKX6KlFRoair59+2LatGn48ssv0bFjR/Tu3RsDBw584k7O/v7+hbZlZWVh5syZWLFiBW7evAkhhLRPo9E89pw1a9YsdP+cnJxw6tSpxx5rbW0NNze3Qsc+2Jfj2rVr8PLyKtScVtqRTg//nmxtbeHl5SX1Tbp8+TIAoHPnzo883t7e3uC5paWl1O/pca5duwYg/33xIIVCgdq1a0v7C9SoUaPIUW8Pvy8LEp9atWo9cvuD9/Ls2bP4+OOP8e+//yI1NdWg/MO/65L8XqOiohAYGFiob9yDLl++DI1GA3d390fuL+jQTVQUJjtERbCwsECnTp2wYMECXL58GQ0aNMB///2Hnj17okOHDliyZAm8vLxgZWWFFStW4Keffip0jodrQAo8mAyUBZlMht9//x0HDx7EX3/9ha1bt+KNN97AF198gYMHD8LW1tbocz/4l32B0aNHY8WKFRg7dixat24NBwcHyGQy9O/fH3q9/rHnfJL7VNSx5lDwWletWgVPT89C+x/+QlcqlQa1NKb0qN9TgaLu2eN+DykpKQgNDYW9vT2mT5+OOnXqwNraGseOHcP7779f6Hdtqve/Xq+Hu7s7Vq9e/cj9Dye7RA9jskNUjLy8PABAeno6gPwqd2tra2zdutWghmTFihVGnd/NzQ0qlUqqEXjQxYsXH3v8o2qTHvT000/j6aefxqeffoqffvoJgwYNwi+//II333zT6HM+yu+//46IiAh88cUX0rbs7OxCo4TMxdfXFzt37iw0/PrKlSulOs/ly5fRqVMn6Xl6ejri4uLQvXt3AJCaLN3d3REWFmaCyO/z9fUFkP++qF27trRdq9UiOjra5Nd7lF27duHu3btYt24dOnToIG2Pjo42+px16tTBoUOHkJubW2Qn4zp16mD79u1o27ZtsUkcUVHYZ4eoCLm5ufjnn3+gUCikkU5yuRwymcxgmG1MTAw2bNhg1DXkcjnCw8OxYcMGxMbGStvPnz+PrVu3Pvb4gjluHk4qkpOTC/313KRJEwAwaHor6pylTVLkcnmh6y1atKjQcGRzCQ8PR25uLpYvXy5t0+v1+Oqrr0p1nq+//tqgD9TSpUuRl5cnjSwKDw+Hvb09Pvvss0f2lbp9+7aRryC//5dCocDChQsN7vW3334LjUZTaCRgWSioqXnw+lqtFkuWLDH6nH379sWdO3ewePHiQvsKrvPyyy9Dp9NhxowZhcrk5eVVmKSaKi7W7BDds3nzZqmDZWJiIn766SdcvnwZH3zwgdTX4rnnnsO8efPQrVs3DBw4EImJifjqq69Qt27dEvUveZRp06Zhy5YtaN++PUaMGIG8vDwsWrQIDRo0eOw5mzRpArlcjtmzZ0Oj0UCpVKJz58746aefsGTJEvTp0wd16tRBWloali9fDnt7e6kWoijNmzfH0qVL8cknn6Bu3bpwd3cvsg9Kgeeffx6rVq2Cg4MD6tevjwMHDmD79u3S8Hpz6927N1q2bInx48fjypUrCAoKwp9//inNIVPS2iytVosuXbrg5ZdfxsWLF7FkyRK0a9cOPXv2BJDfJ2fp0qV49dVX0axZM/Tv3x9ubm6IjY3Fpk2b0LZt20d+qZeEm5sbJk6ciGnTpqFbt27o2bOnFEOLFi0KTZFQFtq0aQMnJydERERgzJgxkMlkWLVq1RM1y7722mv44YcfMG7cOBw+fBjt27dHRkYGtm/fjhEjRqBXr14IDQ3FsGHDMHPmTJw4cQJdu3aFlZUVLl++jDVr1mDBggV48cUXTfhKqaphskN0z+TJk6Wfra2tERQUhKVLl2LYsGHS9s6dO+Pbb7/FrFmzMHbsWPj7+2P27NmIiYkxOtlp1KgRtm7dinHjxmHy5MmoWbMmpk2bhri4uMee09PTE8uWLcPMmTMxZMgQ6HQ67Ny5E6GhoTh8+DB++eUXJCQkwMHBAS1btsTq1asf2cH44ftw7do1zJkzB2lpaQgNDX1ssrNgwQLI5XKsXr0a2dnZaNu2LbZv3/5EI8pMSS6XY9OmTXj77bfx/fffw8LCAn369MGUKVPQtm3bEs/MvHjxYqxevRqTJ09Gbm4uBgwYgIULFxokSwMHDoS3tzdmzZqFzz//HDk5OahRowbat29f5Oiokpo6dSrc3NywePFivPPOO3B2dsbQoUPx2Weflcs8My4uLti4cSPGjx+Pjz/+GE5OTnjllVfQpUsXo3/Xcrkcf//9t9TUunbtWri4uKBdu3Zo2LChVG7ZsmVo3rw5/u///g8ffvghLC0t4efnh1deeQVt27Y11UukKkomyrqnJBFRBbVhwwb06dMHe/fuLfYLs2Ayu8jISIMRe0RUObDPDhFVC1lZWQbPdTodFi1aBHt7ezRr1sxMURFReWAzFhFVC6NHj0ZWVhZat26NnJwcrFu3Dvv378dnn33GET5EVRyTHSKqFjp37owvvvgCGzduRHZ2NurWrYtFixZh1KhR5g6NiMoY++wQERFRlcY+O0RERFSlMdkhIiKiKo19dpA/k+qtW7dgZ2dn1FT5REREVP6EEEhLS4O3t3ex68wx2QFw69atQqv9EhERUeVw/fp11KxZs8j9THYA2NnZAci/WQXLAhAREVHFlpqailq1aknf40VhsoP76+LY29sz2SEiIqpkHtcFhR2UiYiIqEpjskNERERVGpMdIiIiqtKY7BAREVGVZtZkZ8+ePejRowe8vb0hk8mwYcMGg/1CCEyePBleXl5QqVQICwvD5cuXDcokJSVh0KBBsLe3h6OjI4YMGYL09PRyfBVERERUkZk12cnIyEDjxo3x1VdfPXL/nDlzsHDhQixbtgyHDh2CjY0NwsPDkZ2dLZUZNGgQzp49i23btmHjxo3Ys2cPhg4dWl4vgYiIiCq4CrMQqEwmw/r169G7d28A+bU63t7eGD9+PCZMmAAA0Gg08PDwwMqVK9G/f3+cP38e9evXR2RkJEJCQgAAW7ZsQffu3XHjxg14e3uX6NqpqalwcHCARqPh0HMiIqJKoqTf3xW2z050dDTi4+MRFhYmbXNwcECrVq1w4MABAMCBAwfg6OgoJToAEBYWBgsLCxw6dKjIc+fk5CA1NdXgQURERFVThZ1UMD4+HgDg4eFhsN3Dw0PaFx8fD3d3d4P9lpaWcHZ2lso8ysyZMzFt2rRC2zMyMiCXywttl8vlsLa2NihXFAsLC6hUKqPKZmZmoqiKNplMBrVabVTZrKws6PX6IuOwsbExqmx2djZ0Op1JyqrVamlSqJycHOTl5ZmkrEqlktZL0Wq1yM3NNUlZa2tr6b1SmrK5ubnQarVFllUqlbC0tCx12by8POTk5BRZVqFQwMrKqtRldTqdQbPxw6ysrKBQKEpdVq/XIysryyRlLS0toVQqAeTXCGdmZpqkbGn+3/Mz4tFl+RnBz4jy+IwoEVFBABDr16+Xnu/bt08AELdu3TIo99JLL4mXX35ZCCHEp59+KurVq1foXG5ubmLJkiVFXis7O1toNBrpcf36dQGgyEf37t0Njler1UWWDQ0NNSjr6upaZNmQkBCDsr6+vkWWrV+/vkHZ+vXrF1nW19fXoGxISEiRZV1dXQ3KhoaGFllWrVYblO3evXux9+1BL774YrFl09PTpbIRERHFlk1MTJTKjhgxotiy0dHRUtkJEyYUW/bMmTNS2SlTphRb9vDhw1LZOXPmFFt2586dUtnFixcXW3bjxo1S2RUrVhRb9rfffpPK/vbbb8WWXbFihVR248aNxZZdvHixVHbnzp3Flp0zZ45U9vDhw8WWnTJlilT2zJkzxZadMGGCVDY6OrrYsiNGjJDKJiYmFls2IiJCKpuenl5s2RdffNHgPVxcWX5G5D/4GXH/wc+I/EdZf0ZoNBoBQGg0GlGcCtuM5enpCQBISEgw2J6QkCDt8/T0RGJiosH+vLw8JCUlSWUeRalUSktDcIkIIiKiqq3Cd1CeMGECxo8fDyC/I5K7u3uhDspHjhxB8+bNAQD//PMPunXrZlQH5Vu3bj0y8WEV9aPLsoqaVdRsxip9WX5GGFeWnxH5+BlhWLakHZTNmuykp6fjypUrAICmTZti3rx56NSpE5ydneHj44PZs2dj1qxZ+P777+Hv749Jkybh1KlTOHfunPTB8uyzzyIhIQHLli1Dbm4uXn/9dYSEhOCnn34qcRxlNRor9m4mLiWkoVFNB7jbWz/+ACIiIiqxkn5/m7WD8pEjR9CpUyfp+bhx4wAAERERWLlyJd577z1kZGRg6NChSElJQbt27bBlyxaDv6BWr16NUaNGoUuXLrCwsEDfvn2xcOHCcn8tjzJ+zQlExiRjQf8m6NWkhrnDISIiqpYqTDOWOZVVzc4Ha0/hl8jrGNMlAOOeqWey8xIREVEVmGenKqjjZgsAiLrN5SuIiIjMhclOGarjnt/5LiqRyQ4REZG5MNkpQwU1O9F3MqDTV/vWQiIiIrNgslOGajqpoZBbICdPj1spRQ+hIyIiorLDZKcMyS1k8HfNb8q6wn47REREZsFkp4yx3w4REZF5MdkpY/dHZBU9SyoRERGVHSY7ZUxKdlizQ0REZBZMdspYXXfOtUNERGROTHbKWEEH5bsZWiRnFL1gGxEREZUNJjtlzEZpCW+H/LW8rt5h7Q4REVF5Y7JTDuoUNGUlspMyERFReWOyUw64RhYREZH5MNkpB3Xc7s21w2SHiIio3DHZKQeca4eIiMh8mOyUg4I+O7FJmcjJ05k5GiIiouqFyU45cLdTwlZpCZ1eIPZuprnDISIiqlaY7JQDmUzGfjtERERmwmSnnLDfDhERkXkw2Skn9+faYc0OERFReWKyU07YjEVERGQeTHbKyYPNWEIIM0dDRERUfTDZKSc+LmrILWRIz8lDYlqOucMhIiKqNpjslBOlpRw+zmoAwBX22yEiIio3THbKEfvtEBERlT8mO+WII7KIiIjKH5OdcsS5doiIiMofk51ydD/ZYc0OERFReWGyU44K+uzEabKRnpNn5miIiIiqByY75chRrYCrrQIAEM2mLCIionLBZKec1WZTFhERUblislPO2G+HiIiofDHZKWeca4eIiKh8MdkpZ/fn2mGfHSIiovLAZKec1b3XjBV9JwM6PRcEJSIiKmtMdsqZt6MKSksLaHV63EjONHc4REREVR6TnXImt5DB35X9doiIiMoLkx0zYL8dIiKi8sNkxww4/JyIiKj8MNkxg4Lh51e4+jkREVGZY7JjBqzZISIiKj9MdsygINlJzsxFUobWzNEQERFVbUx2zEClkKOGowoAa3eIiIjKGpMdM7k/IovJDhERUVlismMmXCOLiIiofDDZMZP7nZQ51w4REVFZYrJjJhyRRUREVD6Y7JhJHff8ZqzrSZnIztWZORoiIqKqi8mOmbjZKmFnbQm9AK7d5YKgREREZYXJjpnIZDI2ZREREZUDJjtmJCU7HH5ORERUZpjsmFFBvx3W7BAREZUdJjtmxOHnREREZY/Jjhk92GdHCGHmaIiIiKomJjtm5OuihqWFDJlaHeJTs80dDhERUZXEZMeMrOQW8HFRAwCusJMyERFRmWCyY2YckUVERFS2mOyYGTspExERlS0mO2ZW1z0/2dl8Jh57Lt02czRERERVD5MdM3umvgf8XW1wJz0Hr313GO/9fhKarFxzh0VERFRlMNkxMweVFTaNaYfBbfwgkwG/HbmB8C/34N8LCeYOjYiIqEqo8MlOWloaxo4dC19fX6hUKrRp0waRkZHSfiEEJk+eDC8vL6hUKoSFheHy5ctmjLj01ApLTO3ZAL8Naw1/VxvEp2bjjZVHMO7XE0jJ1Jo7PCIiokqtwic7b775JrZt24ZVq1bh9OnT6Nq1K8LCwnDz5k0AwJw5c7Bw4UIsW7YMhw4dgo2NDcLDw5GdXfnmrWnh54y/x7THW+39YSED1h2/iWe+3IN/zsabOzQiIqJKSyYq8NS9WVlZsLOzwx9//IHnnntO2t68eXM8++yzmDFjBry9vTF+/HhMmDABAKDRaODh4YGVK1eif//+JbpOamoqHBwcoNFoYG9vXyavpbSOxSbj3TUnpVFaPRt7Y2rPBnC2UZg5MiIiooqhpN/fFbpmJy8vDzqdDtbW1gbbVSoV9u7di+joaMTHxyMsLEza5+DggFatWuHAgQNFnjcnJwepqakGj4qmmY8TNo1pj+Ed60BuIcOfJ2+hx6K9SMtm52UiIqLSqNDJjp2dHVq3bo0ZM2bg1q1b0Ol0+PHHH3HgwAHExcUhPj6/ecfDw8PgOA8PD2nfo8ycORMODg7So1atWmX6OoxlbSXH+92CsH5EG7jZKXEzJQsHou6aOywiIqJKpUInOwCwatUqCCFQo0YNKJVKLFy4EAMGDICFhfGhT5w4ERqNRnpcv37dhBGbXqOajggLzk/ojl5LNnM0RERElUuFT3bq1KmD3bt3Iz09HdevX8fhw4eRm5uL2rVrw9PTEwCQkGA4TDshIUHa9yhKpRL29vYGj4ouxNcJABAZk2TmSIiIiCqXCp/sFLCxsYGXlxeSk5OxdetW9OrVC/7+/vD09MSOHTukcqmpqTh06BBat25txmhNr4WfMwDg9E0NsnN1Zo6GiIio8rA0dwCPs3XrVgghEBgYiCtXruDdd99FUFAQXn/9dchkMowdOxaffPIJAgIC4O/vj0mTJsHb2xu9e/c2d+gmVctZBXc7JRLTcnDqhgYt/Z3NHRIREVGlUOGTHY1Gg4kTJ+LGjRtwdnZG37598emnn8LKygoA8N577yEjIwNDhw5FSkoK2rVrhy1bthQawVXZyWQyhPg54e/T8YiMSWKyQ0REVEIVep6d8lIR59l5lO/2RmP6xnPoFOiGFa+3NHc4REREZlUl5tkhQwX9do5eS4ZeX+1zVCIiohJhslOJBHvZQa2QIzU7D5cT080dDhERUaXAZKcSsZRboKmPIwAOQSciIiopJjuVTHPf+01ZRERE9HhMdiqZFn6cXJCIiKg0mOxUMk19nGAhA24kZyFek23ucIiIiCo8JjuVjK3SEsFe+cPrjlxj7Q4REdHjMNmphAqGoB+JYb8dIiKix2GyUwmFsN8OERFRiTHZqYRC7o3IOh+XivScPDNHQ0REVLEx2amEPB2sUdNJBb0AjseyKYuIiKg4THYqqRDfgqYsJjtERETFYbJTSYVI62Sx3w4REVFxmOxUUgUjso7HpiBPpzdzNERERBUXk51KKsDdFvbWlsjU6nA+Ls3c4RAREVVYTHYqKQsLGZr7cgg6ERHR4zDZqcQK+u1wJmUiIqKiMdmpxApGZB2JSYYQwszREBERVUxMdiqxxrUcYSWXITEtB9eTsswdDhERUYXEZKcSs7aS46kaDgDYb4eIiKgolsYclJGRgVmzZmHHjh1ITEyEXm849Pnq1asmCY4er4WfM47HpuDItWT0bV7T3OEQERFVOEYlO2+++SZ2796NV199FV5eXpDJZKaOi0ooxNcJXwM4wpodIiKiRzIq2dm8eTM2bdqEtm3bmjoeKqWC4eeXE9ORkqmFo1ph5oiIiIgqFqP67Dg5OcHZ2dnUsZARXGyVqO1mAwA4eo3rZBERET3MqGRnxowZmDx5MjIzM00dDxmhhW9+4slFQYmIiAozqhnriy++QFRUFDw8PODn5wcrKyuD/ceOHTNJcFQyzf2c8OuR6+y3Q0RE9AhGJTu9e/c2cRj0JAoWBT11Q4PsXB2sreRmjoiIiKjiMCrZmTJliqnjoCfg56KGq60Cd9K1OHNTIy0jQURERJxUsEqQyR5cFJT9doiIiB5kVLKj0+kwd+5ctGzZEp6ennB2djZ4UPkraMo6ykVBiYiIDBiV7EybNg3z5s1Dv379oNFoMG7cOLzwwguwsLDA1KlTTRwilURBzc6Ra8nQ67koKBERUQGjkp3Vq1dj+fLlGD9+PCwtLTFgwAB88803mDx5Mg4ePGjqGKkEGng7wNrKAimZuYi6nW7ucIiIiCoMo5Kd+Ph4NGzYEABga2sLjUYDAHj++eexadMm00VHJaawtECTWo4A8mt3iIiIKJ9RyU7NmjURFxcHAKhTpw7++ecfAEBkZCSUSqXpoqNSKei3sz/qrpkjISIiqjiMSnb69OmDHTt2AABGjx6NSZMmISAgAK+99hreeOMNkwZIJdehnhsA4L/Lt6Fjvx0iIiIARs6zM2vWLOnnfv36wcfHBwcOHEBAQAB69OhhsuCodJrWcoSdtSVSMnNx8kYKmvk4mTskIiIiszMq2XlY69at0bp1a1Ocip6ApdwC7QNc8ffpeOy6eJvJDhEREZ5gUsFVq1ahbdu28Pb2xrVr1wAA8+fPxx9//GGy4Kj0OtZzBwDsvpho5kiIiIgqBqOSnaVLl2LcuHHo3r07UlJSoNPpAACOjo6YP3++KeOjUgoNzO+3c+qmBnfTc8wcDRERkfkZlewsWrQIy5cvx0cffQS5/P6ikyEhITh9+rTJgqPS87C3RrCXPYQA9ly+be5wiIiIzM6oZCc6OhpNmzYttF2pVCIjI+OJg6In0/Fe7c6ui0x2iIiIjEp2/P39ceLEiULbt2zZguDg4CeNiZ5Qx3tD0Pdc4hB0IiIio0ZjjRs3DiNHjkR2djaEEDh8+DB+/vlnzJw5E998842pY6RSaubrBDulJZIzc3HqRgqaclQWERFVY0YlO2+++SZUKhU+/vhjZGZmYuDAgfD29saCBQvQv39/U8dIpWQlt0C7AFdsPpM/BJ3JDhERVWdGDz0fNGgQLl++jPT0dMTHx+PGjRsYMmSIKWOjJyD127nEfjtERFS9PfGkgmq1Gmq12hSxkAkVLB1x6kYKkjK0cLZRmDkiIiIi8zCqZufu3bsYOXIk6tevD1dXVzg7Oxs8yPy8HFQI8rSDEPlrZREREVVXRtXsvPrqq7hy5QqGDBkCDw8PyGQyU8dFJhAa6IYL8WnYdfE2ejWpYe5wiIiIzMKoZOe///7D3r170bhxY1PHQybUsZ47/m/3Vey5dBt6vYCFBZNSIiKqfoxqxgoKCkJWVpapYyETC/Fzgq3SEncztDh9U2PucIiIiMzCqGRnyZIl+Oijj7B7927cvXsXqampBg+qGKzkFmhb1wUAZ1MmIqLqy6hkx9HREampqejcuTPc3d3h5OQEJycnODo6wsmJc7pUJB0D81dB33WJq6ATEVH1ZFSfnUGDBsHKygo//fQTOyhXcAXz7Zy4noLkDC2cOASdiIiqGaOSnTNnzuD48eMIDAw0dTxkYl4OKgR62OFiQhr2XOaoLCIiqn6MasYKCQnB9evXTR0LlZGC2p3d7LdDRETVkFE1O6NHj8bbb7+Nd999Fw0bNoSVlZXB/kaNGpkkODKN0EA3/N+eq9hzmUPQiYio+jEq2enXrx8A4I033pC2yWQyCCEgk8mg0+lMEx2ZRIivM2wUctxJ1+LsrVQ0rOlg7pCIiIjKjVHJTnR0tKnjoDKksLRAm7qu2HYuAbsuJjLZISKiasWoZMfX17dE5Z577jl888038PLyMuYyZEIdA93yk51LtzG6S4C5wyEiIio3RnVQLqk9e/ZwpuUKomC+neOxyUjJ1Jo5GiIiovJjVM0OVT41HFUIcLfF5cR0/Hf5Dno09jZ3SERkJjqdDrm5ueYOg+ixrKysIJfLn/g8FTrZ0el0mDp1Kn788UfEx8fD29sbgwcPxscffyxNZCiEwJQpU7B8+XKkpKSgbdu2WLp0KQIC2FTzsI6BbricmI5dF28z2SGqhoQQiI+PR0pKirlDISoxR0dHeHp6PtEExhU62Zk9ezaWLl2K77//Hg0aNMCRI0fw+uuvw8HBAWPGjAEAzJkzBwsXLsT3338Pf39/TJo0CeHh4Th37hysra3N/Aoqlo6B7lj+XzR2cxV0omqpINFxd3eHWq3m7PdUoQkhkJmZicTE/OWOnqT/b4VOdvbv349evXrhueeeAwD4+fnh559/xuHDhwHk34j58+fj448/Rq9evQAAP/zwAzw8PLBhwwb079/fbLFXRCF+TlAr5LiTnoNzcal4qgZHZRFVFzqdTkp0XFxczB0OUYmoVCoAQGJiItzd3Y1u0irTDspPqk2bNtixYwcuXboEADh58iT27t2LZ599FkD+EPj4+HiEhYVJxzg4OKBVq1Y4cOBAkefNycmpliu1Ky3laFPHFQCw+xJnUyaqTgr66KjVajNHQlQ6Be/ZJ+lnVqbJzocffghnZ2ejj//ggw/Qv39/BAUFwcrKCk2bNsXYsWMxaNAgAPlVsgDg4eFhcJyHh4e071FmzpwJBwcH6VGrVi2jY6xsCpaO2HWRq6ATVUdsuqLKxhTv2RI3Y/35558lPmnPnj0BABMnTix9RA/47bffsHr1avz0009o0KABTpw4gbFjx8Lb2xsRERFGn3fixIkYN26c9Dw1NbXaJDwdAvKTneOxKdDm6aGwrNCVe0RERE+sxMlO7969DZ4XLA/x4PMCplou4t1335VqdwCgYcOGuHbtGmbOnImIiAh4enoCABISEgw6LiUkJKBJkyZFnlepVEKpVJokxsqmlrMKdkpLpOXkIeZuBup52Jk7JCKiYnXs2BFNmjTB/Pnzy/W6U6dOxYYNG3DixAkAwODBg5GSkoINGzaUaxz05Er8Z71er5ce//zzD5o0aYLNmzcjJSUFKSkp+Pvvv9GsWTNs2bLFZMFlZmbCwsIwRLlcDr1eDwDw9/eHp6cnduzYIe1PTU3FoUOH0Lp1a5PFUZXIZDLU9bAFAFyMTzNzNERElceCBQuwcuVK6XnHjh0xduxYs8VDJWfUaKyxY8di2bJlaNeunbQtPDwcarUaQ4cOxfnz500SXI8ePfDpp5/Cx8cHDRo0wPHjxzFv3jxpAVKZTIaxY8fik08+QUBAgDT03Nvbu1BNFN0X6GGH47EpuJzAZIeIqKQcHDiCtbIyqsNGVFQUHB0dC213cHBATEzME4Z036JFi/Diiy9ixIgRCA4OxoQJEzBs2DDMmDFDKvPee+9h9OjRGDp0KFq0aIH09HRs2bKFc+wUI+Be09VFJjtEVEnk5eVh1KhRcHBwgKurKyZNmiR1pVi1ahVCQkJgZ2cHT09PDBw4UJqbBQB27doFmUyGHTt2ICQkBGq1Gm3atMHFixcNrjFr1ix4eHjAzs4OQ4YMQXZ2tsH+wYMHS39IDx48GLt378aCBQsgk8kgk8kQExOD5ORkDBo0CG5ublCpVAgICMCKFSvK9ubQYxmV7LRo0QLjxo1DQkKCtC0hIQHvvvsuWrZsabLg7OzsMH/+fFy7dg1ZWVmIiorCJ598AoVCIZWRyWSYPn064uPjkZ2dje3bt6NevXomi6EqCryX7FxOSDdzJERkTkIIZGrzzPJ4sM9nSXz//fewtLTE4cOHsWDBAsybNw/ffPMNgPwhyTNmzMDJkyexYcMGxMTEYPDgwYXO8dFHH+GLL77AkSNHYGlpKbUSAPkDYqZOnYrPPvsMR44cgZeXF5YsWVJkPAsWLEDr1q3x1ltvIS4uDnFxcahVqxYmTZqEc+fOYfPmzTh//jyWLl0KV1fXUr1WMj2jmrG+/fZbvPDCC/Dx8ZFGMV2/fh0BAQHsuFUJ1LvXZyfmbgayc3WwtnrydUeIqPLJytWh/uStZrn2uenhUCtK/hVUq1YtfPnll5DJZAgMDMTp06fx5Zdf4q233jJIWmrXro2FCxdKNf22trbSvk8//RShoaEA8qc2ee6555CdnQ1ra2vMnz8fQ4YMwZAhQwAAn3zyCbZv316odqeAg4MDFAoF1Gq1NFgGAGJjY9G0aVOEhIQAyJ8Ml8zPqJqdgIAAnDp1Cn/99RfGjBmDMWPGYOPGjTh9+jTq1q1r6hjJxNzslHBUW0EvgKjbrN0hoorv6aefNhj127p1a1y+fBk6nQ5Hjx5Fjx494OPjAzs7OymhiY2NNThHo0aNpJ8LRvAWNHedP38erVq1MihvzECX4cOH45dffkGTJk3w3nvvYf/+/aU+B5leqWt2cnNzoVKpcOLECXTt2hVdu3Yti7ioDMlkMtRzt8PhmCRcSkhDA292uiOqjlRWcpybHm62a5tCdnY2wsPDER4ejtWrV8PNzQ2xsbEIDw+HVqs1KGtlZSX9XJA4FYzuNZVnn30W165dw99//41t27ahS5cuGDlyJObOnWvS61DplDrZsbKygo+Pj8nm0iHzqOdpey/ZYc0OUXUlk8lK1ZRkTocOHTJ4fvDgQQQEBODChQu4e/cuZs2aJXWrOHLkSKnPHxwcjEOHDuG1114zuEZxFArFI78L3dzcEBERgYiICLRv3x7vvvsukx0zM6oZ66OPPsKHH36IpKQkU8dD5aRgMsFLnGuHiCqB2NhYjBs3DhcvXsTPP/+MRYsW4e2334aPjw8UCgUWLVqEq1ev4s8//zQYsVtSb7/9Nr777jusWLECly5dwpQpU3D27Nlij/Hz88OhQ4cQExODO3fuQK/XY/Lkyfjjjz9w5coVnD17Fhs3bkRwcLCxL5tMxKiUfvHixbhy5Qq8vb3h6+sLGxsbg/3Hjh0zSXBUdqRkJ5HJDhFVfK+99hqysrLQsmVLyOVyvP322xg6dChkMhlWrlyJDz/8EAsXLkSzZs0wd+5cadmikurXrx+ioqLw3nvvITs7G3379sXw4cOxdWvRHbgnTJiAiIgI1K9fH1lZWYiOjoZCocDEiRMRExMDlUqF9u3b45dffnnSl09PSCZKO/4PwLRp04rdP2XKFKMDMofU1FQ4ODhAo9HA3t7e3OGUi6QMLZrN2AYAODstHDbKylGVTUTGyc7ORnR0NPz9/TkPGVUqxb13S/r9bdQ3XGVLZqgwZxsFXG2VuJOegyuJ6Whcy9HcIREREZUJLnldjRXMt3OJMykTEVEVZlSyo9PpMHfuXLRs2RKenp5wdnY2eFDlIPXbYbJDRERVmFHJzrRp0zBv3jz069cPGo0G48aNwwsvvAALCwtMnTrVxCFSWbmf7HD4ORERVV1GJTurV6/G8uXLMX78eFhaWmLAgAH45ptvMHny5MfOS0AVR6Anm7GIiKjqMyrZiY+PR8OGDQEAtra20Gg0AIDnn38emzZtMl10VKbquufX7MRpspGanWvmaIiIiMqGUclOzZo1ERcXBwCoU6cO/vnnHwBAZGQklEql6aKjMuWgsoKXQ/4wvsus3SEioirKqGSnT58+2LFjBwBg9OjRmDRpEgICAvDaa68ZrD5LFV8A++0QEVEVZ9Q8O7NmzZJ+7tevH3x9fbF//34EBASgR48eJguOyl6ghy32XLqNi1w2goiIqiiTzLPz9NNPY9y4cUx0KqGCmp3LXDaCiKhC27VrF2QyGVJSUswWQ0xMDGQyGU6cOFFhYioJo5IdHx8fvPbaa/j2228RFRVl6pioHAXeS3YuxrMZi4joccriy/3hBKIyadOmDeLi4uDg4GDuUIplVLLz2WefwdraGrNnz0ZAQABq1aqFV155BcuXL8fly5dNHSOVobru+cPP76TnIClDa+ZoiIioMlEoFPD09IRMJjN3KMUyKtl55ZVX8PXXX+PSpUu4efMmPv/8cwDAiBEjEBQUZNIAqWzZKC1R00kFgPPtEFHF9Pvvv6Nhw4ZQqVRwcXFBWFgYMjIycObMGVhYWOD27dsAgKSkJFhYWKB///7SsZ988gnatWsnPT9z5gyeffZZ2NrawsPDA6+++iru3Lkj7dfr9Zg5cyb8/f2hUqnQuHFj/P777wDya2A6deoEAHBycoJMJsPgwYMfexwAJCcnY9CgQXBzc4NKpUJAQABWrFgBAPD39wcANG3aFDKZDB07diz2fuzbtw+NGjWCtbU1nn76aZw5c0bad/fuXQwYMAA1atSAWq1Gw4YN8fPPP5fofhb45ptvEBwcDGtrawQFBWHJkiVFxvJwTdfKlSvh6OiIrVu3Ijg4GLa2tujWrZs0gtuYa5iEMFJGRobYunWrmDhxonj66aeFUqkUTZo0EWPHjjX2lGaj0WgEAKHRaMwdilm8seKw8H1/o/hhf7S5QyGiMpKVlSXOnTsnsrKyCu9MTy/68XD54spmZpasbCncunVLWFpainnz5ono6Ghx6tQp8dVXX4m0tDSh1+uFq6urWLNmjRBCiA0bNghXV1fh6ekpHR8WFiY++ugjIYQQycnJws3NTUycOFGcP39eHDt2TDzzzDOiU6dOUvlPPvlEBAUFiS1btoioqCixYsUKoVQqxa5du0ReXp5Yu3atACAuXrwo4uLiREpKymOPE0KIkSNHiiZNmojIyEgRHR0ttm3bJv78808hhBCHDx8WAMT27dtFXFycuHv37iPvxc6dOwUAERwcLP755x9x6tQp8fzzzws/Pz+h1WqFEELcuHFDfP755+L48eMiKipKLFy4UMjlcnHo0KHH3k8hhPjxxx+Fl5eXWLt2rbh69apYu3atcHZ2FitXrhRCCBEdHS0AiOPHjxvElJycLIQQYsWKFcLKykqEhYWJyMhIcfToUREcHCwGDhwovY7HXeNhxb13S/r9bVSy07p1a2FtbS2aNm0q3nnnHbFhwwaRlJRkzKkqhOqe7Mz8+7zwfX+j+Gj9KXOHQkRlpNhkByj60b27YVm1uuiyoaGGZV1dH12uFI4ePSoAiJiYmEfuf+GFF8TIkSOFEEKMHTtWvPvuu8LJyUmcP39eaLVaoVarxT///COEEGLGjBmia9euBsdfv35dSl6ys7OFWq0W+/fvNygzZMgQMWDAACFE4S93IUSJjuvRo4d4/fXXH/kaHk4gilJw7V9++UXadvfuXaFSqcSvv/5a5HHPPfecGD9+vBDi8fezTp064qeffjLYNmPGDNG6detHxvqoZAeAuHLlinT8V199JTw8PEp8jYeZItkxauj5hQsXYGNjg6CgIAQFBSE4OBhOTk5PVsVEZnN/2Qh2UiaiiqVx48bo0qULGjZsiPDwcHTt2hUvvvii9J0TGhqKr7/+GgCwe/dufPbZZ7h06RJ27dqFpKQk5Obmom3btgCAkydPYufOnbC1tS10naioKOTm5iIzMxPPPPOMwT6tVoumTZsWGeOVK1cee9zw4cPRt29fHDt2DF27dkXv3r3Rpk0bo+5J69atpZ+dnZ0RGBiI8+fPA8hfqPuzzz7Db7/9hps3b0Kr1SInJwdqtRpA8fczIyMDUVFRGDJkCN566y3pGnl5eaXqgKxWq1GnTh3puZeXFxITEwHAZNcoLaOSnbt37+L06dPYtWsXtm7dio8++ggKhQKhoaHo1KmTwQugii/A/f7q50KICt/RjIhMLL2YP3TkcsPn9760HsnioW6gMTFGh3T/8nJs27YN+/fvxz///INFixbho48+wqFDh+Dv74+OHTti7NixuHz5Ms6dO4d27drhwoUL2LVrF5KTkxESEiJ90aenp6NHjx6YPXt2oet4eXlJfV82bdqEGjVqGOwvbnWA9Hv3r7jjnn32WVy7dg1///03tm3bhi5dumDkyJGYO3eu8TfnET7//HMsWLAA8+fPR8OGDWFjY4OxY8dCq80fgFLc/Sy4T8uXL0erVq0Mzit/+H1QDCsrK4PnMpkMQggA9+/Vk16j1Iqt9ykBvV4vIiMjRUREhLC0tBQWFhZPespyV92bsbK0ecL/g43C9/2NIiH1EVXcRFTpFduMVYnk5eWJGjVqiC+++EIIkf8d5OzsLF577TXRqlUrIYQQx48fF56enqJr165i4sSJ0rEffvihCAwMFLm5uY88d2pqqlAqleKHH34o8vr79u0TAMSdO3dKddzDli1bJuzs7IQQQty8eVMAEEeOHCn2mIImowebrJKSkoRarZa2Pf/88+KNN96Q9ut0OhEQECB69er1yHM+fD+9vb3F9OnTi4yhJM1YDg4OBsesX79ePJhuPO4aDzNbM9axY8ewa9cu7Nq1C3v37kVaWhoaNmyI0aNHIzQ01FR5GJUTays5fF1sEH0nA5fi0+FuZ23ukIiIAACHDh3Cjh070LVrV7i7u+PQoUO4ffs2goODAeTXGnTo0AGrV6/GhAkTAACNGjVCTk4OduzYgXHjxknnGjlyJJYvX44BAwbgvffeg7OzM65cuYJffvkF33zzDezs7DBhwgS888470Ov1aNeuHTQaDfbt2wd7e3tERETA19cXMpkMGzduRPfu3aFSqUp03OTJk9G8eXM0aNAAOTk52Lhxo/Qa3N3doVKpsGXLFtSsWRPW1tbFNulMnz4dLi4u8PDwwEcffQRXV1f07t0bABAQEIDff/8d+/fvh5OTE+bNm4eEhATUr1+/RPdz2rRpGDNmDBwcHNCtWzfk5OTgyJEjSE5ONriXT6I8rlFIiVOrB8jlchESEiLGjx8v/vzzT6k3emVV3Wt2hBBi6A+Rwvf9jeLb/66aOxQiKgOVtWbn3LlzIjw8XLi5uQmlUinq1asnFi1aZFDmyy+/FADE5s2bpW29evUSlpaW0iijApcuXRJ9+vQRjo6OQqVSiaCgIDF27Fih1+uFEPk1RfPnzxeBgYHCyspKuLm5ifDwcLF7927pHNOnTxeenp5CJpOJiIiIEh03Y8YMERwcLFQqlXB2dha9evUSV6/e/7xdvny5qFWrlrCwsBChD3f0vqegFuWvv/4SDRo0EAqFQrRs2VKcPHlSKnP37l3Rq1cvYWtrK9zd3cXHH38sXnvtNalmpyT3c/Xq1aJJkyZCoVAIJycn0aFDB7Fu3TohhGlqdh53jYeZomZHJsS9hrRSSE1Nhb29vUmTLnNKTU2Fg4MDNBpNlXpdpfHFPxex6N8r6N+iFmb1bWTucIjIxLKzsxEdHQ1/f39YW7P2liqP4t67Jf3+NmpSQXt7e6SkpOCbb77BxIkTkZSUBCC/eevmzZvGnJLMrJ7H/U7KREREVYlRfXZOnTqFLl26wNHRETExMXjrrbfg7OyMdevWITY2Fj/88IOp46QyVpDsXE5I54gsIiKqUoyq2Rk3bhxef/11XL582aBKqXv37tizZ4/JgqPy4+9qA0sLGdJy8hCnyTZ3OERERCZjVLITGRmJYcOGFdpeo0YNxMfHP3FQVP4Ulhbwd7UBAFxkUxYREVUhRiU7SqUSqamphbZfunQJbm5uTxwUmUc9z4KmLCY7RERUdRiV7PTs2RPTp09Hbm4ugPx5DmJjY/H++++jb9++Jg2Qyk+9ezMpX4znshFERFR1GJXsfPHFF0hPT4e7uzuysrIQGhqKunXrws7ODp9++qmpY6RyUrBG1uVE1uwQEVHVYdRoLAcHB2zbtg379u3DyZMnkZ6ejmbNmiEsLMzU8VE5CnhgRJZeL2BhwRFZRERU+ZU62cnNzYVKpcKJEyfQtm1baTVZqvx8ndVQWFogK1eHG8lZ8HFRmzskIiKiJ1bqZiwrKyv4+PhAp9OVRTxkRpZyC9Rxy2/K4ogsIqquBg8eLK01VZ5WrlwJR0fHcr/ug3bt2gWZTIaUlJQKE5MpGNVn56OPPsKHH34ozZxMVUegR36yw5mUiYioX79+uHTpkrnDeGJG9dlZvHgxrly5Am9vb/j6+sLGxsZg/7Fjx0wSHJW/AC4bQUQVnFarhUKhMHcY1YJKpYJKpTJ3GE/MqJqd3r17Y8KECZg4cSIGDhyIXr16GTyo8gqUkh0OPyeiiqFjx44YNWoUxo4dC1dXV4SHhwMA5s2bh4YNG8LGxga1atXCiBEjkJ5+/7OroAlm69atCA4Ohq2tLbp164a4uDipjE6nw7hx4+Do6AgXFxe89957eHh97JycHIwZMwbu7u6wtrZGu3btEBkZKe0vaPrZunUrmjZtCpVKhc6dOyMxMRGbN29GcHAw7O3tMXDgQGRmZj729W7YsAEBAQGwtrZGeHg4rl+/Lu2LiopCr1694OHhAVtbW7Ro0QLbt283OH7JkiXS8R4eHnjxxRelfXq9HjNnzoS/vz9UKhUaN26M33//vchYHm7Gmjp1Kpo0aYJVq1bBz88PDg4O6N+/P9LS7v+BXNprlIti10R/Qj/99JNIT08vy0uYREmXiK8Ort3JEL7vbxQBH/0tcvN05g6HiEwkKytLnDt3TmRlZRXal56eXuTj4fLFlc3MzCxR2dIKDQ0Vtra24t133xUXLlwQFy5cEEII8eWXX4p///1XREdHix07dojAwEAxfPhw6bgVK1YIKysrERYWJiIjI8XRo0dFcHCwGDhwoFRm9uzZwsnJSaxdu1acO3dODBkyRNjZ2YlevXpJZcaMGSO8vb3F33//Lc6ePSsiIiKEk5OTuHv3rhBCiJ07dwoA4umnnxZ79+4Vx44dE3Xr1hWhoaGia9eu4tixY2LPnj3CxcVFzJo1q8jXWRBvSEiI2L9/vzhy5Iho2bKlaNOmjVTmxIkTYtmyZeL06dPi0qVL4uOPPxbW1tbi2rVrQgghIiMjhVwuFz/99JOIiYkRx44dEwsWLJCO/+STT0RQUJDYsmWLiIqKEitWrBBKpVLs2rXL4LUkJydLMTk4OEjHT5kyRdja2ooXXnhBnD59WuzZs0d4enqKDz/8sMTXKK3i3rsl/f4u02THzs5OREVFleUlTILJzn06nV4EfbxZ+L6/UVxJTDN3OERkIsV9YQAo8tG9e3eDsmq1usiyoaGhBmVdXV0fWa60QkNDRdOmTR9bbs2aNcLFxUV6vmLFCgFAXLlyRdr21VdfCQ8PD+m5l5eXmDNnjvQ8NzdX1KxZU0p20tPThZWVlVi9erVURqvVCm9vb+m4ggRh+/btUpmZM2cKAAbfgcOGDRPh4eFFxl8Q78GDB6Vt58+fFwDEoUOHijyuQYMGYtGiRUIIIdauXSvs7e1FampqoXLZ2dlCrVaL/fv3G2wfMmSIGDBggMFrKS7ZUavVBud/9913RatWrUp8jdIyRbJjVJ+dUtQaleXpqQxYWMgQ4GGLUzc0uJyQJo3OIiIyp+bNmxfatn37dsycORMXLlxAamoq8vLykJ2djczMTKjV+VNnqNVq1KlTRzrGy8sLiYmJAACNRoO4uDi0atVK2m9paYmQkBDp+ysqKgq5ubkG06xYWVmhZcuWOH/+vEE8jRo1kn728PCAWq1G7dq1DbYdPny42NdpaWmJFi1aSM+DgoLg6OiI8+fPo2XLlkhPT8fUqVOxadMmxMXFIS8vD1lZWYiNjQUAPPPMM/D19UXt2rXRrVs3dOvWDX369IFarcaVK1eQmZmJZ555xuCaWq0WTZs2LTauB/n5+cHOzk56/uA9NdU1TK1Mkx2qnALc7XDqhgYX49PR7SlzR0NEZe3Bfi4Pk8vlBs8LvtQexcLCsBtoTEzME8X1oIcHwsTExOD555/H8OHD8emnn8LZ2Rl79+7FkCFDoNVqpWTHysrK4DiZTFZmf4g/eC2ZTPbIa+v1+ie6xoQJE7Bt2zbMnTsXdevWhUqlwosvvgitVgsAsLOzw7Fjx7Br1y78888/mDx5MqZOnYrIyEjp97xp0ybUqFHD4LxKpbLEMRT3ukx1DVNjskOFFCwbcYnLRhBVCw8nEuYoW1pHjx6FXq/HF198ISVZv/32W6nO4eDgAC8vLxw6dAgdOnQAAOTl5eHo0aNo1qwZAKBOnTpQKBTYt28ffH19AeRPrhsZGYmxY8ea7gXdk5eXhyNHjqBly5YAgIsXLyIlJQXBwcEAgH379mHw4MHo06cPgPzk4uGk0tLSEmFhYQgLC8OUKVPg6OiIf//9F8888wyUSiViY2MRGhpq8tgBoH79+mV+DWMw2aFCpOHn8Ux2iKhiqlu3LnJzc7Fo0SL06NED+/btw7Jly0p9nrfffhuzZs1CQEAAgoKCMG/ePGlCPSA/YRs+fDjeffddODs7w8fHB3PmzEFmZiaGDBliwleUz8rKCqNHj8bChQthaWmJUaNG4emnn5aSn4CAAKxbtw49evSATCbDpEmTDGqLNm7ciKtXr6JDhw5wcnLC33//Db1ej8DAQNjZ2WHChAl45513oNfr0a5dO2g0Guzbtw/29vaIiIh44vjL4xrGYLJDhRQMP4++kwFtnh4KS6NmKCAiKjONGzfGvHnzMHv2bEycOBEdOnTAzJkz8dprr5XqPOPHj0dcXBwiIiJgYWGBN954A3369IFGo5HKzJo1C3q9Hq+++irS0tIQEhKCrVu3wsnJydQvC2q1Gu+//z4GDhyImzdvon379vj222+l/fPmzcMbb7yBNm3awNXVFe+//z5SU1Ol/Y6Ojli3bh2mTp2K7OxsBAQE4Oeff0aDBg0AADNmzICbmxtmzpyJq1evwtHREc2aNcOHH35ostdQHtcoLZkow17ETz31FDZv3oxatWqV1SVMIjU1FQ4ODtBoNLC3tzd3OGYnhECjqf8gLScPW8d2QKCn3eMPIqIKLTs7G9HR0fD394e1tbW5wyEqseLeuyX9/jb6T/aUlBR88803mDhxorRsxLFjx3Dz5k2pzJkzZyp8okOFyWT5I7IA4OSNFPMGQ0RE9ISMSnZOnTqFevXqYfbs2Zg7d67Uvrlu3TpMnDjRlPGRmYTWcwcA/HXylpkjISIiejJGJTvjxo3D4MGDcfnyZYMqpe7du2PPnj0mC47Mp1cTbwDAvit3kJiWbeZoiIiIjGdUshMZGYlhw4YV2l6jRg3Ex8c/cVBkfn6uNmhSyxF6AWw8Gff4A4iIiCooo5IdpVJp0Pu7wKVLl+Dm5vbEQVHF0Pte7c4fbMoiIqJKzKhkp2fPnpg+fTpyc3MB5HdojY2Nxfvvv4++ffuaNEAyn+cbe0NuIcPJ6ymIvpNh7nCIyASedAZfovJmivesUfPsfPHFF3jxxRfh7u6OrKwshIaGIj4+Hq1bt8ann376xEFRxeBqq0S7uq7Yfek2/jhxE2PD6pk7JCIykkKhgIWFBW7dugU3NzcoFArIZDJzh0VUJCEEtFotbt++DQsLCygUCqPPZVSy4+DggG3btmHv3r04deoU0tPT0axZM4SFhRkdCFVMvZt630t2buHtLgH8cCSqpCwsLODv74+4uDjcusWmaao81Go1fHx8Cq29VhpPNINyu3bt0K5duyc5BVVwXet7QmV1BtF3MnDqhgaNazmaOyQiMpJCoYCPjw/y8vKg0+nMHQ7RY8nlclhaWj7xH9olTnYWLlxY4pOOGTPGqGCo4rFRWuKZ+h748+QtbDhxk8kOUSVXsBr3wytXE1VlJV4uwt/f3+D57du3kZmZCUdHRwD5Myqr1Wq4u7vj6tWrJg+0LHG5iOL9eyEBb6w8AldbJQ5O7AxLOdfKIiIi8zP5chHR0dHS49NPP0WTJk1w/vx5JCUlISkpCefPn0ezZs0wY8YMk7wAqjjaB7jBSW2FO+k52B9119zhEBERlYpRf6JPmjQJixYtQmBgoLQtMDAQX375JT7++GOTBUcVg5XcAs818gIAbDhx8zGliYiIKhajkp24uDjk5eUV2q7T6ZCQkPDEQT3Iz88PMpms0GPkyJEA8ldDHTlyJFxcXGBra4u+ffuaPAYCejepAQDYeiYeWVp2bCQiosrDqGSnS5cuGDZsGI4dOyZtO3r0KIYPH27y4eeRkZGIi4uTHtu2bQMAvPTSSwCAd955B3/99RfWrFmD3bt349atW3jhhRdMGgMBzX2dUNNJhQytDtvPM5kkIqLKw6hk57vvvoOnpydCQkKgVCqhVCrRsmVLeHh44JtvvjFpgG5ubvD09JQeGzduRJ06dRAaGgqNRoNvv/0W8+bNQ+fOndG8eXOsWLEC+/fvx8GDB00aR3Unk8mkxUH/YFMWERFVIkbNs+Pm5oa///4bly5dwvnz5yGTyRAUFIR69cp2hl2tVosff/wR48aNg0wmw9GjR5Gbm2tQmxQUFAQfHx8cOHAATz/99CPPk5OTg5ycHOn5o9b5osJ6N6mBr3ZGYdfF20jO0MLJxvjZLImIiMrLE00qWK9ePQQEBABAucysu2HDBqSkpGDw4MEAgPj4eCgUCmn4ewEPD49iV1+fOXMmpk2bVoaRVk0BHnao72WPc3Gp2HQ6Dq887WvukIiIiB7L6AlTfvjhBzRs2BAqlQoqlQqNGjXCqlWrTBlbId9++y2effZZeHt7P9F5Jk6cCI1GIz2uX79uogirvt5N2ZRFRESVi1E1O/PmzcOkSZMwatQotG3bFgCwd+9e/O9//8OdO3fwzjvvmDRIALh27Rq2b9+OdevWSds8PT2h1WqRkpJiULuTkJAAT0/PIs9V0M+ISq9n4xqYufkCImOScSM5EzWd1OYOiYiIqFhG1ewsWrQIS5cuxezZs9GzZ0/07NkTc+bMwZIlS0q1rERprFixAu7u7njuueekbc2bN4eVlRV27Nghbbt48SJiY2PRunXrMomjuvN0sMbT/i4AgD9OcDFBIiKq+IyeZ6dNmzaFtrdp0wZxcXFPHNTD9Ho9VqxYgYiICFha3q+McnBwwJAhQzBu3Djs3LkTR48exeuvv47WrVsX2TmZntyDTVklXG2EiIjIbIxKdurWrYvffvut0PZff/1V6rBsStu3b0dsbCzeeOONQvu+/PJLPP/88+jbty86dOgAT09Pg6YuMr1uT3lBIbfApYR0nI9LM3c4RERExSrxQqAPWrt2Lfr164ewsDCpz86+ffuwY8cO/Pbbb+jTp4/JAy1LXAi09P636ii2nI3HsA61MbF7sLnDISKiasjkC4E+qG/fvjh06BBcXV2xYcMGbNiwAa6urjh8+HClS3TIOAVNWX+evAW9nk1ZRERUcRk9z07z5s3x448/mjIWqkQ6BrrDztoScZpsHI5JwtO1XcwdEhER0SMZVbNz7NgxnD59Wnr+xx9/oHfv3vjwww+h1WpNFhxVXNZWcnR/Kn8ldM65Q0REFZlRyc6wYcNw6dIlAMDVq1fRr18/qNVqrFmzBu+9955JA6SKq3uj/GRnz6U7Zo6EiIioaEYlO5cuXUKTJk0AAGvWrEFoaCh++uknrFy5EmvXrjVlfFSBtfBzgqWFDDdTsnAjOdPc4RARET2SUcmOEAJ6vR5A/rDw7t27AwBq1aqFO3f4V351oVZY4qkaDgCAQ1eTzBwNERHRoxmV7ISEhOCTTz7BqlWrsHv3bmlW4+joaHh4eJg0QKrYWtV2BgAcir5r5kiIiIgezahkZ/78+Th27BhGjRqFjz76CHXr1gUA/P7774+cWZmqroKlIw5Hs2aHiIgqJqOGnjdq1MhgNFaBzz//HHK5/ImDosqjuZ8TLGRAzN1MJKRmw8Pe2twhERERGTCqZqco1tbWsLKyMuUpqYKzt7ZCfe/8WSsPsXaHiIgqoBInO87OzlLnYycnJzg7Oxf5oOqlpV9+U9ahq+y3Q0REFU+Jm7G+/PJL2NnZAcjvs0NUoFVtZ3y3L5o1O0REVCGVONmJiIh45M9ELf3ya/OuJKbjTnoOXG2VZo6IiIjoPqPXxtLpdFi/fj3Onz8PAKhfvz569eoFS0ujT0mVlJONAoEedriYkIbI6CQ829DL3CERERFJjOqgfPbsWdSrVw8RERFYv3491q9fj4iICAQEBODMmTOmjpEqgfvz7bApi4iIKhajkp0333wTDRo0wI0bN3Ds2DEcO3YM169fR6NGjTB06FBTx0iVQEt/JjtERFQxGdXmdOLECRw5cgROTk7SNicnJ3z66ado0aKFyYKjyqMg2bkQnwpNZi4c1JyCgIiIKgajanbq1auHhISEQtsTExOl2ZSpenG3s0ZtNxsIAUTGsHaHiIgqDqOSnZkzZ2LMmDH4/fffcePGDdy4cQO///47xo4di9mzZyM1NVV6UPXRyp/rZBERUcUjE0KI0h5kYXE/R5LJZADyV0J/+LlMJoNOpzNFnGUqNTUVDg4O0Gg0sLe3N3c4ldaG4zcx9tcTaFzTAX+MamfucIiIqIor6fe3UX12du7caXRgVHUV9Ns5cysV6Tl5sFVyGgIiIjI/o5qxQkNDYWFhgeXLl+ODDz5A3bp1ERoaitjYWMjlcoSGhkoPqj68HVWo5ayCTi9whP12iIiogjAq2Vm7di3Cw8OhUqlw/Phx5OTkAAA0Gg0+++wzkwZIlUsr//x1sg5zCDoREVUQRiU7n3zyCZYtW4bly5cbrHLetm1bHDt2zGTBUeXD+XaIiKiiMSrZuXjxIjp06FBou4ODA1JSUp40JqrEnr5Xs3PqRgqytBW/czoREVV9RiU7np6euHLlSqHte/fuRe3atZ84KKq8ajmr4GlvjVydwPHYZHOHQ0REZFyy89Zbb+Htt9/GoUOHIJPJcOvWLaxevRoTJkzA8OHDTR0jVSIymUxaJ+sgm7KIiKgCMGps8AcffAC9Xo8uXbogMzMTHTp0gFKpxIQJEzB69GhTx0iVTEt/Z/xx4hYOc3JBIiKqAIxKdmQyGT766CO8++67uHLlCtLT01G/fn3Y2tqaOj6qhApGZB2PTUFOng5KS7mZIyIioursiWZ9UygUqF+/vqlioSqijpsNXG0VuJOuxakbGrTwczZ3SEREVI0Z1WeHqDgymez+EPSrbMoiIiLzYrJDZaKgKYvz7RARkbkx2aEyUVCzc/RaMnJ1ejNHQ0RE1RmTHSoTgR52cFRbIVOrw5mbGnOHQ0RE1RiTHSoTFhYyqWMym7KIiMicmOxQmWl1rymLi4ISEZE5MdmhMlPQSTkyOgk6vTBzNEREVF0x2aEyE+xlB1ulJdJy8nA+LtXc4RARUTXFZIfKjKXcAiF+TgDYb4eIiMyHyQ6VKWm+HU4uSEREZsJkh8pUwXw7kTFJ0LPfDhERmQGTHSpTjWo6wNrKAsmZubh6J93c4RARUTXEZIfKlJXcAk95OwAATnNyQSIiMgMmO1TmnqqRn+ycusFkh4iIyh+THSpzjWrmJztcNoKIiMyByQ6VuYY1CpKdVE4uSERE5Y7JDpW52m62UCvkyMrV4eptdlImIqLyxWSHypzcQoYG3vYA2G+HiIjKH5MdKhcFnZQ5IouIiMobkx0qF+ykTERE5sJkh8pFQSfls7fYSZmIiMoXkx0qF/6utrC510k5ip2UiYioHDHZoXKR30mZkwsSEVH5Y7JD5aYh++0QEZEZMNmhctNQWjYixbyBEBFRtcJkh8pNwfDzc3GpyNPpzRwNERFVF0x2qNzUdrWBjUKO7Fw9rrCTMhERlRMmO1RuLCxkaFAwuSA7KRMRUTlhskPlqlENdlImIqLyxWSHylXBiKxTTHaIiKicMNmhclUwIuvcLXZSJiKi8lHhk52bN2/ilVdegYuLC1QqFRo2bIgjR45I+4UQmDx5Mry8vKBSqRAWFobLly+bMWIqjp+LDWyVlsjJ0+NyIjspExFR2avQyU5ycjLatm0LKysrbN68GefOncMXX3wBJycnqcycOXOwcOFCLFu2DIcOHYKNjQ3Cw8ORnZ1txsipKBYWMjxVwx4AV0AnIqLyYWnuAIoze/Zs1KpVCytWrJC2+fv7Sz8LITB//nx8/PHH6NWrFwDghx9+gIeHBzZs2ID+/fuXe8z0eA1rOODg1SScvqHByyG1zB0OERFVcRW6ZufPP/9ESEgIXnrpJbi7u6Np06ZYvny5tD86Ohrx8fEICwuTtjk4OKBVq1Y4cOBAkefNyclBamqqwYPKT8HkgqzZISKi8lChk52rV69i6dKlCAgIwNatWzF8+HCMGTMG33//PQAgPj4eAODh4WFwnIeHh7TvUWbOnAkHBwfpUasWaxfKU6OajgCA83GpyGUnZSIiKmMVOtnR6/Vo1qwZPvvsMzRt2hRDhw7FW2+9hWXLlj3ReSdOnAiNRiM9rl+/bqKIqSR8ndWwK+iknMBOykREVLYqdLLj5eWF+vXrG2wLDg5GbGwsAMDT0xMAkJCQYFAmISFB2vcoSqUS9vb2Bg8qP/mdlDm5IBERlY8Kney0bdsWFy9eNNh26dIl+Pr6AsjvrOzp6YkdO3ZI+1NTU3Ho0CG0bt26XGOl0rk/uWCKeQMhIqIqr0KPxnrnnXfQpk0bfPbZZ3j55Zdx+PBhfP311/j6668BADKZDGPHjsUnn3yCgIAA+Pv7Y9KkSfD29kbv3r3NGzwVq6HUSZmdw4mIqGxV6GSnRYsWWL9+PSZOnIjp06fD398f8+fPx6BBg6Qy7733HjIyMjB06FCkpKSgXbt22LJlC6ytrc0YOT1OQbJT0EnZSl6hKxmJiKgSkwkhhLmDMLfU1FQ4ODhAo9Gw/045EUKg0bR/kJadh01j2qGBt4O5QyIiokqmpN/f/HOazEImk0m1O+ykTEREZYnJDpmN1En5BpMdIiIqO0x2yGxYs0NEROWByQ6Zzf1OymnQ5nEmZSIiKhtMdshsfJzVsLe2hFanx6WENHOHQ0REVRSTHTIbmUwm9dvhoqBERE9Gpxf490ICEtOyzR1KhcNkh8yqYQ1HAEx2iIieRJ5Oj3d+PYE3Vh5B+Jd7sPNiorlDqlCY7JBZsZMyEVVHOXk67Ll0G1P+OINOc3dh6A9HoMnKNepceTo9xv12En+evAUASM7MxesrIjF360Xo9NV+Kj0AFXwGZar6Gt1rxrpwr5OywpL5N1FFptMLxKdmo4ajytyhVDq303Kw82IidpxPwH+X7yBTq5P2Rd/JwNWl+/FdRAv4uKhLfM48nR7j1+QnOpYWMnzZrwkORydh1cFrWLzzCo5eS8aCAU3gble9VxVgskNmVdNJBQeVFTRZubiUkCathk5EFU9yhhZv/nAER68lIyzYAx89Fwx/Vxtzh1Vh5en0uBCfhp0XErH9QiJOXk8x2O9up0SXYHc09XHCvH8u4UpiOnov2YevX22OED/nx55fpxcYv+Yk/jiRn+h8NagZwht4okdjb4T4OWHiutM4cPUunlu4F4sGNMXTtV1KFPeF+FT8FnkDZ29p0L2hFwa28qn0S/pwuQhwuQhze/XbQ/jv8h181qchBrbyMXc4RPQI15MyEbHiMK7ezpC2WcllGNzGD6M6B8BBZVWq8yVlaLHh+E1k5+nQL6QWXGyVpg653AghkJiWgwvxabgYn3rv3zRcTkwvNK1GwxoO6BLsji5BHmjgbQ8LCxkAICE1G29+fwSnb2qgkFtgzouN0LtpjSKvqdMLjP/tBDbcS3QWD2yGbk95GpS5kpiOEauP4lJCOixkwPiugRgeWke65oM0Wbn48+QtrDlyvdBEr7VdbfDBs0F4pr4HZLLCxz7O1dvp+PPkLYzuHAD5I679JEr6/c1kB0x2zG32lgtYuisKA1r6YOYLDc0dDhE95MxNDV5fGYnbaTnwdrDG9F5PYfWha9h58TYAwNlGgfFd66FfSC1YFlMDIIRAZEwyVh+6hs2n46HV5ScCtkpLvNW+Noa094etsuI2OOTp9LiVko2Yuxm4lpSJqMR0nI9LxcWENKRkPrq/jVohR5s6rugS7I7OQe7wsC+6OSlTm4d3fj2BrWcTAABjugTgnbCAQgmGTi8wYc1JrD9+816i0xTdnvIq8pwfbziDdcduAgA6B7lj3suN4ahWQK8XOHj1Ln49ch1bzsQj515iZiWXISzYA0/VcMCKfdG4k64FALT0d8bHzwWjUU3Hx96rnDwdtpyJx8+HY3HwahIA4LvBIegc5PHYY0uDyU4pMNkxr79Px2HE6mN4qoY9No5ub+5wiOgBey7dxvAfjyJDq0OQpx1Wvt4Sng75X9i7LiZixsZziLpX2xPkaYdJz9dH27quBufQZOZi3fEb+OlQLC4npkvbG9ZwgIDAmZupAAAXGwVGd66Lga18Tdp/T68XOHVTgx3nE3AhPg02CjlsrS1hq7SCnbUl7KwtYavMf9hZW0GtkCMxLQfX7mbg2t1MXEvKROzdDNxIzkJeER1+LWSAn6sNgjztEOhhj0BPOwR52sHHWf3ImpTiYp2z9SKW7Y4CADzfyAtzX2oMays5gNIlOgWEEPg18jom/3kW2jw9ajiq0KuJN/48eQs3krOkcoEedni5RS30buIt1bSlZefi/3ZfxfL/rkrJUO8m3pgQHoiaToX7Fl1JTMPPh69j3bEbSL6XAFrIgNB6bhjVOQDNfZ1KfC9KgslOKTDZMa/rSZloP2cnrOQynJkWDqWl3NwhERGAtUdv4P21p5CnF2hTxwXLXm0Oe2vD5qpcnR6rD17Dl9svS6OJCvrzJGdqsfpgLDaeuiV9UaoVcvRs7I2BrXzQqKYj9HqBv8/EYe7Wi4i5mwkAqOWswvhnAtGzsXepEoUHZWl12HvlDnacT8COC4m4nZbzBHfiPoWlBXyd1fB1UcPf1QaBnvYI8rRDXXdbKSExhd8ir+PD9aeRpxdo6uOIr18NgbONAu+uOYl1x29CbiHD4gFN8WzD4hOdB529pcHI1cek+wwAdkpL9GzijX4taqFhDYcim6lupWRh7j8XpRoihaUF3mjrjxGd6kAht8DmM3H4+dB1HI5Jko7xcrBGvxa18HJILXiXUYd2JjulwGTHvIQQaDpjG1Iyc/HXqHbSRINE1ZEQArFJmTh1Q4NzcanIujdiRyYDZJDd+/fec5kMMgB21pYI8rRHsLc9vB2sjepX8XAMS3ZF4fOtFwEAvZp44/MXGxdb25KSqcX87Zex6uA16PQCMhnw4LdLkKcdBj3ti95NvGFnXbh/T65Oj18jr2PBjstSYhLkaYf3uwWhY6BbiV5TvCYbOy4kYMf5ROy7ckdKsADARiFHh3puaOnvjDydQFpOHtKz85Cek4u07Dyk5+RJ/2bk5MHFVgFfZxv4uuQnNj7ONvBzVcPDztroBKy0DkTdxf9+PApNVi5qOKrQqKYDNp+JNyrRKZCanYsZf51DYloO+jStgfAGnlApSp6knbmpwSebzklNU05qK+j0AqnZeQAAuYUMnYPcMaBlLYTWczd5H52HMdkpBSY75lfQSfmT3k/hlad9zR0OUbkQQuCWJhunb6Tg5A0NTt/Q4PRNjdHzrQCAg8oKQZ52CPayR30ve9T3ti9VrYNOLzDlzzP48WAsAGBYh9p4v1tQib/grySmYcbG89h96TaUlhboca8Wp2ktxxIlLJnaPKzYF4Nlu6OQdu8LtLmvE3yd1cjJ0yMnTw+tTo+cXB20Oj2097Zl5+oMmmQAoIajCmHB7ugS7IFWtZ0rZa3x1dvpeGNlpFQb8ySJjqkIIbDjfCI+23xe6rBew1GF/i1q4aWQWlIzZ3lgslMK0s26devRN0suB6wf+OVlZBQuU8DCAlCpjCubmWn4p9CDZDJArTaubFYWoC9moU0bG+PKZmcDOp1Jys7ffwPzd1xB27ouWP1qUyAvr+jzqtX5rxEAcnKKL6tS5d9nANBqgdxivkRKU9baOv99Udqyubn55YuiVAKWlqUvm5eXfy+KolAAVlalL6vT5f/uimJllV++tGX1+vz3minKWlrm3wsg//9EZqZpypbm/30xZYUQSM3Kw42UTNxKzsaN1GzEZglcvZ2BMzc1yExOLXQ6hdwCgZ62CK7hCDsnewgICAHIs7MAISCEgLh3biGApIxcXEhIw9mUPKlPiXVuNmT3PiLkFjL4u6jh5aSCu60S7vbWcHZ3goe9NTzslfCwEnBRWSLvXn+QHecTIZMBE58Nwqut/Yz6jLielAl7mQ4OimL63hTzGZGcocU3e6/ix4Ox0ObpkWWllP7fK/JyIdcX/jyRyfL7AbVv7IOwBp4I9LCDTKut9J8RyRlaTFhzEsdjU/BJv+bo3qxWkWUNlPFnRK5Oj51n42Ar8vB0bZdHJ8Rl/BlR4soKQUKj0QgAQpP/8Vf40b274QFq9aPLAUKEhhqWdXUtumxIiGFZX9+iy9avb1i2fv2iy/r6GpYNCSm6rKurYdnQ0KLLqtWGZbt3L7rsw2+tF18stuzNG7eF/wcbhe/7G0XKywOLP29i4v3zjhhRfNno6PtlJ0wovuyZM/fLTplSfNnDh++XnTOn+LI7d94vu3hx8WU3brxfdsWK4sv+9tv9sr/9VnzZFSvul924sfiyixffL7tzZ/Fl58y5X/bw4eLLTplyv+yZM8WXnTDhftno6OLLjhhxv2xiYvFlIyLul01PL77siy8KA8WVvfcZEXMnXaw6ECNylKoiyx6o9ZTwfX+j9Lirsi/6vKX8jMjOzRNnbqaINUeui8RadYose93e3SCGE54BRZ+3gnxGfLP5lPhu71Wx+uA1Ef188WX5GXHvUQ0+I6Tvb41GFKfijvGjasXbUYXwBp7YfCYeV26no7m5A6IqTwiB4hpVtHl6KEp4rgvxaXhrzr+4npT/l+gL+qKPdbZVYliH2qjlrMZTNRzg9K0CKOYP2NJQWsrRwNsBDbwdALui562xUVrimfoeSEzNRkJqTrH3oaIY0r72/ZogF05kSKXDZiywGasiNGNBrcah6CT0+/og7GQ67B3XAQ7qIiYpYzNW4bJl1IyVkZmDeX+dxE+HrgMAXGwVaFzLEY1rOqBxTUc85ecKG7t777VK0Iwl5HKcup2NLWfjseV0HOLjkoosq7ewgIe7I5r6OKJJLUc0c7FCXXc7nL2lwYGou9gXdRdnb2qgF/llcywVsJLL0NTHCa3clfB2VKGGozVqOKrh7ai63wm0An5G6DIycTctC7fTcuDrYlN4rpsK8hlR4v/3/IwoXLaKNnWzz04psINyxSCEQPeFe3E+LhUTnw3CsNA65g6pWjsQdRfvrT0p1VZYWsgKzTFiIQOCPO3R1McRTX2c0MzHEf6uNk88GsiUdHqBIzFJ2HwmHv+cjcctzf0PW4XcAu0DXBH+lCfqedjh9E0NTsSm4Pj1ZIOZgotT190W7QNc0T7AFa38XWBTgSfFI6pqmOyUApOdiuO3yOt4b+0p1HBUYfe7HYudjZUKE0Lg9E0N/jxxC3+fjoNMJkP/FrUwoJUPXEs4HX9GTh5mb7mAHw5cA5A/ymJ230YI8XPCmZsaHL+XDByPTUGcpvBfae52Sjxd2+Xew7nMkx+9XuB2eg5upmThZnIWbqVkST/fTMnCjeQspOfc/8terZCjU6A7uj3liY6Bbo8cBg3kT4R38kYKTly//0jK0MLFRoF2Aa5oV9cV7QJc4eXABTGJzIXJTikw2ak4snN1aDPrXyRlaLHsleaF1nqhR7uSmL/2zF8nbyH6TuEaCYU8fwjw4DZ+xc5jtD/qDt5fe0qqzRnYygcTnw0qMiGI02ThRGwKjsUm41hsCk7f0EhLABR4XPKj0wtk5eqQqc1DZo4OmVodsnLz5zxJzc5DalYuUrNzocnKRWpWHlKzc/O3ZeUiKVOLeE02cnXFf4w5qKwQFuyBbk95on2Aq1GTvwkhcDdDC2e1otzmWSGi4jHZKQUmOxXL51sv4KudUXi6tjN+Gdra3OGUC71e4MwtDf69kIhrdzPhYqOAu70S7nbWBv/aKS2lROFWShY2nrqFP07cwtlb94cvW1tZoEuwB3o29kZ2rg4r9sXgxAOrLYf4OmFwWz+EN/CUVjLOyMnDrM0XsOqgYW1OuwDDaf8fJztXh+OxKTh49S4OXr2L47EphZIfV1sllJYW+cmNVmcw8Zux5BYyeNpbw9vRGjUcVfn9ZZzu/euogr+rTaVftZmICmOyUwpMdiqWOE0W2s3eCZ1eYPPb7RHsVTV/J2nZufjv8h3svJCInRdv407646ezt7aygIe9NVRWclyIT5O2W1rI0D7AFb2a1EBYfY9CHUyPxybj+/0x2HQ6TqoF8bS3xitP+yDQ0x7TN541qM35sHuwSRZkLEnyU0AmA9RWcqgUllAr5LBRWsJBZQl7ayvYq6zgoLK697Ol9LOj2gpejip42CnZ5ElUDTHZKQUmOxXPyJ+OYdOpOPRvUQuz+jYydzgmIYRA1O0M7LyQiH8vJCIyJsmgw6+NQo52Aa5oVNMRKZlaJKblIDE1B4lp2UhMzUFaTuERJS39ndGzsTe6N/SCs83jB0onpmZj9aFYrD4UWyi5MrY2pzSyc3U4H5cKmUwGtUIOlVV+UqNWyKG0tKhQHZuJqOJjslMKTHYqniMxSXhx2QEoLS1wYGKXEn2RV2T7r9zB1L/O4lJCusF2f1cbdAp0R+cgd7Twdyp2OvssrS4/8UnLQVKGFg1rOBi9uF5Ong5/n47Dyn0xOHVTgwEtTVebQ0RUXkr6/c1PNqqQmvs64aka9jhzMxW/RMZiRMe65g7JKCmZWnz293n8duQGgPyOwq1qO6NToDs6BbnD37Xkk6OpFHL4utjA1wQTqikt5ejTtCb6NK2JLK2uVAsBEhFVNkx2qEKSyWQY3MYfE9acxKoD1zC0fe1K1SdDCIFNp+Mw9c+zuJOeP+nXK0/74N3wIDioipgs0UyY6BBRVVd5vj2o2nm+kRdcbBSI02Tjn3MJ5g6nxG6lZOGtH45g1E/HcSddizpuNljzv9b4pHfDCpfoEBFVB0x2qMKytpJjYCsfAMDKfTHmDaYE9HqBHw7E4Jl5u7H9fCKs5DK83SUAf7/dHi38nM0dHhFRtcVmLKrQBrXyxdJdUTgck4QzNzV4qkbRE+KZ06WENHyw9hSOxaYAAJr5OGJW30ao52Fn3sCIiIg1O1SxeTpY49mGXgCA7/fHmDeYIqw6eA3PLfwPx2JTYKOQY3qvBvj9f22Y6BARVRBMdqjCG9zGDwDwx8lbuFuCiffKixACc7dexKQNZ5CrE+gS5I5t40LxWms/LidARFSBMNmhCq+ZjyMa1XSANk+Pnw/HmjscAECeTo/3157C4p1XAADjnqmHbyJCjJ73hoiIyg6THarwZDIZXm/rByC/ySi3iOUGykuWVodhq47ityM3YCEDZr7QEGO6BHD2XyKiCorJDlUK3Rt6wdVWiYTUHGw5E2+2OJIztBj0zUHsuJAIpaUFlr3SHANa+pgtHiIiejwmO1QpKC3lGHRvGPrif68gKUNb7jHcTMnCi8v241hsChxUVlj9Zit0beBZ7nEQEVHpMNmhSmPQ0z6wt7bExYQ09Fy8F+fjUsvt2hfiU/HCkn2Iup0BLwdrrPlfa4Rw7hwiokqByQ5VGu521vh9eBv4OKtxIzkLfZfux9azZd+kdejqXby07AASUnNQz8MW60ZwWDkRUWXCVc/BVc8rm+QMLUb+dAz7o+4CAMY/Uw+jOtctdQfhnDwd0rLzkKXVIVOrQ6b2gZ9zdcjS5iExNQeLdl6BNk+PFn5O+Oa1FnBQc8kHIqKKoKTf30x2wGSnMsrV6fHppvNYeW+iwecaeuHzlxpBrSh+UnAhBA5cvYufDsVi69l45OpK9vZ/pr4HFg1oCmsrLppJRFRRlPT7m8tFUKVkJbfA1J4NEOhph8l/nMGm03GIuZuBr18LQY1HzHWTlKHF2qM38PPhWFy9k2Gwz9rKAmqFJVRWctgo5VApLKG2kkOtkEOlkKNhDQcMaedfqVZdJyKi+1izA9bsVHaHo5Mw/MejuJuhhautAsteaY4QP2cIIRAZk4zVh65h8+l4aO/Nz2OjkKNX0xoY2NIH9b3sOdsxEVElxWasUmCyU/ndSM7EWz8cxfm4VFjJZXjlaV/8d/kOriSmS2WeqmGPgS190bOJN2yVrNQkIqrsmOyUApOdqiFTm4cJa07i79P3R2ipFXL0bOyNga180Kimo/mCIyIik2OfHap21ApLfDWwGZbtvopdFxPxfGNv9G7iDTtrjp4iIqrOWLMD1uwQERFVRiX9/ubwEiIiIqrSmOwQERFRlcZkh4iIiKo0JjtERERUpTHZISIioiqNyQ4RERFVaUx2iIiIqEpjskNERERVGpMdIiIiqtKY7BAREVGVxmSHiIiIqjQmO0RERFSlMdkhIiKiKo3JDhEREVVpluYOoCIQQgDIXyqeiIiIKoeC7+2C7/GiMNkBkJaWBgCoVauWmSMhIiKi0kpLS4ODg0OR+2XicelQNaDX63Hr1i3Y2dlBJpOV6JjU1FTUqlUL169fh729fRlHSAV4382D9908eN/Ng/fdPIy570IIpKWlwdvbGxYWRffMYc0OAAsLC9SsWdOoY+3t7fmfwQx4382D9908eN/Ng/fdPEp734ur0SnADspERERUpTHZISIioiqNyY6RlEolpkyZAqVSae5QqhXed/PgfTcP3nfz4H03j7K87+ygTERERFUaa3aIiIioSmOyQ0RERFUakx0iIiKq0pjsEBERUZXGZMcIX331Ffz8/GBtbY1WrVrh8OHD5g6pytmzZw969OgBb29vyGQybNiwwWC/EAKTJ0+Gl5cXVCoVwsLCcPnyZfMEW0XMnDkTLVq0gJ2dHdzd3dG7d29cvHjRoEx2djZGjhwJFxcX2Nraom/fvkhISDBTxFXD0qVL0ahRI2kitdatW2Pz5s3Sft7z8jFr1izIZDKMHTtW2sZ7b3pTp06FTCYzeAQFBUn7y+qeM9kppV9//RXjxo3DlClTcOzYMTRu3Bjh4eFITEw0d2hVSkZGBho3boyvvvrqkfvnzJmDhQsXYtmyZTh06BBsbGwQHh6O7Ozsco606ti9ezdGjhyJgwcPYtu2bcjNzUXXrl2RkZEhlXnnnXfw119/Yc2aNdi9ezdu3bqFF154wYxRV341a9bErFmzcPToURw5cgSdO3dGr169cPbsWQC85+UhMjIS//d//4dGjRoZbOe9LxsNGjRAXFyc9Ni7d6+0r8zuuaBSadmypRg5cqT0XKfTCW9vbzFz5kwzRlW1ARDr16+Xnuv1euHp6Sk+//xzaVtKSopQKpXi559/NkOEVVNiYqIAIHbv3i2EyL/HVlZWYs2aNVKZ8+fPCwDiwIED5gqzSnJychLffPMN73k5SEtLEwEBAWLbtm0iNDRUvP3220IIvt/LypQpU0Tjxo0fua8s7zlrdkpBq9Xi6NGjCAsLk7ZZWFggLCwMBw4cMGNk1Ut0dDTi4+MNfg8ODg5o1aoVfw8mpNFoAADOzs4AgKNHjyI3N9fgvgcFBcHHx4f33UR0Oh1++eUXZGRkoHXr1rzn5WDkyJF47rnnDO4xwPd7Wbp8+TK8vb1Ru3ZtDBo0CLGxsQDK9p5zIdBSuHPnDnQ6HTw8PAy2e3h44MKFC2aKqvqJj48HgEf+Hgr20ZPR6/UYO3Ys2rZti6eeegpA/n1XKBRwdHQ0KMv7/uROnz6N1q1bIzs7G7a2tli/fj3q16+PEydO8J6XoV9++QXHjh1DZGRkoX18v5eNVq1aYeXKlQgMDERcXBymTZuG9u3b48yZM2V6z5nsEFEhI0eOxJkzZwza0qnsBAYG4sSJE9BoNPj9998RERGB3bt3mzusKu369et4++23sW3bNlhbW5s7nGrj2WeflX5u1KgRWrVqBV9fX/z2229QqVRldl02Y5WCq6sr5HJ5oZ7hCQkJ8PT0NFNU1U/BvebvoWyMGjUKGzduxM6dO1GzZk1pu6enJ7RaLVJSUgzK874/OYVCgbp166J58+aYOXMmGjdujAULFvCel6GjR48iMTERzZo1g6WlJSwtLbF7924sXLgQlpaW8PDw4L0vB46OjqhXrx6uXLlSpu93JjuloFAo0Lx5c+zYsUPaptfrsWPHDrRu3dqMkVUv/v7+8PT0NPg9pKam4tChQ/w9PAEhBEaNGoX169fj33//hb+/v8H+5s2bw8rKyuC+X7x4EbGxsbzvJqbX65GTk8N7Xoa6dOmC06dP48SJE9IjJCQEgwYNkn7mvS976enpiIqKgpeXV9m+35+oe3M19MsvvwilUilWrlwpzp07J4YOHSocHR1FfHy8uUOrUtLS0sTx48fF8ePHBQAxb948cfz4cXHt2jUhhBCzZs0Sjo6O4o8//hCnTp0SvXr1Ev7+/iIrK8vMkVdew4cPFw4ODmLXrl0iLi5OemRmZkpl/ve//wkfHx/x77//iiNHjojWrVuL1q1bmzHqyu+DDz4Qu3fvFtHR0eLUqVPigw8+EDKZTPzzzz9CCN7z8vTgaCwheO/Lwvjx48WuXbtEdHS02LdvnwgLCxOurq4iMTFRCFF295zJjhEWLVokfHx8hEKhEC1bthQHDx40d0hVzs6dOwWAQo+IiAghRP7w80mTJgkPDw+hVCpFly5dxMWLF80bdCX3qPsNQKxYsUIqk5WVJUaMGCGcnJyEWq0Wffr0EXFxceYLugp44403hK+vr1AoFMLNzU106dJFSnSE4D0vTw8nO7z3ptevXz/h5eUlFAqFqFGjhujXr5+4cuWKtL+s7rlMCCGerG6IiIiIqOJinx0iIiKq0pjsEBERUZXGZIeIiIiqNCY7REREVKUx2SEiIqIqjckOERERVWlMdoiIiKhKY7JDRE/Mz88P8+fPL3H5Xbt2QSaTFVoDpyx17NgRY8eOLbfrlZRMJsOGDRvMHQZRlcZJBYmqqY4dO6JJkyalSlKKcvv2bdjY2ECtVpeovFarRVJSEjw8PCCTyZ74+iWRlJQEKysr2NnZAchP0MaOHVtuCdDUqVOxYcMGnDhxwmB7fHw8nJycoFQqyyUOourI0twBEFHFJISATqeDpeXjPybc3NxKdW6FQlHuK0c7OzuXyXm1Wi0UCoXRx3MFbaKyx2Ysompo8ODB2L17NxYsWACZTAaZTIaVK1dCJpNh8+bNaN68OZRKJfbu3YuoqCj06tULHh4esLW1RYsWLbB9+3aD8z3cjCWTyfDNN9+gT58+UKvVCAgIwJ9//intf7gZa+XKlXB0dMTWrVsRHBwMW1tbdOvWDXFxcdIxeXl5GDNmDBwdHeHi4oL3338fERER6N27d4le84PNWB07dsS1a9fwzjvvSK+/wN69e9G+fXuoVCrUqlULY8aMQUZGhsFrnTFjBl577TXY29tj6NChAID3338f9erVg1qtRu3atTFp0iTk5uZKr2/atGk4efKkwf0uuFcPNmOdPn0anTt3hkqlgouLC4YOHYr09HSD313v3r0xd+5ceHl5wcXFBSNHjpSuRUSFMdkhqoYWLFiA1q1b46233kJcXBzi4uJQq1YtAMAHH3yAWbNm4fz582jUqBHS09PRvXt37NixA8ePH0e3bt3Qo0cPxMbGFnuNadOm4eWXX8apU6fQvXt3DBo0CElJSUWWz8zMxNy5c7Fq1Srs2bMHsbGxmDBhgrR/9uzZWL16NVasWIF9+/YhNTXV6L4u69atQ82aNTF9+nTp9QNAVFQUunXrhr59++LUqVP49ddfsXfvXowaNcrg+Llz56Jx48Y4fvw4Jk2aBACws7PDypUrce7cOSxYsADLly/Hl19+CQDo168fxo8fjwYNGkjX69evX6G4MjIyEB4eDicnJ0RGRmLNmjXYvn17oevv3LkTUVFR2LlzJ77//nusXLlSSp6I6BGeeClRIqqUHl7huWCl+Q0bNjz22AYNGohFixZJz319fcWXX34pPQcgPv74Y+l5enq6ACA2b95scK3k5GQhhBArVqwQAAxWP/7qq6+Eh4eH9NzDw0N8/vnn0vO8vDzh4+MjevXqZdTrfThmIYQYMmSIGDp0qMG2//77T1hYWIisrCzpuN69ez/2ep9//rlo3ry59HzKlCmicePGhcoBEOvXrxdCCPH1118LJycnkZ6eLu3ftGmTsLCwEPHx8UIIISIiIoSvr6/Iy8uTyrz00kuiX79+j42JqLpinx0iMhASEmLwPD09HVOnTsWmTZsQFxeHvLw8ZGVlPbZmp1GjRtLPNjY2sLe3R2JiYpHl1Wo16tSpIz338vKSyms0GiQkJKBly5bSfrlcjubNm0Ov15fq9RXn5MmTOHXqFFavXi1tE0JAr9cjOjoawcHBAArfIwD49ddfsXDhQkRFRSE9PR15eXmwt7cv1fXPnz+Pxo0bw8bGRtrWtm1b6PV6XLx4ER4eHgCABg0aQC6XS2W8vLxw+vTpUl2LqDphskNEBh78ogWACRMmYNu2bZg7dy7q1q0LlUqFF198EVqtttjzWFlZGTyXyWTFJiaPKi/KebBoeno6hg0bhjFjxhTa5+PjI/388D06cOAABg0ahGnTpiE8PBwODg745Zdf8MUXX5RJnKW9t0TVHZMdompKoVBAp9M9tty+ffswePBg9OnTB0B+QhATE1PG0RlycHCAh4cHIiMj0aFDBwCATqfDsWPH0KRJE6PO+ajX36xZM5w7dw5169Yt1bn2798PX19ffPTRR9K2a9euPfZ6DwsODsbKlSuRkZEhJVT79u2DhYUFAgMDSxUTEd3HDspE1ZSfnx8OHTqEmJgY3Llzp8iagYCAAKxbtw4nTpzAyZMnMXDgQLPUIowePRozZ87EH3/8gYsXL+Ltt99GcnKy0fP0+Pn5Yc+ePbh58ybu3LkDIH9E1f79+zFq1CicOHECly9fxh9//FGog/DDAgICEBsbi19++QVRUVFYuHAh1q9fX+h60dHROHHiBO7cuYOcnJxC5xk0aBCsra0RERGBM2fOYOfOnRg9ejReffVVqQmLiEqPyQ5RNTVhwgTI5XLUr18fbm5uRfbBmTdvHpycnNCmTRv06NED4eHhaNasWTlHm5+IDBgwAK+99hpat24NW1tbhIeHw9ra2qjzTZ8+HTExMahTp440T1CjRo2we/duXLp0Ce3bt0fTpk0xefJkeHt7F3uunj174p133sGoUaPQpEkT7N+/XxqlVaBv377o1q0bOnXqBDc3N/z888+FzqNWq7F161YkJSWhRYsWePHFF9GlSxcsXrzYqNdIRPk4gzIRVUp6vR7BwcF4+eWXMWPGDHOHQ0QVGPvsEFGlcO3aNfzzzz8IDQ1FTk4OFi9ejOjoaAwcONDcoRFRBcdmLCKqFCwsLLBy5Uq0aNECbdu2xenTp7F9+3YEBwcjNjYWtra2RT4eN0yeiKo2NmMRUaWXl5dX7AgxPz+/Eq3xRURVE5MdIiIiqtLYjEVERERVGpMdIiIiqtKY7BAREVGVxmSHiIiIqjQmO0RERFSlMdkhIiKiKo3JDhEREVVpTHaIiIioSvt/tFf0GMF7xpAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data=df, x=\"training_iteration\", y=\"episode_reward_mean\", label=\"bandits\")\n",
    "plt.axhline(sweetest_baseline, color=\"red\", linestyle='--', label=\"sweetest baseline\")\n",
    "plt.axhline(random_baseline, color=\"k\", linestyle='--', label=\"random baseline\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Bandits training performance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the Bandit Training results to Baseline\n",
    "- Bandit Mean Reward=~56 \n",
    "- Kaleist (Argmin) Baseline Mean Reward = ~10.87+/-0.26\n",
    "- Random Baseline Mean Reward = ~99.90+/-23.75\n",
    "- Sweetest (Argmax) Baseline Mean Reward = ~56.56+/-1.37\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "      <b>Bandit mean reward is approx the same as the sweetest baseline!</b> \n",
    "</div>  \n",
    "\n",
    "Try the code block below to compare what the bandit recommends with what is the sweetest item... you will see that the bandit always recommends the sweetest item!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_disable_action_flattening': False,\n",
      " '_disable_execution_plan_api': True,\n",
      " '_disable_preprocessor_api': False,\n",
      " '_fake_gpus': False,\n",
      " '_tf_policy_handles_more_than_one_loss': False,\n",
      " 'action_space': None,\n",
      " 'actions_in_input_normalized': False,\n",
      " 'adam_epsilon': 1e-08,\n",
      " 'always_attach_evaluation_results': False,\n",
      " 'batch_mode': 'complete_episodes',\n",
      " 'before_learn_on_batch': None,\n",
      " 'buffer_size': -1,\n",
      " 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
      " 'clip_actions': False,\n",
      " 'clip_rewards': None,\n",
      " 'collect_metrics_timeout': -1,\n",
      " 'compress_observations': False,\n",
      " 'create_env_on_driver': True,\n",
      " 'custom_eval_function': None,\n",
      " 'custom_resources_per_worker': {},\n",
      " 'disable_env_checking': False,\n",
      " 'double_q': True,\n",
      " 'dueling': False,\n",
      " 'eager_max_retraces': 20,\n",
      " 'eager_tracing': False,\n",
      " 'enable_connectors': False,\n",
      " 'enable_tf1_exec_eagerly': False,\n",
      " 'env': 'modified-lts',\n",
      " 'env_config': {'num_candidates': 20,\n",
      "                'resample_documents': True,\n",
      "                'reward_scale': 1.0,\n",
      "                'seed': 0,\n",
      "                'slate_size': 1},\n",
      " 'env_task_fn': None,\n",
      " 'evaluation_config': {'explore': False},\n",
      " 'evaluation_duration': 100,\n",
      " 'evaluation_duration_unit': 'episodes',\n",
      " 'evaluation_interval': 1,\n",
      " 'evaluation_num_episodes': -1,\n",
      " 'evaluation_num_workers': 0,\n",
      " 'evaluation_parallel_to_training': True,\n",
      " 'evaluation_sample_timeout_s': 180.0,\n",
      " 'exploration_config': {'epsilon_timesteps': 10000,\n",
      "                        'final_epsilon': 0.02,\n",
      "                        'initial_epsilon': 1.0,\n",
      "                        'type': 'EpsilonGreedy'},\n",
      " 'explore': True,\n",
      " 'extra_python_environs_for_driver': {},\n",
      " 'extra_python_environs_for_worker': {},\n",
      " 'fake_sampler': False,\n",
      " 'framework': 'torch',\n",
      " 'gamma': 0.0,\n",
      " 'grad_clip': 40,\n",
      " 'hiddens': [256],\n",
      " 'horizon': None,\n",
      " 'ignore_worker_failures': False,\n",
      " 'in_evaluation': False,\n",
      " 'input': 'sampler',\n",
      " 'input_config': {},\n",
      " 'input_evaluation': -1,\n",
      " 'keep_per_episode_custom_metrics': False,\n",
      " 'learning_starts': -1,\n",
      " 'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                           'intra_op_parallelism_threads': 8},\n",
      " 'log_level': 'ERROR',\n",
      " 'log_sys_usage': True,\n",
      " 'logger_config': None,\n",
      " 'logger_creator': None,\n",
      " 'lr': 0.0003,\n",
      " 'lr_schedule': None,\n",
      " 'metrics_episode_collection_timeout_s': 60.0,\n",
      " 'metrics_num_episodes_for_smoothing': 100,\n",
      " 'metrics_smoothing_episodes': -1,\n",
      " 'min_iter_time_s': -1,\n",
      " 'min_sample_timesteps_per_iteration': 0,\n",
      " 'min_sample_timesteps_per_reporting': -1,\n",
      " 'min_time_s_per_iteration': 0,\n",
      " 'min_time_s_per_reporting': -1,\n",
      " 'min_train_timesteps_per_iteration': 0,\n",
      " 'min_train_timesteps_per_reporting': -1,\n",
      " 'model': {'fcnet_activation': 'relu', 'fcnet_hiddens': [1024, 1024, 1024]},\n",
      " 'monitor': -1,\n",
      " 'multiagent': {'count_steps_by': 'env_steps',\n",
      "                'observation_fn': None,\n",
      "                'policies': {},\n",
      "                'policies_to_train': None,\n",
      "                'policy_map_cache': None,\n",
      "                'policy_map_capacity': 100,\n",
      "                'policy_mapping_fn': None,\n",
      "                'replay_mode': 'independent'},\n",
      " 'n_step': 1,\n",
      " 'no_done_at_end': False,\n",
      " 'noisy': False,\n",
      " 'normalize_actions': True,\n",
      " 'num_atoms': 1,\n",
      " 'num_consecutive_worker_failures_tolerance': 100,\n",
      " 'num_cpus_for_driver': 1,\n",
      " 'num_cpus_per_worker': 1,\n",
      " 'num_envs_per_worker': 1,\n",
      " 'num_gpus': 0,\n",
      " 'num_gpus_per_worker': 0,\n",
      " 'num_workers': 1,\n",
      " 'observation_filter': 'NoFilter',\n",
      " 'observation_space': None,\n",
      " 'off_policy_estimation_methods': {},\n",
      " 'optimizer': {},\n",
      " 'output': None,\n",
      " 'output_compress_columns': ['obs', 'new_obs'],\n",
      " 'output_config': {},\n",
      " 'output_max_file_size': 67108864,\n",
      " 'placement_strategy': 'PACK',\n",
      " 'postprocess_inputs': False,\n",
      " 'preprocessor_pref': 'deepmind',\n",
      " 'prioritized_replay': -1,\n",
      " 'prioritized_replay_alpha': -1,\n",
      " 'prioritized_replay_beta': -1,\n",
      " 'prioritized_replay_eps': -1,\n",
      " 'recreate_failed_workers': False,\n",
      " 'remote_env_batch_wait_ms': 0,\n",
      " 'remote_worker_envs': False,\n",
      " 'render_env': False,\n",
      " 'replay_batch_size': -1,\n",
      " 'replay_buffer_config': {'capacity': 512, 'learning_starts': 0},\n",
      " 'replay_sequence_length': None,\n",
      " 'restart_failed_sub_environments': False,\n",
      " 'rollout_fragment_length': 512,\n",
      " 'sample_async': False,\n",
      " 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      " 'sampler_perf_stats_ema_coef': None,\n",
      " 'seed': 0,\n",
      " 'shuffle_buffer_size': 0,\n",
      " 'sigma0': 0.5,\n",
      " 'simple_optimizer': -1,\n",
      " 'soft_horizon': False,\n",
      " 'store_buffer_in_checkpoints': False,\n",
      " 'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
      " 'synchronize_filters': True,\n",
      " 'target_network_update_freq': 512,\n",
      " 'tf_session_args': {'allow_soft_placement': True,\n",
      "                     'device_count': {'CPU': 1},\n",
      "                     'gpu_options': {'allow_growth': True},\n",
      "                     'inter_op_parallelism_threads': 2,\n",
      "                     'intra_op_parallelism_threads': 2,\n",
      "                     'log_device_placement': False},\n",
      " 'timesteps_per_iteration': -1,\n",
      " 'train_batch_size': 512,\n",
      " 'training_intensity': None,\n",
      " 'v_max': 10.0,\n",
      " 'v_min': -10.0,\n",
      " 'validate_workers_after_construction': True}\n"
     ]
    }
   ],
   "source": [
    "# build the algorithm and load from checkpoint\n",
    "with open(\"saved_runs/bandits/params.pkl\", 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "\n",
    "pprint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/rllib/utils/debug/deterministic.py:42: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(torch.__version__) >= LooseVersion(\"1.8.0\"):\n",
      "2022-09-14 13:51:40,621\tWARNING algorithm.py:2114 -- `evaluation_parallel_to_training` can only be done if `evaluation_num_workers` > 0! Setting `evaluation_parallel_to_training` to False.\n",
      "2022-09-14 13:51:40,623\tWARNING deprecation.py:47 -- DeprecationWarning: `config['multiagent']['replay_mode']` has been deprecated. config['replay_buffer_config']['replay_mode'] This will raise an error in the future!\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/_private/ray_option_utils.py:266: DeprecationWarning: Setting 'object_store_memory' for actors is deprecated since it doesn't actually reserve the required object store memory. Use object spilling that's enabled by default (https://docs.ray.io/en/releases-2.0.0/ray-core/objects/object-spilling.html) instead to bypass the object store memory size limitation.\n",
      "  warnings.warn(\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   _ATTRVALUE_LISTVALUE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   import imp\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:36: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   'nearest': pil_image.NEAREST,\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:37: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   'bilinear': pil_image.BILINEAR,\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:38: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   'bicubic': pil_image.BICUBIC,\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:39: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   'hamming': pil_image.HAMMING,\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:40: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   'box': pil_image.BOX,\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:41: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   'lanczos': pil_image.LANCZOS,\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow_probability/__init__.py:58: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow_probability/python/mcmc/sample_halton_sequence.py:374: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\u001b[2m\u001b[36m(pid=85570)\u001b[0m   sieve = np.ones(n // 3 + (n % 6 == 2), dtype=np.bool)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/gin/tf/__init__.py:48: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=85570)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=85570)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/rllib/utils/debug/deterministic.py:42: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=85570)\u001b[0m   if LooseVersion(torch.__version__) >= LooseVersion(\"1.8.0\"):\n",
      "2022-09-14 13:51:48,887\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DQN"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_algo = DQN(params)\n",
    "bandit_algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not recover from checkpoint as it does not exist on local disk and was not available on cloud storage or another Ray node. Got checkpoint path: saved_runs/bandits/checkpoint_000097 and IP None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/kourosh/dev/anyscale_academy/ray-rllib/acm_recsys_tutorial_2022/01_anyscale_acm_recsys_tutorial_dryrun_1_sol.ipynb Cell 43\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kourosh/dev/anyscale_academy/ray-rllib/acm_recsys_tutorial_2022/01_anyscale_acm_recsys_tutorial_dryrun_1_sol.ipynb#X60sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Load the checkpoint from the result folder of your running script\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kourosh/dev/anyscale_academy/ray-rllib/acm_recsys_tutorial_2022/01_anyscale_acm_recsys_tutorial_dryrun_1_sol.ipynb#X60sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m checkpoint \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msaved_runs/bandits/checkpoint_000097\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kourosh/dev/anyscale_academy/ray-rllib/acm_recsys_tutorial_2022/01_anyscale_acm_recsys_tutorial_dryrun_1_sol.ipynb#X60sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m bandit_algo\u001b[39m.\u001b[39;49mrestore(checkpoint)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/tune/trainable/trainable.py:631\u001b[0m, in \u001b[0;36mTrainable.restore\u001b[0;34m(self, checkpoint_path, checkpoint_node_ip)\u001b[0m\n\u001b[1;32m    628\u001b[0m         checkpoint\u001b[39m.\u001b[39mto_directory(checkpoint_path)\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(checkpoint_path):\n\u001b[0;32m--> 631\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    632\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not recover from checkpoint as it does not exist on local \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    633\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdisk and was not available on cloud storage or another Ray node. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    634\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot checkpoint path: \u001b[39m\u001b[39m{\u001b[39;00mcheckpoint_path\u001b[39m}\u001b[39;00m\u001b[39m and IP \u001b[39m\u001b[39m{\u001b[39;00mcheckpoint_node_ip\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    635\u001b[0m     )\n\u001b[1;32m    637\u001b[0m checkpoint_dir \u001b[39m=\u001b[39m TrainableUtil\u001b[39m.\u001b[39mfind_checkpoint_dir(checkpoint_path)\n\u001b[1;32m    638\u001b[0m metadata \u001b[39m=\u001b[39m TrainableUtil\u001b[39m.\u001b[39mload_metadata(checkpoint_dir)\n",
      "\u001b[0;31mValueError\u001b[0m: Could not recover from checkpoint as it does not exist on local disk and was not available on cloud storage or another Ray node. Got checkpoint path: saved_runs/bandits/checkpoint_000097 and IP None"
     ]
    }
   ],
   "source": [
    "# Load the checkpoint from the result folder of your running script\n",
    "# checkpoint = \"saved_runs/bandits/checkpoint_000097\"\n",
    "# bandit_algo.restore(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "observation_features:  [0.88634086 0.18800597 0.9635299  0.06722239 0.8350821  0.07456641\n",
      " 0.8011377  0.05048527 0.9591325  0.00305099 0.9197687  0.12076091\n",
      " 0.82102954 0.07638869 0.8072952  0.17808232 0.9961842  0.0119884\n",
      " 0.9781092  0.1153803 ]\n",
      "bandit's feature value=[0.8350821]; argmax feature=[0.9961842];\n",
      "--------------------------------------------------\n",
      "observation_features:  [0.9484959  0.1260368  0.9163684  0.00408783 0.8420053  0.10893697\n",
      " 0.95382303 0.05013905 0.85717916 0.17047901 0.9950013  0.17697066\n",
      " 0.8719016  0.11977179 0.8709591  0.06803805 0.8356162  0.04753884\n",
      " 0.8089725  0.10108629]\n",
      "bandit's feature value=[0.1260368]; argmax feature=[0.9950013];\n",
      "--------------------------------------------------\n",
      "observation_features:  [0.8752505  0.11856108 0.9259884  0.02852006 0.98676825 0.18927598\n",
      " 0.92045933 0.07755326 0.8726376  0.04086906 0.855353   0.04930717\n",
      " 0.8347216  0.19332194 0.9914025  0.11959474 0.94626015 0.06807704\n",
      " 0.8184111  0.0926996 ]\n",
      "bandit's feature value=[0.18927598]; argmax feature=[0.9914025];\n",
      "--------------------------------------------------\n",
      "observation_features:  [0.9017398  0.01769204 0.90560704 0.19843161 0.87900716 0.06711929\n",
      " 0.9610901  0.1508698  0.86261326 0.12680733 0.90808094 0.05935875\n",
      " 0.82215756 0.06252806 0.8913958  0.13178802 0.8508515  0.12822025\n",
      " 0.8400247  0.13152497]\n",
      "bandit's feature value=[0.8913958]; argmax feature=[0.9610901];\n",
      "--------------------------------------------------\n",
      "observation_features:  [0.95565784 0.15591969 0.9220656  0.06180007 0.939547   0.17192365\n",
      " 0.92506474 0.19648157 0.99530005 0.03333883 0.80463564 0.03214891\n",
      " 0.98469937 0.19070996 0.8421957  0.07210505 0.90987504 0.05436617\n",
      " 0.8921203  0.13923231]\n",
      "bandit's feature value=[0.92506474]; argmax feature=[0.99530005];\n",
      "--------------------------------------------------\n",
      "observation_features:  [9.0007120e-01 1.4321420e-01 9.0519118e-01 2.7980463e-04 8.7894005e-01\n",
      " 9.8433390e-02 8.8057607e-01 7.0859663e-02 9.0012288e-01 8.9035325e-02\n",
      " 8.1808656e-01 5.4712582e-02 9.8869544e-01 5.3089284e-03 8.0799973e-01\n",
      " 5.6628071e-02 9.1646886e-01 1.9817856e-01 9.9852842e-01 1.9862348e-01]\n",
      "bandit's feature value=[0.9985284]; argmax feature=[0.9985284];\n",
      "--------------------------------------------------\n",
      "observation_features:  [0.8220097  0.13289629 0.9047974  0.03462998 0.988592   0.04837202\n",
      " 0.99978644 0.11653876 0.8366558  0.07736909 0.83793473 0.08215413\n",
      " 0.918936   0.14331722 0.8973783  0.06191796 0.9154883  0.08834156\n",
      " 0.8719356  0.06426638]\n",
      "bandit's feature value=[0.11653876]; argmax feature=[0.99978644];\n",
      "--------------------------------------------------\n",
      "observation_features:  [0.8416414  0.09025172 0.8983686  0.17981526 0.94587207 0.15401796\n",
      " 0.87508786 0.06874791 0.931007   0.1422076  0.82270753 0.02660574\n",
      " 0.8912078  0.03194725 0.9923284  0.16752315 0.9040321  0.04365445\n",
      " 0.82698375 0.19581407]\n",
      "bandit's feature value=[0.87508786]; argmax feature=[0.9923284];\n",
      "--------------------------------------------------\n",
      "observation_features:  [0.9414087  0.17199512 0.87743455 0.0501668  0.8598876  0.1713791\n",
      " 0.8945968  0.13265541 0.9611457  0.0505961  0.8159147  0.14655212\n",
      " 0.99227947 0.19076094 0.89809984 0.12643841 0.946599   0.1804819\n",
      " 0.8324494  0.08117627]\n",
      "bandit's feature value=[0.99227947]; argmax feature=[0.99227947];\n",
      "--------------------------------------------------\n",
      "observation_features:  [0.88341814 0.13911821 0.8849695  0.17162284 0.9693865  0.01403982\n",
      " 0.8603505  0.19592473 0.8071254  0.09847853 0.99047536 0.16211475\n",
      " 0.8588661  0.11924671 0.8862356  0.1184795  0.9787504  0.11080424\n",
      " 0.8985733  0.06385409]\n",
      "bandit's feature value=[0.16211475]; argmax feature=[0.99047536];\n"
     ]
    }
   ],
   "source": [
    "env = ModifiedLongTermSatisfactionRecSimEnv(env_config)\n",
    "obs = env.reset()\n",
    "\n",
    "# Run a single episode.\n",
    "done = False\n",
    "while not done:\n",
    "    # use `compute_single_action` method of our Trainer.\n",
    "    # This is one way to perform inference on a learned policy.\n",
    "    # TODO: Code here\n",
    "    bandit_action = bandit_algo.compute_single_action(obs)\n",
    "    argmax_action = int(max(obs['doc'], key=lambda x: obs['doc'][x]))\n",
    "\n",
    "    feature_value_of_bandit = obs[\"doc\"][str(bandit_action)]\n",
    "    feature_value_of_greedy = obs[\"doc\"][str(argmax_action)]\n",
    "\n",
    "\n",
    "    # Print out the picked document's feature value and compare that to the highest possible feature value.\n",
    "    print(\"-\"*50)\n",
    "    print(\"observation_features: \", np.concatenate(list(obs[\"doc\"].values())))\n",
    "    print(f\"bandit's feature value={feature_value_of_bandit}; argmax feature={feature_value_of_greedy};\")\n",
    "\n",
    "    # Apply the computed action in the environment and continue.\n",
    "    obs, r, done, _ = env.step(bandit_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dummy Recsim environment, we did not have any user features.  This makes the contextual bandit without any user context, i.e. without any state.  A stateless bandit cannot remember things between timesteps, so it will sort of converge to the most greedy policy that recommends chocolotes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the problem with RL <a class=\"anchor\" id=\"dqn\"></a>\n",
    "\n",
    "So far the bandit solution has just converged to the perforamnce of greedy argmax policy. **How can we improve over the random policy baseline** Now let's run the DQN algorithm with $\\gamma = 0.99$. We run this script for 1M enviroenment timesteps till convergence. It will take ~ 1hour to run this training job.\n",
    "\n",
    "**Exercise (1 min)** How would you modify the previous config object (`bandit_config`) to train an RL agent to optimize long-term engagement (hint: use `.training()` API)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-09-14 14:08:55 (running for 00:00:17.01)<br>Memory usage on this node: 13.3/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/8.32 GiB heap, 0.0/2.0 GiB objects<br>Result logdir: /Users/kourosh/dev/anyscale_academy/ray-rllib/acm_recsys_tutorial_2022/results_notebook/online_rl/dqn/DQN_2022-09-14_14-08-38<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  num_recreated_wor...</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_modified-lts_671b0_00000</td><td>TERMINATED</td><td>127.0.0.1:87634</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.61303</td><td style=\"text-align: right;\">1000</td><td style=\"text-align: right;\"> 99.8093</td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">             142.959</td><td style=\"text-align: right;\">             51.0457</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/util/placement_group.py:78: DeprecationWarning: placement_group parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return bundle_reservation_check.options(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/_private/ray_option_utils.py:266: DeprecationWarning: Setting 'object_store_memory' for actors is deprecated since it doesn't actually reserve the required object store memory. Use object spilling that's enabled by default (https://docs.ray.io/en/releases-2.0.0/ray-core/objects/object-spilling.html) instead to bypass the object store memory size limitation.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/actor.py:637: DeprecationWarning: placement_group parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/actor.py:637: DeprecationWarning: placement_group_bundle_index parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/actor.py:637: DeprecationWarning: placement_group_capture_child_tasks parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   _ATTRVALUE_LISTVALUE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   import imp\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:36: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   'nearest': pil_image.NEAREST,\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:37: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   'bilinear': pil_image.BILINEAR,\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:38: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   'bicubic': pil_image.BICUBIC,\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:39: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   'hamming': pil_image.HAMMING,\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:40: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   'box': pil_image.BOX,\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:41: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   'lanczos': pil_image.LANCZOS,\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow_probability/__init__.py:58: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow_probability/python/mcmc/sample_halton_sequence.py:374: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   sieve = np.ones(n // 3 + (n % 6 == 2), dtype=np.bool)\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/gin/tf/__init__.py:48: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m 2022-09-14 14:08:52,263\tWARNING deprecation.py:47 -- DeprecationWarning: `ray.rllib.algorithms.dqn.dqn.DEFAULT_CONFIG` has been deprecated. Use `ray.rllib.algorithms.dqn.dqn.DQNConfig(...)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m 2022-09-14 14:08:52,263\tWARNING deprecation.py:47 -- DeprecationWarning: `config['multiagent']['replay_mode']` has been deprecated. config['replay_buffer_config']['replay_mode'] This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m 2022-09-14 14:08:52,264\tINFO simple_q.py:293 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m 2022-09-14 14:08:52,267\tINFO algorithm.py:351 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/_private/ray_option_utils.py:266: DeprecationWarning: Setting 'object_store_memory' for actors is deprecated since it doesn't actually reserve the required object store memory. Use object spilling that's enabled by default (https://docs.ray.io/en/releases-2.0.0/ray-core/objects/object-spilling.html) instead to bypass the object store memory size limitation.\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m 2022-09-14 14:08:52,280\tWARNING env.py:142 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m 2022-09-14 14:08:52,321\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m 2022-09-14 14:08:52,350\tWARNING deprecation.py:47 -- DeprecationWarning: `ReplayBuffer.add_batch()` has been deprecated. Use `ReplayBuffer.add()` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m 2022-09-14 14:08:52,359\tWARNING multi_agent_prioritized_replay_buffer.py:220 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_modified-lts_671b0_00000:\n",
      "  agent_timesteps_total: 1000\n",
      "  counters:\n",
      "    last_target_update_ts: 1000\n",
      "    num_agent_steps_sampled: 1000\n",
      "    num_agent_steps_trained: 32\n",
      "    num_env_steps_sampled: 1000\n",
      "    num_env_steps_trained: 32\n",
      "    num_target_updates: 1\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-14_14-08-54\n",
      "  done: true\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 142.95924904647663\n",
      "  episode_reward_mean: 99.80930260753946\n",
      "  episode_reward_min: 51.045706115732166\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: d00664721d804eaf8baf6db631d081e4\n",
      "  hostname: Kouroshs-MacBook-Pro-13\n",
      "  info:\n",
      "    last_target_update_ts: 1000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 40.0\n",
      "          max_q: 0.587704598903656\n",
      "          mean_q: -0.3412080705165863\n",
      "          min_q: -1.316676378250122\n",
      "        mean_td_error: -14.340478897094727\n",
      "        model: {}\n",
      "        num_agent_steps_trained: 32.0\n",
      "        td_error: [-1.6475883722305298, -2.1412103176116943, -3.0756161212921143, -22.532344818115234,\n",
      "          -19.332195281982422, -4.6281609535217285, -17.081340789794922, -10.205001831054688,\n",
      "          -32.18067169189453, -11.900308609008789, -10.277835845947266, -2.2524795532226562,\n",
      "          -3.0889298915863037, -26.728652954101562, -27.32392692565918, -10.521056175231934,\n",
      "          -2.843743085861206, -5.937435150146484, -2.834545612335205, -10.277835845947266,\n",
      "          -36.546661376953125, -2.970632314682007, -21.60882568359375, -38.42585372924805,\n",
      "          -10.522065162658691, -2.3687524795532227, -1.545008897781372, -12.605607986450195,\n",
      "          -32.1558723449707, -1.7617833614349365, -3.741828441619873, -67.83155822753906]\n",
      "    num_agent_steps_sampled: 1000\n",
      "    num_agent_steps_trained: 32\n",
      "    num_env_steps_sampled: 1000\n",
      "    num_env_steps_trained: 32\n",
      "    num_target_updates: 1\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 1000\n",
      "  num_agent_steps_trained: 32\n",
      "  num_env_steps_sampled: 1000\n",
      "  num_env_steps_sampled_this_iter: 1000\n",
      "  num_env_steps_trained: 32\n",
      "  num_env_steps_trained_this_iter: 32\n",
      "  num_faulty_episodes: 0\n",
      "  num_healthy_workers: 0\n",
      "  num_recreated_workers: 0\n",
      "  num_steps_trained_this_iter: 32\n",
      "  perf:\n",
      "    cpu_util_percent: 65.25\n",
      "    ram_util_percent: 83.75\n",
      "  pid: 87634\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039328347433816184\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.26843621656968525\n",
      "    mean_inference_ms: 0.9887947307361832\n",
      "    mean_raw_obs_processing_ms: 1.128431562181715\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 142.95924904647663\n",
      "    episode_reward_mean: 99.80930260753946\n",
      "    episode_reward_min: 51.045706115732166\n",
      "    episodes_this_iter: 100\n",
      "    hist_stats:\n",
      "      episode_lengths: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "      episode_reward: [142.82140520823282, 118.79649889433985, 96.08563575347209, 109.63964221576862,\n",
      "        68.90383257917489, 110.54726871015623, 82.41518761886068, 104.27587448292759,\n",
      "        130.43063797227524, 94.1570927483861, 100.20888907303294, 119.40801129866, 99.63524768613817,\n",
      "        101.05245480511068, 122.7129450401749, 95.87132598584526, 122.73694087293917,\n",
      "        95.22584450426224, 111.92994942620057, 132.04953675450128, 80.0306716646244,\n",
      "        103.72943306371079, 71.97234596005222, 101.01894065685607, 91.96404222410507,\n",
      "        101.6383963245272, 112.2938291818112, 76.55705535718404, 100.3079848333377,\n",
      "        96.81201534087295, 107.37549504413658, 112.43197371121092, 91.04536139795091,\n",
      "        75.08128930831019, 86.07203320614653, 86.11291859502192, 139.50896696466745,\n",
      "        116.22026632242236, 142.95924904647663, 109.20623703530461, 97.83864271118539,\n",
      "        118.11822723199012, 96.5535602557827, 115.92114714344085, 87.39437683902332,\n",
      "        65.80254911682248, 123.84396072100745, 101.79964502112516, 64.51143270185237,\n",
      "        125.36591193471254, 76.19294661275028, 122.28110444265961, 84.80734936026016,\n",
      "        94.15720756107478, 64.99112026997325, 100.70676776242466, 68.68432086725835,\n",
      "        106.18993606953018, 109.81122396035914, 88.17957458628072, 105.96931824564163,\n",
      "        106.3384265103192, 51.045706115732166, 124.1795604537601, 95.9752515854708,\n",
      "        92.544641326244, 73.64767486457478, 124.94483101545441, 117.8221969856634, 86.24175414602897,\n",
      "        64.4633709070464, 84.80538050129208, 138.14993341029046, 110.02295947129863,\n",
      "        75.64960618215925, 138.63700920643322, 86.04021687775534, 95.7190905280978,\n",
      "        116.37095445992816, 104.55429582822316, 130.10584704533832, 103.70335531751269,\n",
      "        80.20212849512968, 62.89079636018156, 105.94297989144106, 122.5016266525284,\n",
      "        75.47346858186171, 77.4130901327444, 75.89722589648497, 74.04548810207478, 98.31717244645365,\n",
      "        83.18459674717748, 97.51290624941042, 120.72971782053874, 76.27962666534499,\n",
      "        80.5957007158652, 110.28984568352499, 118.20599686621051, 119.10315215691523,\n",
      "        101.01962826709232]\n",
      "    num_faulty_episodes: 0\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.039328347433816184\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.26843621656968525\n",
      "      mean_inference_ms: 0.9887947307361832\n",
      "      mean_raw_obs_processing_ms: 1.128431562181715\n",
      "  time_since_restore: 2.6130282878875732\n",
      "  time_this_iter_s: 2.6130282878875732\n",
      "  time_total_s: 2.6130282878875732\n",
      "  timers:\n",
      "    learn_throughput: 2427.171\n",
      "    learn_time_ms: 13.184\n",
      "    load_throughput: 38468.824\n",
      "    load_time_ms: 0.832\n",
      "    synch_weights_time_ms: 0.019\n",
      "    training_iteration_time_ms: 17.54\n",
      "  timestamp: 1663189734\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1000\n",
      "  training_iteration: 1\n",
      "  trial_id: 671b0_00000\n",
      "  warmup_time: 0.07596802711486816\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m 2022-09-14 14:08:54,917\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n",
      "2022-09-14 14:08:56,000\tINFO tune.py:758 -- Total run time: 17.60 seconds (16.99 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "# TODO: Code here\n",
    "dqn_config = bandit_config.training(gamma=0.99)\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    DQN,\n",
    "    param_space=dqn_config.to_dict(),\n",
    "    run_config=air.RunConfig(\n",
    "        local_dir='./results_notebook/online_rl/dqn',\n",
    "        stop={\"training_iteration\": 1},  # this is enough for it to converge\n",
    "    )\n",
    ")\n",
    "dqn_results = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the same script as before, with `gamma=0.99` passed in as a parameter. We should also run the script longer (1M steps) as it will take longer for DQN to converge. \n",
    "```bash\n",
    "python tutorial_scripts/run_online_rl.py --seed 0 --gamma 0.99 --exp_name dqn --timesteps 1_000_000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Take a look at the results and compare them to bandits via tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the results\n",
    "bandit_df = pd.read_csv(\"saved_runs/bandits/progress.csv\")\n",
    "dqn_df = pd.read_csv(\"saved_runs/dqn/progress.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'RL vs. Bandits training performance')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results and compare to baselines\n",
    "sns.lineplot(data=bandit_df, x=\"training_iteration\", y=\"episode_reward_mean\", label=\"Bandits\")\n",
    "sns.lineplot(data=dqn_df, x=\"training_iteration\", y=\"episode_reward_mean\", label=\"DQN\")\n",
    "plt.axhline(random_baseline, color=\"red\", linestyle='--', label=\"random baseline\")\n",
    "plt.axhline(sweetest_baseline, color=\"blue\", linestyle='--', label=\"sweetest baseline\")\n",
    "plt.legend()\n",
    "plt.title('RL vs. Bandits training performance')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Sweetest** straight line, is the mean reward achieved by the greedy policy, selecting always the item with most immediate reward value.\n",
    "- **Bandit** short term reward hovers around the \"sweetest baseline\".\n",
    "- **Random** straight line, items are randomly chosen to be recommended at each timestep. Since this baseline mixes the sweetest and kaliest options the engagement is kept higher than either of the greedy methods, obtaining larger rewards.\n",
    "- **DQN (RL)**, such as DQN that optimize for long-term engagement significantly improves upon random baselines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions and Break (5 min) <a class=\"anchor\" id=\"break\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline RL with RecSys <a class=\"anchor\" id=\"offline-rl\"></a>\n",
    "\n",
    "<img src=\"images/offline_rl.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### If we don't have a live environment, how do we know, how well our trained policy will perform?\n",
    "\n",
    "One of the challenges in offline RL is the evaluation of the trained policy. In online RL (when a simulator\n",
    "is available), one can either use the data collected for training to compute episode total rewards. Remember\n",
    "that observations, actions, rewards, and done flags are all part of this training data. Alternatively,\n",
    "one could run a separate worker (with the same trained policy) and run it on a fresh evaluation-only environment.\n",
    "In this latter case, we would also have the chance to switch off any exploratory behavior (e.g. stochasticity used\n",
    "for better action entropy).\n",
    "\n",
    "In offline RL, no such data from a live environment is available to us. There are two common ways of addressing this dilemma:\n",
    "\n",
    "1) We deploy the learned policies into production, or maybe just a portion of our production system (similar to A/B testing), and see what happens.\n",
    "\n",
    "2) We use a method called \"off policy evaluation\" (OPE) to compute an estimate on how the new policy would perform if we were to deploy it into a real environment. There are different OPE methods available in RLlib off-the-shelf.\n",
    "\n",
    "3) The third option - which we will use here - is kind of cheating and only possible if you actually do have a simulator available (but you only want to use it for evaluation, not for training, because you want to see how cool offline RL is :) )\n",
    "\n",
    "In this tutorial, we will use the third option to show the effectiveness of offline RL in improving over existing policies running in production. We will also see how much benefit we can get by improving our dataset quality, starting from a totally random policy all the way to 20% expert demonstrations adn 80% random. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the currently running policies in production to collect some \"historical data\" that we can use to train RL agents with. Offline RL can be used to improve upon the existing policies deployed in production. We have prepared some datasets in advance for the purpose of this tutorial. They were all generated using `<path to the script>`. In this script we can mix the percentage of the \"expert\" data vs. random data to investigate the effect of dataset quality on the final performance of our models.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an exemplar dataset we have prepared before:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 14:09:02,640\tWARNING read_api.py:291 --   The number of blocks in this dataset (1) limits its parallelism to 1 concurrent tasks. This is much less than the number of available CPU slots in the cluster. Use `.repartition(n)` to increase the number of dataset blocks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colimns:  Index(['type', 'obs', 'new_obs', 'actions', 'rewards', 'dones', 'eps_id', 't',\n",
      "       'action_prob'],\n",
      "      dtype='object')\n",
      "Number of rows:  100\n",
      "Value of the first row\n",
      "--------------------\n",
      "type                                                 SampleBatch\n",
      "obs            BCJNGGhAMAQAAAAAAACKIgIAAGGABZUlBAABAPEcjBVudW...\n",
      "new_obs        BCJNGGhALQQAAAAAAABmHgIAAGGABZUiBAABAPEcjBVudW...\n",
      "actions                                                      [0]\n",
      "rewards                                      [22.45008736559994]\n",
      "dones                                                    [False]\n",
      "eps_id                                                       [0]\n",
      "t                                                            [0]\n",
      "action_prob                                               [0.05]\n",
      "Name: 0, dtype: object\n",
      "Value of the second row:\n",
      "--------------------\n",
      "type                                                 SampleBatch\n",
      "obs            BCJNGGhALQQAAAAAAABmHgIAAGGABZUiBAABAPEcjBVudW...\n",
      "new_obs        BCJNGGhALQQAAAAAAABmHAIAAGGABZUiBAABAPEcjBVudW...\n",
      "actions                                                      [7]\n",
      "rewards                                     [1.4457165728302563]\n",
      "dones                                                    [False]\n",
      "eps_id                                                       [0]\n",
      "t                                                            [1]\n",
      "action_prob                                               [0.05]\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "prefix = \"s3://air-example-data/rllib/acm_recsys22_tutorial_data/\"\n",
    "train_data_path = prefix + \"sampled_data_train_random_transitions_small\"\n",
    "\n",
    "dset = data.read_json(train_data_path)\n",
    "df = dset.to_pandas()\n",
    "print('Colimns: ', df.columns)\n",
    "print('Number of rows: ', len(df))\n",
    "print('Value of the first row')\n",
    "print('-'*20)\n",
    "print(df.iloc[0])\n",
    "print('Value of the second row:')\n",
    "print('-'*20)\n",
    "print(df.iloc[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dataset schema, we can see that RLlib always expects a `type` column that is `SampleBatch`. It will have the normal transition entities per each row (i.e. observation, next_observation, action, reward, done values). It will also contain an episode_id, a timestep indicator, and an action_prob that show the probablity of the action that we chosen at the time of data collection. For random policy the action prob will always be 1/20 (0.05). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an understaning of the dataset example format, we can use RLlib to train an offline RL algorithm. RLlib provides several out of the box offline RL algorithms that you can use. Beside those offline-RL-specific algorithms, we can also use any off-policy algorithm (e.g. DQN) to do offline-RL. The only difference between online and offline version is that instead of using an enviornement sampler, we use a dataset sampler to get the data from. In the next section, we will use DQN, with the difference that we pass a dataset path to the input config."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the summary of the differences:\n",
    "\n",
    "- Change the input config from a sample to offline dataset is configured by `.offline_data()` API:\n",
    "\n",
    "```python\n",
    "    .offline_data(\n",
    "        input_='dataset',\n",
    "        input_config={\n",
    "            'format': 'json',\n",
    "            'paths': train_data_path\n",
    "        }\n",
    "    )\n",
    "```\n",
    "\n",
    "- The environement is not passed to the enviornement anymore. Instead we need to pass in the expected action and observation space to construct the policies. We can create them manually based on our knowledge of our system. In this case we actually cheat and use the environement attributes to get the correct action and observatin spaces.\n",
    "\n",
    "```python \n",
    "    .environment(\n",
    "        action_space=action_space,\n",
    "        observation_space=observation_space,\n",
    "    )\n",
    "```\n",
    "\n",
    "- evaluation config: Since during the evaluation we still need to use the enviroenement simulations, we need to specify it explicitly here. RLlib by default will use the training settings during evaluation and to avoid that default behavior we need to explicitly specify the simulation environement configs. \n",
    "\n",
    "```python\n",
    "    .evaluation(\n",
    "        evaluation_config={\n",
    "            \"input\": \"sampler\",\n",
    "            \"explore\": False,\n",
    "            \"env\": \"modified-lts\",\n",
    "            \"env_config\": env_config,\n",
    "        },\n",
    "    )\n",
    "```\n",
    "\n",
    "- (Advanced) configuring the replay buffer to become a dummy buffer. By default RLlib uses a large replay buffer that is useful in online RL but doesn't add much value in the offline case. It is recommended to by-pass this behavior by configuring the replay buffer size to be the same as the dataset sampling size, so that the sampling flow does not get dirupted by the replay buffer behavior.\n",
    "\n",
    "```python\n",
    "    .training(\n",
    "        replay_buffer_config={\n",
    "            \"capacity\": 512,\n",
    "            \"learning_starts\": 0\n",
    "        }\n",
    "    )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the script below takes about 1 hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ModifiedLongTermSatisfactionRecSimEnv(env_config)\n",
    "action_space = env.action_space\n",
    "observation_space = env.observation_space\n",
    "\n",
    "dqn_config_offline = (\n",
    "    dqn_config\n",
    "    .offline_data(\n",
    "        input_='dataset',\n",
    "        input_config={\n",
    "            'format': 'json',\n",
    "            'paths': train_data_path,\n",
    "        }\n",
    "    )\n",
    "    .environment(\n",
    "        action_space=action_space,\n",
    "        observation_space=observation_space,\n",
    "    )\n",
    "    .evaluation(\n",
    "        evaluation_interval=10, \n",
    "        evaluation_duration=10, \n",
    "        evaluation_duration_unit=\"episodes\",\n",
    "        evaluation_parallel_to_training=True,\n",
    "        evaluation_config={\n",
    "            \"input\": \"sampler\",\n",
    "            \"explore\": False,\n",
    "            \"env\": \"modified-lts\",\n",
    "            \"env_config\": env_config,\n",
    "        },\n",
    "    )\n",
    "    .debugging(seed=seed, log_level=\"ERROR\")\n",
    "    .training(\n",
    "        gamma=1.0,\n",
    "        num_atoms=1,\n",
    "        double_q=True,\n",
    "        dueling=False,\n",
    "        model=dict(\n",
    "            fcnet_hiddens=[1024, 1024, 1024],\n",
    "            fcnet_activation='relu', \n",
    "        ),\n",
    "        train_batch_size=512,\n",
    "        lr=3e-4,\n",
    "        target_network_update_freq=512,\n",
    "        replay_buffer_config={\n",
    "            \"capacity\": 512,\n",
    "            \"learning_starts\": 0\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the long-running learning script run:\n",
    "\n",
    "```bash\n",
    "python tutorial_scripts/run_offline_rl.py --dataset_suffix sampled_data_train_random_transitions\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-09-14 14:09:27 (running for 00:00:23.77)<br>Memory usage on this node: 13.4/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/8.32 GiB heap, 0.0/2.0 GiB objects<br>Result logdir: /Users/kourosh/dev/anyscale_academy/ray-rllib/acm_recsys_tutorial_2022/results_notebook/offline_rl/DQN_2022-09-14_14-09-03<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  num_recreated_wor...</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_modified-lts_75ee4_00000</td><td>TERMINATED</td><td>127.0.0.1:87694</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.42812</td><td style=\"text-align: right;\">1024</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">                 nan</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/util/placement_group.py:78: DeprecationWarning: placement_group parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return bundle_reservation_check.options(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/_private/ray_option_utils.py:266: DeprecationWarning: Setting 'object_store_memory' for actors is deprecated since it doesn't actually reserve the required object store memory. Use object spilling that's enabled by default (https://docs.ray.io/en/releases-2.0.0/ray-core/objects/object-spilling.html) instead to bypass the object store memory size limitation.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/actor.py:637: DeprecationWarning: placement_group parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/actor.py:637: DeprecationWarning: placement_group_bundle_index parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/actor.py:637: DeprecationWarning: placement_group_capture_child_tasks parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   _ATTRVALUE_LISTVALUE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   import imp\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:36: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   'nearest': pil_image.NEAREST,\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:37: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   'bilinear': pil_image.BILINEAR,\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:38: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   'bicubic': pil_image.BICUBIC,\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:39: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   'hamming': pil_image.HAMMING,\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:40: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   'box': pil_image.BOX,\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:41: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   'lanczos': pil_image.LANCZOS,\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow_probability/__init__.py:58: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow_probability/python/mcmc/sample_halton_sequence.py:374: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   sieve = np.ones(n // 3 + (n % 6 == 2), dtype=np.bool)\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/gin/tf/__init__.py:48: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m 2022-09-14 14:09:12,674\tWARNING deprecation.py:47 -- DeprecationWarning: `ray.rllib.algorithms.dqn.dqn.DEFAULT_CONFIG` has been deprecated. Use `ray.rllib.algorithms.dqn.dqn.DQNConfig(...)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/rllib/utils/debug/deterministic.py:42: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m   if LooseVersion(torch.__version__) >= LooseVersion(\"1.8.0\"):\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m 2022-09-14 14:09:12,675\tWARNING algorithm.py:2114 -- `evaluation_parallel_to_training` can only be done if `evaluation_num_workers` > 0! Setting `evaluation_parallel_to_training` to False.\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m 2022-09-14 14:09:12,676\tWARNING deprecation.py:47 -- DeprecationWarning: `config['multiagent']['replay_mode']` has been deprecated. config['replay_buffer_config']['replay_mode'] This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m 2022-09-14 14:09:12,676\tINFO simple_q.py:293 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m 2022-09-14 14:09:12,678\tINFO algorithm.py:351 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/_private/ray_option_utils.py:266: DeprecationWarning: Setting 'object_store_memory' for actors is deprecated since it doesn't actually reserve the required object store memory. Use object spilling that's enabled by default (https://docs.ray.io/en/releases-2.0.0/ray-core/objects/object-spilling.html) instead to bypass the object store memory size limitation.\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m DatasetReader 0 has 100, samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m 2022-09-14 14:09:17,271\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_modified-lts_75ee4_00000:\n",
      "  agent_timesteps_total: 1024\n",
      "  counters:\n",
      "    last_target_update_ts: 1024\n",
      "    num_agent_steps_sampled: 1024\n",
      "    num_agent_steps_trained: 1024\n",
      "    num_env_steps_sampled: 1024\n",
      "    num_env_steps_trained: 1024\n",
      "    num_target_updates: 2\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-14_14-09-26\n",
      "  done: true\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: f7393cf8e4374f09897d4d26f4bac9bf\n",
      "  hostname: Kouroshs-MacBook-Pro-13\n",
      "  info:\n",
      "    last_target_update_ts: 1024\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0003\n",
      "          grad_gnorm: 40.0\n",
      "          max_q: 17.398069381713867\n",
      "          mean_q: 0.5301390886306763\n",
      "          min_q: -3.08048152923584\n",
      "        mean_td_error: -13.04154109954834\n",
      "        model: {}\n",
      "        num_agent_steps_trained: 512.0\n",
      "        td_error: [-2.5246975421905518, -15.832113265991211, -2.9286468029022217, -1.7219157218933105,\n",
      "          -4.7678351402282715, -2.867734432220459, -3.785020589828491, -2.311821222305298,\n",
      "          -2.578303813934326, -0.10062360763549805, -1.5532351732254028, -2.895843029022217,\n",
      "          -1.9734052419662476, -2.389592409133911, -2.867734432220459, -2.4410769939422607,\n",
      "          -4.14689826965332, -0.6847338676452637, -3.685330390930176, -34.133575439453125,\n",
      "          -27.677404403686523, -0.6847338676452637, -2.300475835800171, -36.87446975708008,\n",
      "          -80.83019256591797, -1.135479211807251, -34.133575439453125, -9.623801231384277,\n",
      "          -80.83019256591797, -3.1824049949645996, -10.576726913452148, -3.1533682346343994,\n",
      "          -49.37401580810547, -23.009357452392578, -49.37401580810547, -5.817642688751221,\n",
      "          -15.491028785705566, -3.567211151123047, -10.576726913452148, -55.56748580932617,\n",
      "          -53.11589050292969, -1.7219157218933105, -2.895843029022217, -51.195518493652344,\n",
      "          -10.576726913452148, -22.60820770263672, -53.11589050292969, -27.677404403686523,\n",
      "          -3.5373010635375977, -2.312549352645874, -53.11589050292969, -3.169973373413086,\n",
      "          -61.502071380615234, -2.4410910606384277, -2.5911331176757812, -28.612890243530273,\n",
      "          -2.300475835800171, -3.3312034606933594, -22.60820770263672, -1.927714228630066,\n",
      "          -32.955265045166016, -3.1824049949645996, -42.27695083618164, -1.276259422302246,\n",
      "          -9.16895580291748, -2.343522548675537, -2.4410769939422607, -1.135479211807251,\n",
      "          -3.567211151123047, -1.3226743936538696, 1.77516508102417, -2.300475835800171,\n",
      "          -73.47428131103516, -2.578303813934326, -13.988373756408691, -9.16895580291748,\n",
      "          -80.83019256591797, -1.276259422302246, -3.503541946411133, -3.1824049949645996,\n",
      "          -2.300475835800171, -49.37401580810547, -4.214771270751953, -1.311438798904419,\n",
      "          -2.312549352645874, -50.07960891723633, -2.329728364944458, -42.27695083618164,\n",
      "          -15.234942436218262, -2.3673818111419678, -38.11575698852539, -73.47428131103516,\n",
      "          -2.578303813934326, -2.605522394180298, -3.144289970397949, -2.343522548675537,\n",
      "          -2.312549352645874, -2.867734432220459, -3.685330390930176, -24.746192932128906,\n",
      "          -61.502071380615234, -80.83019256591797, -15.491028785705566, -2.5246975421905518,\n",
      "          -9.4075927734375, -3.144289970397949, -2.5911331176757812, -1.9351129531860352,\n",
      "          -0.10062360763549805, -1.977062702178955, -1.9769949913024902, -1.9351129531860352,\n",
      "          -3.3312034606933594, -9.4075927734375, -1.5532351732254028, -0.6847338676452637,\n",
      "          -3.75954532623291, -1.192234992980957, -1.927714228630066, -1.8868589401245117,\n",
      "          -2.605522394180298, -24.46055030822754, -34.133575439453125, -23.009357452392578,\n",
      "          -1.7219157218933105, -2.1288492679595947, -1.8868589401245117, -4.14689826965332,\n",
      "          -2.329728364944458, -1.9351129531860352, -3.169973373413086, -15.491028785705566,\n",
      "          -42.27695083618164, -13.988373756408691, -2.867734432220459, -42.27695083618164,\n",
      "          -36.87446975708008, -0.10062360763549805, -23.009357452392578, -2.895843029022217,\n",
      "          -2.5911331176757812, -10.576726913452148, -1.192234992980957, -26.344017028808594,\n",
      "          -1.9351129531860352, -2.596219301223755, -4.214771270751953, -2.895843029022217,\n",
      "          -1.135479211807251, -26.344017028808594, -2.329728364944458, -5.817642688751221,\n",
      "          -2.272246837615967, -2.597764015197754, -0.14541101455688477, -11.272283554077148,\n",
      "          -30.51406478881836, -2.329728364944458, -1.927714228630066, -24.746192932128906,\n",
      "          -2.343522548675537, -2.4410769939422607, -1.9734052419662476, -1.927714228630066,\n",
      "          -42.27695083618164, -26.344017028808594, -1.276259422302246, -2.343522548675537,\n",
      "          -3.685330390930176, -24.46055030822754, -11.272283554077148, -2.597764015197754,\n",
      "          -2.578303813934326, -2.946082353591919, -1.977062702178955, -3.5373010635375977,\n",
      "          -2.389592409133911, -2.832310199737549, -2.9286468029022217, -1.276259422302246,\n",
      "          -1.135479211807251, -2.311821222305298, -3.144289970397949, -2.300475835800171,\n",
      "          -2.832310199737549, -2.596219301223755, -2.311821222305298, -40.6142463684082,\n",
      "          -8.945487976074219, -2.57388973236084, -34.133575439453125, -2.300475835800171,\n",
      "          -2.81644344329834, -36.87446975708008, -10.576726913452148, -30.51406478881836,\n",
      "          -2.389592409133911, -0.6847338676452637, -2.81644344329834, -2.57388973236084,\n",
      "          1.77516508102417, -1.9769949913024902, -2.4410910606384277, -2.1288492679595947,\n",
      "          -36.87446975708008, -26.344017028808594, -51.195518493652344, -11.272283554077148,\n",
      "          -0.14541101455688477, -8.945487976074219, -13.988373756408691, -38.11575698852539,\n",
      "          -13.988373756408691, -2.343522548675537, -3.75954532623291, -4.7678351402282715,\n",
      "          -2.81644344329834, -40.6142463684082, -5.817642688751221, -9.623801231384277,\n",
      "          -2.5246975421905518, -38.11575698852539, -2.3673818111419678, -2.946082353591919,\n",
      "          1.77516508102417, -12.777097702026367, -26.344017028808594, -2.329728364944458,\n",
      "          -2.272246837615967, -15.234942436218262, -1.986715316772461, -12.777097702026367,\n",
      "          -1.691193699836731, -4.214771270751953, -2.1288492679595947, -2.895843029022217,\n",
      "          -11.272283554077148, -1.9351129531860352, -3.3312034606933594, -11.272283554077148,\n",
      "          -3.785020589828491, -2.1288492679595947, -2.320448160171509, -3.1533682346343994,\n",
      "          -3.1824049949645996, -0.10062360763549805, -2.312549352645874, -2.3673818111419678,\n",
      "          -27.677404403686523, -2.678253650665283, -4.14689826965332, -3.1533682346343994,\n",
      "          -2.312549352645874, -28.612890243530273, -1.135479211807251, -9.623801231384277,\n",
      "          -5.817642688751221, -23.009357452392578, -1.927714228630066, -2.300475835800171,\n",
      "          -2.4410910606384277, -32.955265045166016, -1.927714228630066, -1.135479211807251,\n",
      "          -2.605522394180298, -2.946082353591919, -42.27695083618164, -53.11589050292969,\n",
      "          -2.343522548675537, -42.27695083618164, -15.832113265991211, -2.57388973236084,\n",
      "          -3.1533682346343994, -9.4075927734375, -1.7219157218933105, -2.895843029022217,\n",
      "          -3.75954532623291, -9.16895580291748, -2.895843029022217, -9.4075927734375,\n",
      "          -3.75954532623291, -9.623801231384277, -28.612890243530273, -2.81644344329834,\n",
      "          -2.9286468029022217, -1.311438798904419, -1.7316410541534424, -49.37401580810547,\n",
      "          -2.343522548675537, -2.312549352645874, -4.14689826965332, -3.3312034606933594,\n",
      "          -12.777097702026367, -5.817642688751221, -9.4075927734375, -1.135479211807251,\n",
      "          -2.946082353591919, -2.4410910606384277, -3.144289970397949, -2.272246837615967,\n",
      "          -58.38572692871094, -27.677404403686523, -58.38572692871094, -2.946082353591919,\n",
      "          -1.9734052419662476, -2.605522394180298, -12.777097702026367, -2.3673818111419678,\n",
      "          -1.5532351732254028, -2.311821222305298, -15.491028785705566, -1.9769949913024902,\n",
      "          -2.5911331176757812, -2.946082353591919, -51.195518493652344, -2.4410910606384277,\n",
      "          -1.276259422302246, -32.955265045166016, -2.5246975421905518, -4.14689826965332,\n",
      "          -2.678253650665283, -32.955265045166016, -2.272246837615967, -49.77021026611328,\n",
      "          -3.785020589828491, -1.7219157218933105, -23.009357452392578, -1.927714228630066,\n",
      "          -80.83019256591797, -3.6408185958862305, -32.955265045166016, -40.6142463684082,\n",
      "          -11.272283554077148, -2.946082353591919, -73.47428131103516, -15.234942436218262,\n",
      "          -3.75954532623291, -15.234942436218262, -1.8868589401245117, -2.343522548675537,\n",
      "          -0.45891237258911133, -1.135479211807251, -34.133575439453125, -2.389592409133911,\n",
      "          -3.75954532623291, -1.691193699836731, -55.56748580932617, -2.578303813934326,\n",
      "          -2.867734432220459, -2.9286468029022217, -3.785020589828491, -32.955265045166016,\n",
      "          -73.47428131103516, -2.5911331176757812, -36.87446975708008, -1.311438798904419,\n",
      "          -2.5246975421905518, -58.38572692871094, -61.502071380615234, -50.07960891723633,\n",
      "          -2.597764015197754, -3.685330390930176, -1.5532351732254028, -61.502071380615234,\n",
      "          -11.272283554077148, -9.16895580291748, -1.8868589401245117, -9.623801231384277,\n",
      "          -3.169973373413086, -2.4410910606384277, -4.7678351402282715, -34.133575439453125,\n",
      "          -1.986715316772461, -1.927714228630066, -36.87446975708008, -24.46055030822754,\n",
      "          -35.1298713684082, -9.16895580291748, -10.576726913452148, -1.7219157218933105,\n",
      "          -2.343522548675537, 1.77516508102417, -0.6847338676452637, -8.945487976074219,\n",
      "          -2.272246837615967, -38.11575698852539, -1.9734052419662476, -3.685330390930176,\n",
      "          -2.320448160171509, -1.9769949913024902, -1.7219157218933105, -1.3226743936538696,\n",
      "          -36.87446975708008, -4.14689826965332, -30.51406478881836, -2.9286468029022217,\n",
      "          -1.311438798904419, -13.988373756408691, -8.945487976074219, -24.746192932128906,\n",
      "          -53.11589050292969, -24.746192932128906, -11.272283554077148, -1.9351129531860352,\n",
      "          -2.5246975421905518, -22.60820770263672, -4.14689826965332, -1.691193699836731,\n",
      "          -38.11575698852539, -12.777097702026367, -2.81644344329834, 1.77516508102417,\n",
      "          -2.946082353591919, -3.6408185958862305, -32.955265045166016, -22.60820770263672,\n",
      "          -3.75954532623291, -1.9734052419662476, -3.785020589828491, -1.8868589401245117,\n",
      "          -2.320448160171509, -3.503541946411133, -3.75954532623291, -1.7219157218933105,\n",
      "          -2.867734432220459, -1.9769949913024902, -2.3673818111419678, -2.389592409133911,\n",
      "          -49.77021026611328, -2.605522394180298, -53.11589050292969, -2.4410769939422607,\n",
      "          -23.009357452392578, -2.596219301223755, -27.677404403686523, -10.576726913452148,\n",
      "          -2.895843029022217, -27.677404403686523, -2.946082353591919, -1.276259422302246,\n",
      "          -40.6142463684082, -55.56748580932617, -4.214771270751953, -1.8868589401245117,\n",
      "          -3.0267162322998047, -11.272283554077148, -26.344017028808594, -4.214771270751953,\n",
      "          -3.3312034606933594, 1.77516508102417, -3.6408185958862305, -3.144289970397949,\n",
      "          -2.4410769939422607, -2.9286468029022217, -3.3312034606933594, -2.832310199737549,\n",
      "          -4.14689826965332, -9.623801231384277, -80.83019256591797, -38.11575698852539,\n",
      "          -2.3673818111419678, -1.8868589401245117, -3.685330390930176, -5.817642688751221,\n",
      "          -15.234942436218262, -58.38572692871094, -8.945487976074219, -32.955265045166016,\n",
      "          -2.57388973236084, -1.8868589401245117, -10.576726913452148, -53.11589050292969,\n",
      "          -2.272246837615967, -73.47428131103516, -2.329728364944458, -2.678253650665283,\n",
      "          -1.691193699836731, -49.37401580810547, -2.312549352645874, -58.38572692871094,\n",
      "          -11.272283554077148, -2.57388973236084, -2.4410910606384277, -2.343522548675537,\n",
      "          -2.596219301223755, -22.60820770263672, -11.272283554077148, -55.56748580932617,\n",
      "          -2.81644344329834, -50.07960891723633, -1.5532351732254028, 1.77516508102417,\n",
      "          -2.832310199737549, -2.1288492679595947, -11.272283554077148, -11.272283554077148,\n",
      "          -2.4410910606384277, -2.678253650665283, -4.14689826965332, -3.0267162322998047,\n",
      "          -2.3673818111419678, -3.169973373413086, -2.3673818111419678, -32.955265045166016,\n",
      "          -2.343522548675537, -26.344017028808594, -2.678253650665283, -1.8868589401245117,\n",
      "          -1.9769949913024902, -3.0267162322998047, -73.47428131103516, -3.144289970397949]\n",
      "    num_agent_steps_sampled: 1024\n",
      "    num_agent_steps_trained: 1024\n",
      "    num_env_steps_sampled: 1024\n",
      "    num_env_steps_trained: 1024\n",
      "    num_target_updates: 2\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 1024\n",
      "  num_agent_steps_trained: 1024\n",
      "  num_env_steps_sampled: 1024\n",
      "  num_env_steps_sampled_this_iter: 1024\n",
      "  num_env_steps_trained: 1024\n",
      "  num_env_steps_trained_this_iter: 1024\n",
      "  num_faulty_episodes: 0\n",
      "  num_healthy_workers: 0\n",
      "  num_recreated_workers: 0\n",
      "  num_steps_trained_this_iter: 1024\n",
      "  perf:\n",
      "    cpu_util_percent: 38.12857142857143\n",
      "    ram_util_percent: 83.80714285714286\n",
      "  pid: 87694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: .nan\n",
      "    episode_media: {}\n",
      "    episode_reward_max: .nan\n",
      "    episode_reward_mean: .nan\n",
      "    episode_reward_min: .nan\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths: []\n",
      "      episode_reward: []\n",
      "    num_faulty_episodes: 0\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf: {}\n",
      "  time_since_restore: 9.428117990493774\n",
      "  time_this_iter_s: 9.428117990493774\n",
      "  time_total_s: 9.428117990493774\n",
      "  timers:\n",
      "    learn_throughput: 7257.673\n",
      "    learn_time_ms: 70.546\n",
      "    load_throughput: 2072860.664\n",
      "    load_time_ms: 0.247\n",
      "    synch_weights_time_ms: 0.022\n",
      "    training_iteration_time_ms: 4711.518\n",
      "  timestamp: 1663189766\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1024\n",
      "  training_iteration: 1\n",
      "  trial_id: 75ee4_00000\n",
      "  warmup_time: 4.627590179443359\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 14:09:27,236\tWARNING worker.py:1829 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 88f3073d3997f9161bc41c389f2f55e8b52fe10a01000000 Worker ID: 134c0cdb96857a86ccc0ad04f2d9638b4aba55845206cec4e38e3de1 Node ID: 4c51b4fd99d01a8f82171f0de6a2fc03c95f7ab3d52fa98843c58b29 Worker IP address: 127.0.0.1 Worker port: 65415 Worker PID: 87710 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n",
      "2022-09-14 14:09:27,239\tINFO tune.py:758 -- Total run time: 23.96 seconds (23.69 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "tuner = tune.Tuner(\n",
    "    DQN,\n",
    "    param_space=dqn_config_offline.to_dict(),\n",
    "    run_config=air.RunConfig(\n",
    "        local_dir=\"./results_notebook/offline_rl/\",\n",
    "        stop={\"training_iteration\": 1},\n",
    "    )\n",
    ")\n",
    "dqn_offline_results = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the offline training results. From the plot below we can see that by running offline RL on randomly collected transitions we can improve over the random policy. This is extremely useful in practical scenarios where our goal is to improve over existing production policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_offline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_offline_results[0].metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results and compare to baselines\n",
    "fname = \"saved_runs/dqn_offline/random_data/progress.csv\"\n",
    "offline_dqn_df = pd.read_csv(fname)\n",
    "print(offline_dqn_df.columns)\n",
    "offline_dqn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.lineplot(data=offline_dqn_df, x=\"training_iteration\", y=\"evaluation/episode_reward_mean\", label=\"Offline_DQN\")\n",
    "plt.axhline(random_baseline, color=\"red\", linestyle='--', label=\"random baseline\")\n",
    "plt.legend()\n",
    "plt.title('Offline RL vs. Baselines training performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=offline_dqn_df, x=\"training_iteration\", y=\"info/learner/default_policy/learner_stats/mean_q\", label=\"q_value\")\n",
    "plt.legend()\n",
    "plt.title('Average Q value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- Bandits converges to a short-sighted solution\n",
    "    -  Optimizes imediate reward. \n",
    "- DQN takes long-term reward into account\n",
    "    -  Achieves a policy better than random.\n",
    "    -  Can become even better than our heuristic based baseline (even_argmax).\n",
    "- Offline RL is a viable option that works when we don't have simulators for training\n",
    "    -  Since it doesn't explore freely it won't perform as good as an online RL method. \n",
    "    -  Its performance is bounded to the quality of the dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1fa47cc903de259dc4fe0eb866c1abbdf9745b83ed486d15bf7573a1fd3b3fc8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

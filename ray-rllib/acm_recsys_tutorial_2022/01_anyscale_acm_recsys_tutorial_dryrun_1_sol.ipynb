{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â© 2019-2022, Anyscale. All Rights Reserved\n",
    "\n",
    "![Anyscale Academy](../../images/AnyscaleAcademyLogo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning objectives\n",
    "In this this tutorial, you will learn about:\n",
    " * [Defining a MDP for recommendation system using gym API](#recsys) -15 min\n",
    " * [Online RL - Bandits](#bandits) -15 min\n",
    " * [Online RL - DQN](#dqn) -15 min\n",
    " * [Break](#break) -5 min\n",
    " * [Offline RL](#offline-rl) -15 min\n",
    "\n",
    "[Link to slides](https://github.com/anyscale/academy/blob/main/ray-rllib/acm_recsys_tutorial_2022/slides/rllib_acm_recsys_2022_slides.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a RecSys gym environment <a class=\"anchor\" id=\"recsys\"></a>\n",
    "\n",
    "RL is usually a fit when it comes to sequential decision making problems. For example in recommendation systems, the particular items that our AI recommends could impact the interest profile of the users that it interacts with and as result, can have consequences on the next time-step that it is making a decision. This is in contrast to the passive prediction problems where the task is simply to predict the future and that prediction does not change the outcome.\n",
    "\n",
    "To successfully train RL agents we usually need a good simulator that can approximate real-world behavior about what is going to happen if your agent takes certain actions. It is always recomended to start with an environment that can be used to emulate real-world behavior. \n",
    "\n",
    "In this section, we will learn how to create and evaluate an exemplar RecSys environment using gym API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecSim\n",
    "\n",
    "In this notebook, we will use <b><a href=\"https://github.com/google-research/recsim\">Google's RecSim environment</a></b>, which was developed for the YouTube recommendation problem.  It is a configurable environment, where ideally you would plug in your own users, products, and embedding features.\n",
    "\n",
    "**Some further readings**\n",
    "\n",
    "- <a href=\"https://github.com/google-research/recsim\">RecSim github</a>\n",
    "- <a href=\"https://arxiv.org/pdf/1909.04847.pdf\">RecSim paper</a>\n",
    "\n",
    "The following image depicts all the components of the recsim packages:\n",
    "\n",
    "<img src=\"./images/recsim_environment.png\" width=\"70%\" />\n",
    "\n",
    "The environment is <i>Timelimit-based</i>, meaning the termination condition for an episode will be after a fixed number (10) of videos are watched. \n",
    "\n",
    "### Document Model\n",
    "\n",
    "<img src=\"./images/document_model.png\" width=\"70%\" />\n",
    "\n",
    "Documents represent the candidate pool of items that need to be recommended with features sampled in the range [0, 1].  In this tutorial, we use <b>1 single feature \"sweetness\"</b> drawn from a uniform distribution between [0.8, 1.0] to represent \"chocolaty\" items and [0, 0.2] for the \"kaley\" options. \n",
    "- The documents can be different at each step (produced by some \"candidate generation\" process), or fixed throughout the simulation.\n",
    "- The recommendation algorithm observes the D candidate documents.  It then makes a selection (possibly ordered) of k documents and presents them in a \"slate\" to the user. We will focus on **slate size of 1** in this tutorial. \n",
    "\n",
    "### User Model\n",
    "\n",
    "<img src=\"./images/user_model.png\" width=\"70%\" />\n",
    "\n",
    "In RecSim users are representation by a set of features some of which could be latent hidden variables not observed by our recommendation system during live interaction. In this tutorial we assume that a sampled user from the world does not own any observable features like age, gender, etc. and our AI should infer the latent state of the user from its history of interactions in the current session. \n",
    "- The user examines a \"slate\" of recommended items and makes a choice of one item. After making their choice, the user emits an engagement score which indicates how much that user was engaged with that particular item they chose. The agent has to learn to estimate the latent states of the user that shape their choice model in the future. \n",
    "\n",
    "### User Choice\n",
    "\n",
    "<img src=\"./images/user_choice_model.png\" width=\"70%\" />\n",
    "\n",
    "This module controls how a particular user would respond to a set of recommendations and how its latent state would evolve as a function of this interaction. \n",
    "In the environment in this tutorial, engagement is assumed to be a function of two competing phenomenas:\n",
    "-   The love of the user for sweet items ($sweetness(item_t)$)\n",
    "-   The long term satisfaction which cares about healthier options. It is inversely correlated with the sweetness of items suggested so far ($satisfaction_{t-1}$)\n",
    "\n",
    "$$satisfaction_t := satisfaction_{t-1} * \\sigma(-sweetness(item_{t}))$$\n",
    "$$r(item_t) \\propto sweetness(item_t) * satisfaction_{t-1}$$\n",
    "\n",
    "i.e. If a user who loves chocolates have not had chocolate for a while, a chocolate item would be more engaging than a kaley item. On the other hand if we keep recommending chocolate to the same person, they may lose interest and not use our recommendations. \n",
    "\n",
    "\n",
    "Let's look at this enviornement properties closer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment for running on anyscale\n",
    "# import os; os.environ[\"PATH\"] = \"/home/ray/anaconda3/bin:\" + os.environ[\"PATH\"]\n",
    "# !pip uninstall -y torch\n",
    "# !python -m pip install torch==1.12.1\n",
    "# !python -m pip install seaborn\n",
    "# import torch\n",
    "# print(f\"torch: {torch.__version__}\")\n",
    "\n",
    "# !pip uninstall -y -r matplotlib\n",
    "# !python3 -m pip install matplotlib==3.5.3\n",
    "# import matplotlib\n",
    "# print(f\"matplotlib: {matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _DATATYPE = _descriptor.EnumDescriptor(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _TENSORPROTO = _descriptor.Descriptor(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _ATTRVALUE_LISTVALUE = _descriptor.Descriptor(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/keras/utils/image_utils.py:36: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  'nearest': pil_image.NEAREST,\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/keras/utils/image_utils.py:37: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  'bilinear': pil_image.BILINEAR,\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/keras/utils/image_utils.py:38: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  'bicubic': pil_image.BICUBIC,\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/keras/utils/image_utils.py:39: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "  'hamming': pil_image.HAMMING,\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/keras/utils/image_utils.py:40: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "  'box': pil_image.BOX,\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/keras/utils/image_utils.py:41: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  'lanczos': pil_image.LANCZOS,\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/gin/tf/__init__.py:48: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if (distutils.version.LooseVersion(tf.__version__) <\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow_probability/python/__init__.py:61: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if (distutils.version.LooseVersion(tf.__version__) <\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ray import tune, air, data\n",
    "\n",
    "import recsim \n",
    "from rllib_recsim.rllib_recsim import ModifiedLongTermSatisfactionRecSimEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main parameters\n",
    "seed = 100\n",
    "num_candidates = 20\n",
    "reward_scale = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ModifiedLongTermSatisfactionRecSimEnv<RecSimRewardScalingWrapper<MultiDiscreteToDiscreteActionWrapper<RecSimObservationSpaceWrapper<RecSimResetWrapper<RecSimGymEnv instance>>>>>>\n"
     ]
    }
   ],
   "source": [
    "# Let's first instantiate the environment\n",
    "\n",
    "config = {\n",
    "    # The number of possible documents/videos/candidates that we can recommend\n",
    "    \"num_candidates\": num_candidates,  \n",
    "    # The number of recommendations that we will be making\n",
    "    \"slate_size\": 1, \n",
    "    # Set to False for re-using the same candidate documents each timestep.\n",
    "    \"resample_documents\": True,\n",
    "    # Use consistent seeds for the environment ...\n",
    "    \"seed\": seed,\n",
    "    # scale rewards with this factor\n",
    "    \"reward_scale\": reward_scale,\n",
    "}\n",
    "\n",
    "env = ModifiedLongTermSatisfactionRecSimEnv(config)\n",
    "print(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The printed environment shows a hierarchy of wrappers around the main RecSim environment. Next we'll investigate the behavior of observation and action space. For more info on how the environment is actually implemented we refer you to the source code acompanied with this tutorial [link](https://github.com/anyscale/academy/blob/main/ray-rllib/acm_recsys_tutorial_2022/rllib_recsim/rllib_recsim.py). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_space:\n",
      "--------------------\n",
      "Dict(user:Box([], [], (0,), float32), doc:Dict(0:Box(0.0, 1.0, (1,), float32), 1:Box(0.0, 1.0, (1,), float32), 2:Box(0.0, 1.0, (1,), float32), 3:Box(0.0, 1.0, (1,), float32), 4:Box(0.0, 1.0, (1,), float32), 5:Box(0.0, 1.0, (1,), float32), 6:Box(0.0, 1.0, (1,), float32), 7:Box(0.0, 1.0, (1,), float32), 8:Box(0.0, 1.0, (1,), float32), 9:Box(0.0, 1.0, (1,), float32), 10:Box(0.0, 1.0, (1,), float32), 11:Box(0.0, 1.0, (1,), float32), 12:Box(0.0, 1.0, (1,), float32), 13:Box(0.0, 1.0, (1,), float32), 14:Box(0.0, 1.0, (1,), float32), 15:Box(0.0, 1.0, (1,), float32), 16:Box(0.0, 1.0, (1,), float32), 17:Box(0.0, 1.0, (1,), float32), 18:Box(0.0, 1.0, (1,), float32), 19:Box(0.0, 1.0, (1,), float32)), response:Tuple(Dict(click:Discrete(2), engagement:Box(-1.0, 100.0, (), float32))), time:Box(-0.5, 0.5, (1,), float32))\n",
      "observation_space example:\n",
      "--------------------\n",
      "OrderedDict([('user', array([], dtype=float32)), ('doc', OrderedDict([('0', array([0.7779674], dtype=float32)), ('1', array([0.00298773], dtype=float32)), ('2', array([0.9206979], dtype=float32)), ('3', array([0.15849109], dtype=float32)), ('4', array([0.63859844], dtype=float32)), ('5', array([0.7074374], dtype=float32)), ('6', array([0.67612886], dtype=float32)), ('7', array([0.38080686], dtype=float32)), ('8', array([0.9994055], dtype=float32)), ('9', array([0.85185015], dtype=float32)), ('10', array([0.12894596], dtype=float32)), ('11', array([0.33710033], dtype=float32)), ('12', array([0.8248622], dtype=float32)), ('13', array([0.6723147], dtype=float32)), ('14', array([0.9291886], dtype=float32)), ('15', array([0.9964431], dtype=float32)), ('16', array([0.35396305], dtype=float32)), ('17', array([0.9029105], dtype=float32)), ('18', array([0.09634282], dtype=float32)), ('19', array([0.01042191], dtype=float32))])), ('response', (OrderedDict([('click', 1), ('engagement', array(0.70971435, dtype=float32))]),)), ('time', array([-0.10854446], dtype=float32))])\n",
      "observation space keys:\n",
      "--------------------\n",
      "['user', 'doc', 'response', 'time']\n"
     ]
    }
   ],
   "source": [
    "# Let's checkout the observation space and action space\n",
    "print(\"observation_space:\")\n",
    "print(\"-\"*20)\n",
    "print(env.observation_space)\n",
    "print(\"observation_space example:\")\n",
    "print(\"-\"*20)\n",
    "print(env.observation_space.sample())\n",
    "print(\"observation space keys:\")\n",
    "print(\"-\"*20)\n",
    "print(list(env.observation_space.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observation space is a dictionary of four keys. \n",
    "- The `user` key is empty, because there is no observable user features. \n",
    "- The `doc` key contains a set of documents presented with numerical keys. Each doc item has a scalar score representing its sweetness. \n",
    "- The `response` key includes a single record of `click` and `engagement` from the immediate previous interaction. \n",
    "- The `time` shows a normalized timestep within the session for this user. -0.5 corresponds to the beginnig of the interaction and +0.5 corresponds to the end of the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_space:\n",
      "--------------------\n",
      "Discrete(20)\n",
      "action_space example:\n",
      "--------------------\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Let's checkout the action space\n",
    "print(\"action_space:\")\n",
    "print(\"-\"*20)\n",
    "print(env.action_space)\n",
    "print(\"action_space example:\")\n",
    "print(\"-\"*20)\n",
    "print(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The action space is simply an integer number between 0, 19 (`Discrete(20)`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now checkout environment's reward behavior. Let's see what happens if we always pick the sweetest item and plot the reward over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's checkout the reward space\n",
    "# TODO: code here\n",
    "rewards = []\n",
    "obs = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = int(max(obs[\"doc\"], key=lambda x: obs[\"doc\"][x]))\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    rewards.append(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'step')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rewards)\n",
    "plt.ylabel('engagement per step for maximum greedy policy')\n",
    "plt.xlabel('step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can note a couple of things here already:\n",
    "\n",
    "1. The immediate engagement would be high initially when the sweetest item is suggested for the first time.\n",
    "2. As we keep recommending the sweetest items, the user satisfaction significantly tampers off and as a result engagement quickly drops.\n",
    "3. Episodes seem to last for 10 timesteps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise (2 min):\n",
    "Instead of picking the item with the highest feature, pick the item with the lowest feature and see what happens?\n",
    "\n",
    "- What do your observations imply about this environment?\n",
    "- What policy maximizes engagement with the user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "rewards = []\n",
    "done = False\n",
    "while not done:\n",
    "    # TODO (exercise): code here\n",
    "    action = int(min(obs[\"doc\"], key=lambda x: obs[\"doc\"][x]))\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    rewards.append(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'step')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rewards)\n",
    "plt.ylabel('engagement per step for minimum greedy policy')\n",
    "plt.xlabel('step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting some baseline policies\n",
    "Next we will run some simple baselines to get a feeling of the reward we can accumulate in these enviornements using simple policies.\n",
    "\n",
    "- Greedy minimum feature value (recommending the kaliest option)\n",
    "- Greedy maximum feature value (recommending the chocoletiest option)\n",
    "- random policy (recommending random items from the pool)\n",
    "- even argmin (recommmending alternations between argmax and argmin to keep the engagement high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that measures and outputs the random baseline reward.\n",
    "# This computes  the expected accumulated reward per episode, if we act randomly (recommend random items) at each time step.\n",
    "def calc_baseline(baseline_type=\"random\",\n",
    "                  episodes=100):\n",
    "\n",
    "    env_config = {\n",
    "        # The number of possible documents/videos/candidates that we can recommend\n",
    "        # no flattening necessary (see `convert_to_discrete_action_space=False` below)\n",
    "        \"num_candidates\": num_candidates,  \n",
    "        # The number of recommendations that we will be making\n",
    "        \"slate_size\": 1, \n",
    "        # Set to False for re-using the same candidate documents each timestep.\n",
    "        \"resample_documents\": True,\n",
    "        # Use consistent seeds for the environment ...\n",
    "        \"seed\": seed,\n",
    "        # scale rewards with this factor\n",
    "        \"reward_scale\": reward_scale,\n",
    "    }\n",
    "\n",
    "    env = ModifiedLongTermSatisfactionRecSimEnv(env_config)\n",
    "    # Reset the env.\n",
    "    obs = env.reset()\n",
    "\n",
    "    # Number of episodes already done.\n",
    "    num_episodes = 0\n",
    "    # Current episode's accumulated reward.\n",
    "    episode_reward = 0.0\n",
    "    epsiode_satisfaction = []\n",
    "    # Collect all episode rewards here to be able to calculate a random baseline reward.\n",
    "    episode_rewards = []\n",
    "    episode_satisfactions = []\n",
    "    \n",
    "    # Enter while loop (to step through the episode).\n",
    "    time_step = 0\n",
    "    while num_episodes < episodes:\n",
    "        # Produce an action\n",
    "        # TODO: code here\n",
    "        random_action = env.action_space.sample()\n",
    "        argmax_action = int(max(obs['doc'], key=lambda x: obs['doc'][x]))\n",
    "        argmin_action = int(min(obs['doc'], key=lambda x: obs['doc'][x]))\n",
    "\n",
    "        action_dict = {\n",
    "            'argmax': argmax_action, # greedy choc\n",
    "            'argmin': argmin_action, # greedy kale\n",
    "            'random': random_action,\n",
    "        }\n",
    "        # a baseline that performs argmax in even time steps and argmin in odd time steps\n",
    "        action_dict[\"even_argmin\"] = (\n",
    "            action_dict[\"argmin\"] if time_step % 2 == 0 else action_dict[\"argmax\"]\n",
    "        )\n",
    "        action = action_dict[baseline_type]\n",
    "        \n",
    "        # Send the action to the env's `step()` method to receive: obs, reward, done, and info.\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # Accumulate the rewards\n",
    "        episode_reward += reward\n",
    "        \n",
    "        # Append satisfaction to episode_satiscation\n",
    "        epsiode_satisfaction.append(\n",
    "            env.environment._user_model._user_state.satisfaction\n",
    "        )\n",
    "\n",
    "        time_step += 1\n",
    "        # Check, whether the episde is done, if yes, reset and increase episode counter.\n",
    "        if done:\n",
    "            if num_episodes % 99 == 0:\n",
    "                print(f\" {num_episodes} \", end=\"\")\n",
    "            elif num_episodes % 9 == 0:\n",
    "                print(\".\", end=\"\")\n",
    "                \n",
    "            # increment on end of episode\n",
    "            num_episodes += 1\n",
    "            time_step = 0\n",
    "            obs = env.reset()\n",
    "            episode_rewards.append(episode_reward)\n",
    "            episode_reward = 0.0\n",
    "            episode_satisfactions.append(np.mean(epsiode_satisfaction))\n",
    "\n",
    "    # Print out and return mean episode reward (and standard error of the mean).\n",
    "    env_mean_reward = np.mean(episode_rewards)\n",
    "    env_sd_reward = np.std(episode_rewards)\n",
    "\n",
    "    # Print out the satisfaction over the episodes\n",
    "    env_mean_satisfaction = np.mean(episode_satisfactions)\n",
    "    env_sd_satisfaction = np.std(episode_satisfactions)\n",
    "    \n",
    "    print(f\"\\nMean {baseline_type} baseline reward: {env_mean_reward:.2f}+/-{env_sd_reward:.2f}, satisfaction: {env_mean_satisfaction:.2f}+/-{env_sd_satisfaction:.2f}\")\n",
    "\n",
    "    return env_mean_reward, episode_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 .......... 99 .......... 198 .......... 297 .......... 396 .......... 495 .......... 594 .......... 693 .......... 792 .......... 891 .......... 990 .\n",
      "Mean argmin baseline reward: 10.87+/-0.26, satisfaction: 0.91+/-0.00\n",
      " 0 .......... 99 .......... 198 .......... 297 .......... 396 .......... 495 .......... 594 .......... 693 .......... 792 .......... 891 .......... 990 .\n",
      "Mean argmax baseline reward: 56.56+/-1.37, satisfaction: 0.14+/-0.00\n",
      " 0 .......... 99 .......... 198 .......... 297 .......... 396 .......... 495 .......... 594 .......... 693 .......... 792 .......... 891 .......... 990 .\n",
      "Mean random baseline reward: 98.51+/-24.20, satisfaction: 0.54+/-0.01\n",
      " 0 .......... 99 .......... 198 .......... 297 .......... 396 .......... 495 .......... 594 .......... 693 .......... 792 .......... 891 .......... 990 .\n",
      "Mean even_argmin baseline reward: 172.15+/-4.59, satisfaction: 0.57+/-0.00\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 1000\n",
    "kaliest_baseline, _ = calc_baseline(baseline_type=\"argmin\", episodes=num_episodes)\n",
    "sweetest_baseline,  _ = calc_baseline(baseline_type=\"argmax\", episodes=num_episodes)\n",
    "random_baseline, _ = calc_baseline(baseline_type=\"random\", episodes=num_episodes)\n",
    "even_margin_baseline, _ = calc_baseline(baseline_type=\"even_argmin\", episodes=num_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion about the baselines\n",
    "\n",
    "For every baseline we have printed out not only the engagement score of the entire user session but also the average of the satisfaction term over the entire session as well.\n",
    "- **Random policy beats greedy options**\n",
    "- **Alternation between argmax and argmin beats random**\n",
    "\n",
    "The question is whether we automatically learn an optimal policy in this recommendation enviornement?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions (2 min)\n",
    "\n",
    "- Any questions so far?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a contextual bandit on the environment <a class=\"anchor\" id=\"bandits\"></a>\n",
    "\n",
    "Bandit is a classical algorithm used in RecSys that is known to optimize single-step objectives. **They maximize immediate engagement not accumulated engagement over the user session.**\n",
    "\n",
    "Any RL algorithm can be turned into a contextual bandit algorithm if the discount factor of the Markov Decision Process is set to 0.0. This will result in maximizing the immediate reward and hence a bandit solution. \n",
    "\n",
    "In this section, we will use [DQN](https://docs.ray.io/en/latest/rllib/rllib-algorithms.html#dqn) to train an agent both with $\\gamma = 0$ and $\\gamma = 0.99$ to see the difference between a bandit solution and an RL solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the config below we set a few settings:\n",
    "- For the environment, we specify 20 candidates that are randomly re-sampled at each time-step.\n",
    "- We use the torch implementation of the algorithm in RLlib\n",
    "- For evaluation, we rollout 100 complete episodes at the end of each training iteration and compute the average of un-discounted reward over the episode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tune to register the environment\n",
    "tune.register_env(\"modified-lts\", \n",
    "    lambda config: ModifiedLongTermSatisfactionRecSimEnv(config)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.dqn import DQNConfig, DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the environment config\n",
    "env_config = {\n",
    "    \"num_candidates\": num_candidates,  \n",
    "    \"slate_size\": 1, \n",
    "    \"resample_documents\": True,\n",
    "    \"seed\": seed,\n",
    "    \"reward_scale\": reward_scale\n",
    "}\n",
    "\n",
    "bandit_config = DQNConfig()\n",
    "# setup the env\n",
    "bandit_config = bandit_config.environment(env=\"modified-lts\", env_config=env_config)\n",
    "# setup framework to be torch\n",
    "bandit_config = bandit_config.framework(\"torch\")\n",
    "# setup the gamma\n",
    "bandit_config = bandit_config.training(gamma=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_disable_action_flattening': False,\n",
      " '_disable_execution_plan_api': True,\n",
      " '_disable_preprocessor_api': False,\n",
      " '_fake_gpus': False,\n",
      " '_tf_policy_handles_more_than_one_loss': False,\n",
      " 'action_space': None,\n",
      " 'actions_in_input_normalized': False,\n",
      " 'adam_epsilon': 1e-08,\n",
      " 'always_attach_evaluation_results': False,\n",
      " 'batch_mode': 'truncate_episodes',\n",
      " 'before_learn_on_batch': None,\n",
      " 'buffer_size': -1,\n",
      " 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
      " 'clip_actions': False,\n",
      " 'clip_rewards': None,\n",
      " 'collect_metrics_timeout': -1,\n",
      " 'compress_observations': False,\n",
      " 'create_env_on_driver': False,\n",
      " 'custom_eval_function': None,\n",
      " 'custom_resources_per_worker': {},\n",
      " 'disable_env_checking': False,\n",
      " 'double_q': True,\n",
      " 'dueling': True,\n",
      " 'eager_max_retraces': 20,\n",
      " 'eager_tracing': False,\n",
      " 'enable_async_evaluation': False,\n",
      " 'enable_connectors': False,\n",
      " 'enable_tf1_exec_eagerly': False,\n",
      " 'env': 'modified-lts',\n",
      " 'env_config': {'num_candidates': 20,\n",
      "                'resample_documents': True,\n",
      "                'reward_scale': 1.0,\n",
      "                'seed': 100,\n",
      "                'slate_size': 1},\n",
      " 'env_task_fn': None,\n",
      " 'evaluation_config': {'explore': False},\n",
      " 'evaluation_duration': 10,\n",
      " 'evaluation_duration_unit': 'episodes',\n",
      " 'evaluation_interval': None,\n",
      " 'evaluation_num_episodes': -1,\n",
      " 'evaluation_num_workers': 0,\n",
      " 'evaluation_parallel_to_training': False,\n",
      " 'evaluation_sample_timeout_s': 180.0,\n",
      " 'exploration_config': {'epsilon_timesteps': 10000,\n",
      "                        'final_epsilon': 0.02,\n",
      "                        'initial_epsilon': 1.0,\n",
      "                        'type': 'EpsilonGreedy'},\n",
      " 'explore': True,\n",
      " 'extra_python_environs_for_driver': {},\n",
      " 'extra_python_environs_for_worker': {},\n",
      " 'fake_sampler': False,\n",
      " 'framework': 'torch',\n",
      " 'gamma': 0.0,\n",
      " 'grad_clip': 40,\n",
      " 'hiddens': [256],\n",
      " 'horizon': None,\n",
      " 'ignore_worker_failures': False,\n",
      " 'in_evaluation': False,\n",
      " 'input': 'sampler',\n",
      " 'input_config': {},\n",
      " 'input_evaluation': -1,\n",
      " 'keep_per_episode_custom_metrics': False,\n",
      " 'learning_starts': -1,\n",
      " 'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                           'intra_op_parallelism_threads': 8},\n",
      " 'log_level': 'WARN',\n",
      " 'log_sys_usage': True,\n",
      " 'logger_config': None,\n",
      " 'logger_creator': None,\n",
      " 'lr': 0.0005,\n",
      " 'lr_schedule': None,\n",
      " 'metrics_episode_collection_timeout_s': 60.0,\n",
      " 'metrics_num_episodes_for_smoothing': 100,\n",
      " 'metrics_smoothing_episodes': -1,\n",
      " 'min_iter_time_s': -1,\n",
      " 'min_sample_timesteps_per_iteration': 1000,\n",
      " 'min_sample_timesteps_per_reporting': -1,\n",
      " 'min_time_s_per_iteration': None,\n",
      " 'min_time_s_per_reporting': -1,\n",
      " 'min_train_timesteps_per_iteration': 0,\n",
      " 'min_train_timesteps_per_reporting': -1,\n",
      " 'model': {'_disable_action_flattening': False,\n",
      "           '_disable_preprocessor_api': False,\n",
      "           '_time_major': False,\n",
      "           '_use_default_native_models': False,\n",
      "           'attention_dim': 64,\n",
      "           'attention_head_dim': 32,\n",
      "           'attention_init_gru_gate_bias': 2.0,\n",
      "           'attention_memory_inference': 50,\n",
      "           'attention_memory_training': 50,\n",
      "           'attention_num_heads': 1,\n",
      "           'attention_num_transformer_units': 1,\n",
      "           'attention_position_wise_mlp_dim': 32,\n",
      "           'attention_use_n_prev_actions': 0,\n",
      "           'attention_use_n_prev_rewards': 0,\n",
      "           'conv_activation': 'relu',\n",
      "           'conv_filters': None,\n",
      "           'custom_action_dist': None,\n",
      "           'custom_model': None,\n",
      "           'custom_model_config': {},\n",
      "           'custom_preprocessor': None,\n",
      "           'dim': 84,\n",
      "           'fcnet_activation': 'tanh',\n",
      "           'fcnet_hiddens': [256, 256],\n",
      "           'framestack': True,\n",
      "           'free_log_std': False,\n",
      "           'grayscale': False,\n",
      "           'lstm_cell_size': 256,\n",
      "           'lstm_use_prev_action': False,\n",
      "           'lstm_use_prev_action_reward': -1,\n",
      "           'lstm_use_prev_reward': False,\n",
      "           'max_seq_len': 20,\n",
      "           'no_final_linear': False,\n",
      "           'post_fcnet_activation': 'relu',\n",
      "           'post_fcnet_hiddens': [],\n",
      "           'use_attention': False,\n",
      "           'use_lstm': False,\n",
      "           'vf_share_layers': True,\n",
      "           'zero_mean': True},\n",
      " 'monitor': -1,\n",
      " 'multiagent': {'count_steps_by': 'env_steps',\n",
      "                'observation_fn': None,\n",
      "                'policies': {},\n",
      "                'policies_to_train': None,\n",
      "                'policy_map_cache': None,\n",
      "                'policy_map_capacity': 100,\n",
      "                'policy_mapping_fn': None,\n",
      "                'replay_mode': 'independent'},\n",
      " 'n_step': 1,\n",
      " 'no_done_at_end': False,\n",
      " 'noisy': False,\n",
      " 'normalize_actions': True,\n",
      " 'num_atoms': 1,\n",
      " 'num_consecutive_worker_failures_tolerance': 100,\n",
      " 'num_cpus_for_driver': 1,\n",
      " 'num_cpus_per_worker': 1,\n",
      " 'num_envs_per_worker': 1,\n",
      " 'num_gpus': 0,\n",
      " 'num_gpus_per_worker': 0,\n",
      " 'num_steps_sampled_before_learning_starts': 1000,\n",
      " 'num_workers': 0,\n",
      " 'observation_filter': 'NoFilter',\n",
      " 'observation_space': None,\n",
      " 'off_policy_estimation_methods': {},\n",
      " 'optimizer': {},\n",
      " 'output': None,\n",
      " 'output_compress_columns': ['obs', 'new_obs'],\n",
      " 'output_config': {},\n",
      " 'output_max_file_size': 67108864,\n",
      " 'placement_strategy': 'PACK',\n",
      " 'postprocess_inputs': False,\n",
      " 'preprocessor_pref': 'deepmind',\n",
      " 'prioritized_replay': -1,\n",
      " 'prioritized_replay_alpha': -1,\n",
      " 'prioritized_replay_beta': -1,\n",
      " 'prioritized_replay_eps': -1,\n",
      " 'recreate_failed_workers': False,\n",
      " 'remote_env_batch_wait_ms': 0,\n",
      " 'remote_worker_envs': False,\n",
      " 'render_env': False,\n",
      " 'replay_batch_size': -1,\n",
      " 'replay_buffer_config': {'capacity': 50000,\n",
      "                          'prioritized_replay': -1,\n",
      "                          'prioritized_replay_alpha': 0.6,\n",
      "                          'prioritized_replay_beta': 0.4,\n",
      "                          'prioritized_replay_eps': 1e-06,\n",
      "                          'replay_sequence_length': 1,\n",
      "                          'type': 'MultiAgentPrioritizedReplayBuffer',\n",
      "                          'worker_side_prioritization': False},\n",
      " 'replay_sequence_length': None,\n",
      " 'restart_failed_sub_environments': False,\n",
      " 'rollout_fragment_length': 4,\n",
      " 'sample_async': False,\n",
      " 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      " 'sampler_perf_stats_ema_coef': None,\n",
      " 'seed': None,\n",
      " 'shuffle_buffer_size': 0,\n",
      " 'sigma0': 0.5,\n",
      " 'simple_optimizer': -1,\n",
      " 'soft_horizon': False,\n",
      " 'store_buffer_in_checkpoints': False,\n",
      " 'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
      " 'synchronize_filters': True,\n",
      " 'target_network_update_freq': 500,\n",
      " 'tf_session_args': {'allow_soft_placement': True,\n",
      "                     'device_count': {'CPU': 1},\n",
      "                     'gpu_options': {'allow_growth': True},\n",
      "                     'inter_op_parallelism_threads': 2,\n",
      "                     'intra_op_parallelism_threads': 2,\n",
      "                     'log_device_placement': False},\n",
      " 'timesteps_per_iteration': -1,\n",
      " 'train_batch_size': 32,\n",
      " 'training_intensity': None,\n",
      " 'v_max': 10.0,\n",
      " 'v_min': -10.0,\n",
      " 'validate_workers_after_construction': True}\n"
     ]
    }
   ],
   "source": [
    "pprint(bandit_config.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In RLlib we can run training loops in two ways:\n",
    "1. Ad-hoc for-loop via calling algo.train()\n",
    "2. Using `tune.Tuner()` with stopping condition (recommended)\n",
    "\n",
    "The code below shows the differences. Moving forward (and in all scripts) we use the later option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 14:28:17,741\tWARNING deprecation.py:47 -- DeprecationWarning: `ray.rllib.algorithms.dqn.dqn.DEFAULT_CONFIG` has been deprecated. Use `ray.rllib.algorithms.dqn.dqn.DQNConfig(...)` instead. This will raise an error in the future!\n",
      "2022-09-14 14:28:17,743\tWARNING deprecation.py:47 -- DeprecationWarning: `config['multiagent']['replay_mode']` has been deprecated. config['replay_buffer_config']['replay_mode'] This will raise an error in the future!\n",
      "/Users/kourosh/dev/workspace-project-gpu-workspace-kh/python/ray/_private/ray_option_utils.py:284: DeprecationWarning: Setting 'object_store_memory' for actors is deprecated since it doesn't actually reserve the required object store memory. Use object spilling that's enabled by default (https://docs.ray.io/en/master/ray-core/objects/object-spilling.html) instead to bypass the object store memory size limitation.\n",
      "  warnings.warn(\n",
      "2022-09-14 14:28:19,767\tINFO worker.py:1517 -- Started a local Ray instance.\n",
      "2022-09-14 14:28:20,895\tWARNING env.py:142 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "2022-09-14 14:28:20,990\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
      "2022-09-14 14:28:21,004\tWARNING deprecation.py:47 -- DeprecationWarning: `ReplayBuffer.add_batch()` has been deprecated. Use `ReplayBuffer.add()` instead. This will raise an error in the future!\n",
      "2022-09-14 14:28:21,013\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n"
     ]
    }
   ],
   "source": [
    "# Ad-hoc for-loop\n",
    "# TODO: Code here\n",
    "num_iterations = 1\n",
    "algo = bandit_config.build()\n",
    "for iter_step in range(num_iterations):\n",
    "    results_bandit = algo.train()\n",
    "algo.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['custom_metrics', 'episode_media', 'num_recreated_workers', 'info', 'sampler_results', 'episode_reward_max', 'episode_reward_min', 'episode_reward_mean', 'episode_len_mean', 'episodes_this_iter', 'policy_reward_min', 'policy_reward_max', 'policy_reward_mean', 'hist_stats', 'sampler_perf', 'num_faulty_episodes', 'num_healthy_workers', 'num_agent_steps_sampled', 'num_agent_steps_trained', 'num_env_steps_sampled', 'num_env_steps_trained', 'num_env_steps_sampled_this_iter', 'num_env_steps_trained_this_iter', 'timesteps_total', 'num_steps_trained_this_iter', 'agent_timesteps_total', 'timers', 'counters', 'done', 'episodes_total', 'training_iteration', 'trial_id', 'experiment_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'timesteps_since_restore', 'iterations_since_restore', 'warmup_time', 'perf'])\n",
      "{'agent_timesteps_total': 1000,\n",
      " 'config': {'_disable_action_flattening': False,\n",
      "            '_disable_execution_plan_api': True,\n",
      "            '_disable_preprocessor_api': False,\n",
      "            '_fake_gpus': False,\n",
      "            '_tf_policy_handles_more_than_one_loss': False,\n",
      "            'action_space': None,\n",
      "            'actions_in_input_normalized': False,\n",
      "            'adam_epsilon': 1e-08,\n",
      "            'always_attach_evaluation_results': False,\n",
      "            'batch_mode': 'truncate_episodes',\n",
      "            'before_learn_on_batch': None,\n",
      "            'buffer_size': -1,\n",
      "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
      "            'clip_actions': False,\n",
      "            'clip_rewards': None,\n",
      "            'collect_metrics_timeout': -1,\n",
      "            'compress_observations': False,\n",
      "            'create_env_on_driver': False,\n",
      "            'custom_eval_function': None,\n",
      "            'custom_resources_per_worker': {},\n",
      "            'disable_env_checking': False,\n",
      "            'double_q': True,\n",
      "            'dueling': True,\n",
      "            'eager_max_retraces': 20,\n",
      "            'eager_tracing': False,\n",
      "            'enable_async_evaluation': False,\n",
      "            'enable_connectors': False,\n",
      "            'enable_tf1_exec_eagerly': False,\n",
      "            'env': 'modified-lts',\n",
      "            'env_config': {'num_candidates': 20,\n",
      "                           'resample_documents': True,\n",
      "                           'reward_scale': 1.0,\n",
      "                           'seed': 100,\n",
      "                           'slate_size': 1},\n",
      "            'env_task_fn': None,\n",
      "            'evaluation_config': {'_disable_action_flattening': False,\n",
      "                                  '_disable_execution_plan_api': True,\n",
      "                                  '_disable_preprocessor_api': False,\n",
      "                                  '_fake_gpus': False,\n",
      "                                  '_tf_policy_handles_more_than_one_loss': False,\n",
      "                                  'action_space': None,\n",
      "                                  'actions_in_input_normalized': False,\n",
      "                                  'adam_epsilon': 1e-08,\n",
      "                                  'always_attach_evaluation_results': False,\n",
      "                                  'batch_mode': 'truncate_episodes',\n",
      "                                  'before_learn_on_batch': None,\n",
      "                                  'buffer_size': -1,\n",
      "                                  'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
      "                                  'clip_actions': False,\n",
      "                                  'clip_rewards': None,\n",
      "                                  'collect_metrics_timeout': -1,\n",
      "                                  'compress_observations': False,\n",
      "                                  'create_env_on_driver': False,\n",
      "                                  'custom_eval_function': None,\n",
      "                                  'custom_resources_per_worker': {},\n",
      "                                  'disable_env_checking': False,\n",
      "                                  'double_q': True,\n",
      "                                  'dueling': True,\n",
      "                                  'eager_max_retraces': 20,\n",
      "                                  'eager_tracing': False,\n",
      "                                  'enable_async_evaluation': False,\n",
      "                                  'enable_connectors': False,\n",
      "                                  'enable_tf1_exec_eagerly': False,\n",
      "                                  'env': 'modified-lts',\n",
      "                                  'env_config': {'num_candidates': 20,\n",
      "                                                 'resample_documents': True,\n",
      "                                                 'reward_scale': 1.0,\n",
      "                                                 'seed': 100,\n",
      "                                                 'slate_size': 1},\n",
      "                                  'env_task_fn': None,\n",
      "                                  'evaluation_config': {'explore': False},\n",
      "                                  'evaluation_duration': 10,\n",
      "                                  'evaluation_duration_unit': 'episodes',\n",
      "                                  'evaluation_interval': None,\n",
      "                                  'evaluation_num_episodes': -1,\n",
      "                                  'evaluation_num_workers': 0,\n",
      "                                  'evaluation_parallel_to_training': False,\n",
      "                                  'evaluation_sample_timeout_s': 180.0,\n",
      "                                  'exploration_config': {'epsilon_timesteps': 10000,\n",
      "                                                         'final_epsilon': 0.02,\n",
      "                                                         'initial_epsilon': 1.0,\n",
      "                                                         'type': 'EpsilonGreedy'},\n",
      "                                  'explore': False,\n",
      "                                  'extra_python_environs_for_driver': {},\n",
      "                                  'extra_python_environs_for_worker': {},\n",
      "                                  'fake_sampler': False,\n",
      "                                  'framework': 'torch',\n",
      "                                  'gamma': 0.0,\n",
      "                                  'grad_clip': 40,\n",
      "                                  'hiddens': [256],\n",
      "                                  'horizon': None,\n",
      "                                  'ignore_worker_failures': False,\n",
      "                                  'in_evaluation': False,\n",
      "                                  'input': 'sampler',\n",
      "                                  'input_config': {},\n",
      "                                  'input_evaluation': -1,\n",
      "                                  'keep_per_episode_custom_metrics': False,\n",
      "                                  'learning_starts': -1,\n",
      "                                  'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                                                            'intra_op_parallelism_threads': 8},\n",
      "                                  'log_level': 'WARN',\n",
      "                                  'log_sys_usage': True,\n",
      "                                  'logger_config': None,\n",
      "                                  'logger_creator': None,\n",
      "                                  'lr': 0.0005,\n",
      "                                  'lr_schedule': None,\n",
      "                                  'metrics_episode_collection_timeout_s': 60.0,\n",
      "                                  'metrics_num_episodes_for_smoothing': 100,\n",
      "                                  'metrics_smoothing_episodes': -1,\n",
      "                                  'min_iter_time_s': -1,\n",
      "                                  'min_sample_timesteps_per_iteration': 1000,\n",
      "                                  'min_sample_timesteps_per_reporting': -1,\n",
      "                                  'min_time_s_per_iteration': None,\n",
      "                                  'min_time_s_per_reporting': -1,\n",
      "                                  'min_train_timesteps_per_iteration': 0,\n",
      "                                  'min_train_timesteps_per_reporting': -1,\n",
      "                                  'model': {'_disable_action_flattening': False,\n",
      "                                            '_disable_preprocessor_api': False,\n",
      "                                            '_time_major': False,\n",
      "                                            '_use_default_native_models': False,\n",
      "                                            'attention_dim': 64,\n",
      "                                            'attention_head_dim': 32,\n",
      "                                            'attention_init_gru_gate_bias': 2.0,\n",
      "                                            'attention_memory_inference': 50,\n",
      "                                            'attention_memory_training': 50,\n",
      "                                            'attention_num_heads': 1,\n",
      "                                            'attention_num_transformer_units': 1,\n",
      "                                            'attention_position_wise_mlp_dim': 32,\n",
      "                                            'attention_use_n_prev_actions': 0,\n",
      "                                            'attention_use_n_prev_rewards': 0,\n",
      "                                            'conv_activation': 'relu',\n",
      "                                            'conv_filters': None,\n",
      "                                            'custom_action_dist': None,\n",
      "                                            'custom_model': None,\n",
      "                                            'custom_model_config': {},\n",
      "                                            'custom_preprocessor': None,\n",
      "                                            'dim': 84,\n",
      "                                            'fcnet_activation': 'tanh',\n",
      "                                            'fcnet_hiddens': [256, 256],\n",
      "                                            'framestack': True,\n",
      "                                            'free_log_std': False,\n",
      "                                            'grayscale': False,\n",
      "                                            'lstm_cell_size': 256,\n",
      "                                            'lstm_use_prev_action': False,\n",
      "                                            'lstm_use_prev_action_reward': -1,\n",
      "                                            'lstm_use_prev_reward': False,\n",
      "                                            'max_seq_len': 20,\n",
      "                                            'no_final_linear': False,\n",
      "                                            'post_fcnet_activation': 'relu',\n",
      "                                            'post_fcnet_hiddens': [],\n",
      "                                            'use_attention': False,\n",
      "                                            'use_lstm': False,\n",
      "                                            'vf_share_layers': True,\n",
      "                                            'zero_mean': True},\n",
      "                                  'monitor': -1,\n",
      "                                  'multiagent': {'count_steps_by': 'env_steps',\n",
      "                                                 'observation_fn': None,\n",
      "                                                 'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x2868adc70>},\n",
      "                                                 'policies_to_train': None,\n",
      "                                                 'policy_map_cache': None,\n",
      "                                                 'policy_map_capacity': 100,\n",
      "                                                 'policy_mapping_fn': None,\n",
      "                                                 'replay_mode': 'independent'},\n",
      "                                  'n_step': 1,\n",
      "                                  'no_done_at_end': False,\n",
      "                                  'noisy': False,\n",
      "                                  'normalize_actions': True,\n",
      "                                  'num_atoms': 1,\n",
      "                                  'num_consecutive_worker_failures_tolerance': 100,\n",
      "                                  'num_cpus_for_driver': 1,\n",
      "                                  'num_cpus_per_worker': 1,\n",
      "                                  'num_envs_per_worker': 1,\n",
      "                                  'num_gpus': 0,\n",
      "                                  'num_gpus_per_worker': 0,\n",
      "                                  'num_steps_sampled_before_learning_starts': 1000,\n",
      "                                  'num_workers': 0,\n",
      "                                  'observation_filter': 'NoFilter',\n",
      "                                  'observation_space': None,\n",
      "                                  'off_policy_estimation_methods': {},\n",
      "                                  'optimizer': {},\n",
      "                                  'output': None,\n",
      "                                  'output_compress_columns': ['obs', 'new_obs'],\n",
      "                                  'output_config': {},\n",
      "                                  'output_max_file_size': 67108864,\n",
      "                                  'placement_strategy': 'PACK',\n",
      "                                  'postprocess_inputs': False,\n",
      "                                  'preprocessor_pref': 'deepmind',\n",
      "                                  'prioritized_replay': -1,\n",
      "                                  'prioritized_replay_alpha': -1,\n",
      "                                  'prioritized_replay_beta': -1,\n",
      "                                  'prioritized_replay_eps': -1,\n",
      "                                  'recreate_failed_workers': False,\n",
      "                                  'remote_env_batch_wait_ms': 0,\n",
      "                                  'remote_worker_envs': False,\n",
      "                                  'render_env': False,\n",
      "                                  'replay_batch_size': -1,\n",
      "                                  'replay_buffer_config': {'capacity': 50000,\n",
      "                                                           'prioritized_replay': -1,\n",
      "                                                           'prioritized_replay_alpha': 0.6,\n",
      "                                                           'prioritized_replay_beta': 0.4,\n",
      "                                                           'prioritized_replay_eps': 1e-06,\n",
      "                                                           'replay_mode': 'independent',\n",
      "                                                           'replay_sequence_length': 1,\n",
      "                                                           'type': <class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>,\n",
      "                                                           'worker_side_prioritization': False},\n",
      "                                  'replay_sequence_length': None,\n",
      "                                  'restart_failed_sub_environments': False,\n",
      "                                  'rollout_fragment_length': 4,\n",
      "                                  'sample_async': False,\n",
      "                                  'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      "                                  'sampler_perf_stats_ema_coef': None,\n",
      "                                  'seed': None,\n",
      "                                  'shuffle_buffer_size': 0,\n",
      "                                  'sigma0': 0.5,\n",
      "                                  'simple_optimizer': False,\n",
      "                                  'soft_horizon': False,\n",
      "                                  'store_buffer_in_checkpoints': False,\n",
      "                                  'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
      "                                  'synchronize_filters': True,\n",
      "                                  'target_network_update_freq': 500,\n",
      "                                  'tf_session_args': {'allow_soft_placement': True,\n",
      "                                                      'device_count': {'CPU': 1},\n",
      "                                                      'gpu_options': {'allow_growth': True},\n",
      "                                                      'inter_op_parallelism_threads': 2,\n",
      "                                                      'intra_op_parallelism_threads': 2,\n",
      "                                                      'log_device_placement': False},\n",
      "                                  'timesteps_per_iteration': -1,\n",
      "                                  'train_batch_size': 32,\n",
      "                                  'training_intensity': None,\n",
      "                                  'v_max': 10.0,\n",
      "                                  'v_min': -10.0,\n",
      "                                  'validate_workers_after_construction': True},\n",
      "            'evaluation_duration': 10,\n",
      "            'evaluation_duration_unit': 'episodes',\n",
      "            'evaluation_interval': None,\n",
      "            'evaluation_num_episodes': -1,\n",
      "            'evaluation_num_workers': 0,\n",
      "            'evaluation_parallel_to_training': False,\n",
      "            'evaluation_sample_timeout_s': 180.0,\n",
      "            'exploration_config': {'epsilon_timesteps': 10000,\n",
      "                                   'final_epsilon': 0.02,\n",
      "                                   'initial_epsilon': 1.0,\n",
      "                                   'type': 'EpsilonGreedy'},\n",
      "            'explore': True,\n",
      "            'extra_python_environs_for_driver': {},\n",
      "            'extra_python_environs_for_worker': {},\n",
      "            'fake_sampler': False,\n",
      "            'framework': 'torch',\n",
      "            'gamma': 0.0,\n",
      "            'grad_clip': 40,\n",
      "            'hiddens': [256],\n",
      "            'horizon': None,\n",
      "            'ignore_worker_failures': False,\n",
      "            'in_evaluation': False,\n",
      "            'input': 'sampler',\n",
      "            'input_config': {},\n",
      "            'input_evaluation': -1,\n",
      "            'keep_per_episode_custom_metrics': False,\n",
      "            'learning_starts': -1,\n",
      "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                                      'intra_op_parallelism_threads': 8},\n",
      "            'log_level': 'WARN',\n",
      "            'log_sys_usage': True,\n",
      "            'logger_config': None,\n",
      "            'logger_creator': None,\n",
      "            'lr': 0.0005,\n",
      "            'lr_schedule': None,\n",
      "            'metrics_episode_collection_timeout_s': 60.0,\n",
      "            'metrics_num_episodes_for_smoothing': 100,\n",
      "            'metrics_smoothing_episodes': -1,\n",
      "            'min_iter_time_s': -1,\n",
      "            'min_sample_timesteps_per_iteration': 1000,\n",
      "            'min_sample_timesteps_per_reporting': -1,\n",
      "            'min_time_s_per_iteration': None,\n",
      "            'min_time_s_per_reporting': -1,\n",
      "            'min_train_timesteps_per_iteration': 0,\n",
      "            'min_train_timesteps_per_reporting': -1,\n",
      "            'model': {'_disable_action_flattening': False,\n",
      "                      '_disable_preprocessor_api': False,\n",
      "                      '_time_major': False,\n",
      "                      '_use_default_native_models': False,\n",
      "                      'attention_dim': 64,\n",
      "                      'attention_head_dim': 32,\n",
      "                      'attention_init_gru_gate_bias': 2.0,\n",
      "                      'attention_memory_inference': 50,\n",
      "                      'attention_memory_training': 50,\n",
      "                      'attention_num_heads': 1,\n",
      "                      'attention_num_transformer_units': 1,\n",
      "                      'attention_position_wise_mlp_dim': 32,\n",
      "                      'attention_use_n_prev_actions': 0,\n",
      "                      'attention_use_n_prev_rewards': 0,\n",
      "                      'conv_activation': 'relu',\n",
      "                      'conv_filters': None,\n",
      "                      'custom_action_dist': None,\n",
      "                      'custom_model': None,\n",
      "                      'custom_model_config': {},\n",
      "                      'custom_preprocessor': None,\n",
      "                      'dim': 84,\n",
      "                      'fcnet_activation': 'tanh',\n",
      "                      'fcnet_hiddens': [256, 256],\n",
      "                      'framestack': True,\n",
      "                      'free_log_std': False,\n",
      "                      'grayscale': False,\n",
      "                      'lstm_cell_size': 256,\n",
      "                      'lstm_use_prev_action': False,\n",
      "                      'lstm_use_prev_action_reward': -1,\n",
      "                      'lstm_use_prev_reward': False,\n",
      "                      'max_seq_len': 20,\n",
      "                      'no_final_linear': False,\n",
      "                      'post_fcnet_activation': 'relu',\n",
      "                      'post_fcnet_hiddens': [],\n",
      "                      'use_attention': False,\n",
      "                      'use_lstm': False,\n",
      "                      'vf_share_layers': True,\n",
      "                      'zero_mean': True},\n",
      "            'monitor': -1,\n",
      "            'multiagent': {'count_steps_by': 'env_steps',\n",
      "                           'observation_fn': None,\n",
      "                           'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x2868ad610>},\n",
      "                           'policies_to_train': None,\n",
      "                           'policy_map_cache': None,\n",
      "                           'policy_map_capacity': 100,\n",
      "                           'policy_mapping_fn': None,\n",
      "                           'replay_mode': 'independent'},\n",
      "            'n_step': 1,\n",
      "            'no_done_at_end': False,\n",
      "            'noisy': False,\n",
      "            'normalize_actions': True,\n",
      "            'num_atoms': 1,\n",
      "            'num_consecutive_worker_failures_tolerance': 100,\n",
      "            'num_cpus_for_driver': 1,\n",
      "            'num_cpus_per_worker': 1,\n",
      "            'num_envs_per_worker': 1,\n",
      "            'num_gpus': 0,\n",
      "            'num_gpus_per_worker': 0,\n",
      "            'num_steps_sampled_before_learning_starts': 1000,\n",
      "            'num_workers': 0,\n",
      "            'observation_filter': 'NoFilter',\n",
      "            'observation_space': None,\n",
      "            'off_policy_estimation_methods': {},\n",
      "            'optimizer': {},\n",
      "            'output': None,\n",
      "            'output_compress_columns': ['obs', 'new_obs'],\n",
      "            'output_config': {},\n",
      "            'output_max_file_size': 67108864,\n",
      "            'placement_strategy': 'PACK',\n",
      "            'postprocess_inputs': False,\n",
      "            'preprocessor_pref': 'deepmind',\n",
      "            'prioritized_replay': -1,\n",
      "            'prioritized_replay_alpha': -1,\n",
      "            'prioritized_replay_beta': -1,\n",
      "            'prioritized_replay_eps': -1,\n",
      "            'recreate_failed_workers': False,\n",
      "            'remote_env_batch_wait_ms': 0,\n",
      "            'remote_worker_envs': False,\n",
      "            'render_env': False,\n",
      "            'replay_batch_size': -1,\n",
      "            'replay_buffer_config': {'capacity': 50000,\n",
      "                                     'prioritized_replay': -1,\n",
      "                                     'prioritized_replay_alpha': 0.6,\n",
      "                                     'prioritized_replay_beta': 0.4,\n",
      "                                     'prioritized_replay_eps': 1e-06,\n",
      "                                     'replay_mode': 'independent',\n",
      "                                     'replay_sequence_length': 1,\n",
      "                                     'type': <class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>,\n",
      "                                     'worker_side_prioritization': False},\n",
      "            'replay_sequence_length': None,\n",
      "            'restart_failed_sub_environments': False,\n",
      "            'rollout_fragment_length': 4,\n",
      "            'sample_async': False,\n",
      "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      "            'sampler_perf_stats_ema_coef': None,\n",
      "            'seed': None,\n",
      "            'shuffle_buffer_size': 0,\n",
      "            'sigma0': 0.5,\n",
      "            'simple_optimizer': False,\n",
      "            'soft_horizon': False,\n",
      "            'store_buffer_in_checkpoints': False,\n",
      "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
      "            'synchronize_filters': True,\n",
      "            'target_network_update_freq': 500,\n",
      "            'tf_session_args': {'allow_soft_placement': True,\n",
      "                                'device_count': {'CPU': 1},\n",
      "                                'gpu_options': {'allow_growth': True},\n",
      "                                'inter_op_parallelism_threads': 2,\n",
      "                                'intra_op_parallelism_threads': 2,\n",
      "                                'log_device_placement': False},\n",
      "            'timesteps_per_iteration': -1,\n",
      "            'train_batch_size': 32,\n",
      "            'training_intensity': None,\n",
      "            'v_max': 10.0,\n",
      "            'v_min': -10.0,\n",
      "            'validate_workers_after_construction': True},\n",
      " 'counters': {'num_agent_steps_sampled': 1000,\n",
      "              'num_agent_steps_trained': 0,\n",
      "              'num_env_steps_sampled': 1000,\n",
      "              'num_env_steps_trained': 0},\n",
      " 'custom_metrics': {},\n",
      " 'date': '2022-09-14_14-28-22',\n",
      " 'done': False,\n",
      " 'episode_len_mean': 10.0,\n",
      " 'episode_media': {},\n",
      " 'episode_reward_max': 170.76252958631184,\n",
      " 'episode_reward_mean': 99.40375292593367,\n",
      " 'episode_reward_min': 45.187937576841456,\n",
      " 'episodes_this_iter': 100,\n",
      " 'episodes_total': 100,\n",
      " 'experiment_id': '438eacd4085544c0a4c317ad837b6c6c',\n",
      " 'hist_stats': {'episode_lengths': [10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10],\n",
      "                'episode_reward': [117.39775769181404,\n",
      "                                   78.1875843896656,\n",
      "                                   100.3389321113046,\n",
      "                                   111.38918930320388,\n",
      "                                   55.00630946712411,\n",
      "                                   66.09480208142227,\n",
      "                                   110.53680285803777,\n",
      "                                   107.74208324631546,\n",
      "                                   91.334119581761,\n",
      "                                   53.602065077547294,\n",
      "                                   140.5031722394544,\n",
      "                                   160.7840168396832,\n",
      "                                   99.16868849426322,\n",
      "                                   102.08715844990766,\n",
      "                                   111.07130383917546,\n",
      "                                   128.99086730530627,\n",
      "                                   137.47003128629854,\n",
      "                                   90.87821145842786,\n",
      "                                   95.50900785340434,\n",
      "                                   119.00141655551712,\n",
      "                                   84.82672012955597,\n",
      "                                   122.17268380919845,\n",
      "                                   97.25251448266752,\n",
      "                                   102.12635645400553,\n",
      "                                   92.50591782053482,\n",
      "                                   103.45758790418363,\n",
      "                                   107.82443157661255,\n",
      "                                   141.75962614067188,\n",
      "                                   131.05085355952485,\n",
      "                                   108.33029166220307,\n",
      "                                   76.91766923379662,\n",
      "                                   143.8101102077366,\n",
      "                                   134.53407288365787,\n",
      "                                   135.19527537939777,\n",
      "                                   45.187937576841456,\n",
      "                                   100.40943786784192,\n",
      "                                   65.1160782619414,\n",
      "                                   72.92212948447165,\n",
      "                                   87.24171779385317,\n",
      "                                   111.79345976441412,\n",
      "                                   64.62884689508148,\n",
      "                                   84.81705959020267,\n",
      "                                   97.08642152436036,\n",
      "                                   87.09476513106652,\n",
      "                                   99.46081059490785,\n",
      "                                   134.4975470957795,\n",
      "                                   121.32471822386651,\n",
      "                                   78.14227675504767,\n",
      "                                   97.82753923189416,\n",
      "                                   82.25779112882171,\n",
      "                                   80.44414073804342,\n",
      "                                   127.43344394449717,\n",
      "                                   73.03285957512016,\n",
      "                                   129.6356104560014,\n",
      "                                   115.02654535113953,\n",
      "                                   102.34460409077529,\n",
      "                                   120.59414644241046,\n",
      "                                   121.7203196086651,\n",
      "                                   106.64212917152058,\n",
      "                                   80.87166155813262,\n",
      "                                   123.6119274250055,\n",
      "                                   170.76252958631184,\n",
      "                                   100.65688725296093,\n",
      "                                   128.34933975759523,\n",
      "                                   73.10469464600003,\n",
      "                                   91.100482723935,\n",
      "                                   55.57779827663085,\n",
      "                                   135.15743535615655,\n",
      "                                   88.5881327367536,\n",
      "                                   109.02543966117146,\n",
      "                                   80.32889793198308,\n",
      "                                   69.40417677651097,\n",
      "                                   59.41982691706202,\n",
      "                                   66.01372425810975,\n",
      "                                   99.00223209222183,\n",
      "                                   76.93012812888256,\n",
      "                                   90.11051706806121,\n",
      "                                   61.93609692299524,\n",
      "                                   78.09671164885249,\n",
      "                                   96.2578914477889,\n",
      "                                   101.32799762833871,\n",
      "                                   111.37374950734522,\n",
      "                                   80.58641155309152,\n",
      "                                   93.15669437568617,\n",
      "                                   77.71352245367919,\n",
      "                                   95.80973732839509,\n",
      "                                   59.44444637224809,\n",
      "                                   98.66607602746717,\n",
      "                                   105.0537645851343,\n",
      "                                   75.09825512484939,\n",
      "                                   126.34248534510361,\n",
      "                                   123.99843556499768,\n",
      "                                   81.13095190954647,\n",
      "                                   131.58041636955113,\n",
      "                                   116.88313902319655,\n",
      "                                   118.33199166941614,\n",
      "                                   88.09479109803182,\n",
      "                                   62.77827149266231,\n",
      "                                   102.97785101222522,\n",
      "                                   90.17980430733627]},\n",
      " 'hostname': 'Kouroshs-MacBook-Pro-13',\n",
      " 'info': {'learner': {},\n",
      "          'num_agent_steps_sampled': 1000,\n",
      "          'num_agent_steps_trained': 0,\n",
      "          'num_env_steps_sampled': 1000,\n",
      "          'num_env_steps_trained': 0},\n",
      " 'iterations_since_restore': 1,\n",
      " 'node_ip': '127.0.0.1',\n",
      " 'num_agent_steps_sampled': 1000,\n",
      " 'num_agent_steps_trained': 0,\n",
      " 'num_env_steps_sampled': 1000,\n",
      " 'num_env_steps_sampled_this_iter': 1000,\n",
      " 'num_env_steps_trained': 0,\n",
      " 'num_env_steps_trained_this_iter': 0,\n",
      " 'num_faulty_episodes': 0,\n",
      " 'num_healthy_workers': 0,\n",
      " 'num_recreated_workers': 0,\n",
      " 'num_steps_trained_this_iter': 0,\n",
      " 'perf': {'cpu_util_percent': 34.1, 'ram_util_percent': 83.06666666666666},\n",
      " 'pid': 90513,\n",
      " 'policy_reward_max': {},\n",
      " 'policy_reward_mean': {},\n",
      " 'policy_reward_min': {},\n",
      " 'sampler_perf': {'mean_action_processing_ms': 0.025076823277430577,\n",
      "                  'mean_env_render_ms': 0.0,\n",
      "                  'mean_env_wait_ms': 0.18104401739922676,\n",
      "                  'mean_inference_ms': 0.6443715833879256,\n",
      "                  'mean_raw_obs_processing_ms': 0.8175234932761327},\n",
      " 'sampler_results': {'custom_metrics': {},\n",
      "                     'episode_len_mean': 10.0,\n",
      "                     'episode_media': {},\n",
      "                     'episode_reward_max': 170.76252958631184,\n",
      "                     'episode_reward_mean': 99.40375292593367,\n",
      "                     'episode_reward_min': 45.187937576841456,\n",
      "                     'episodes_this_iter': 100,\n",
      "                     'hist_stats': {'episode_lengths': [10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10],\n",
      "                                    'episode_reward': [117.39775769181404,\n",
      "                                                       78.1875843896656,\n",
      "                                                       100.3389321113046,\n",
      "                                                       111.38918930320388,\n",
      "                                                       55.00630946712411,\n",
      "                                                       66.09480208142227,\n",
      "                                                       110.53680285803777,\n",
      "                                                       107.74208324631546,\n",
      "                                                       91.334119581761,\n",
      "                                                       53.602065077547294,\n",
      "                                                       140.5031722394544,\n",
      "                                                       160.7840168396832,\n",
      "                                                       99.16868849426322,\n",
      "                                                       102.08715844990766,\n",
      "                                                       111.07130383917546,\n",
      "                                                       128.99086730530627,\n",
      "                                                       137.47003128629854,\n",
      "                                                       90.87821145842786,\n",
      "                                                       95.50900785340434,\n",
      "                                                       119.00141655551712,\n",
      "                                                       84.82672012955597,\n",
      "                                                       122.17268380919845,\n",
      "                                                       97.25251448266752,\n",
      "                                                       102.12635645400553,\n",
      "                                                       92.50591782053482,\n",
      "                                                       103.45758790418363,\n",
      "                                                       107.82443157661255,\n",
      "                                                       141.75962614067188,\n",
      "                                                       131.05085355952485,\n",
      "                                                       108.33029166220307,\n",
      "                                                       76.91766923379662,\n",
      "                                                       143.8101102077366,\n",
      "                                                       134.53407288365787,\n",
      "                                                       135.19527537939777,\n",
      "                                                       45.187937576841456,\n",
      "                                                       100.40943786784192,\n",
      "                                                       65.1160782619414,\n",
      "                                                       72.92212948447165,\n",
      "                                                       87.24171779385317,\n",
      "                                                       111.79345976441412,\n",
      "                                                       64.62884689508148,\n",
      "                                                       84.81705959020267,\n",
      "                                                       97.08642152436036,\n",
      "                                                       87.09476513106652,\n",
      "                                                       99.46081059490785,\n",
      "                                                       134.4975470957795,\n",
      "                                                       121.32471822386651,\n",
      "                                                       78.14227675504767,\n",
      "                                                       97.82753923189416,\n",
      "                                                       82.25779112882171,\n",
      "                                                       80.44414073804342,\n",
      "                                                       127.43344394449717,\n",
      "                                                       73.03285957512016,\n",
      "                                                       129.6356104560014,\n",
      "                                                       115.02654535113953,\n",
      "                                                       102.34460409077529,\n",
      "                                                       120.59414644241046,\n",
      "                                                       121.7203196086651,\n",
      "                                                       106.64212917152058,\n",
      "                                                       80.87166155813262,\n",
      "                                                       123.6119274250055,\n",
      "                                                       170.76252958631184,\n",
      "                                                       100.65688725296093,\n",
      "                                                       128.34933975759523,\n",
      "                                                       73.10469464600003,\n",
      "                                                       91.100482723935,\n",
      "                                                       55.57779827663085,\n",
      "                                                       135.15743535615655,\n",
      "                                                       88.5881327367536,\n",
      "                                                       109.02543966117146,\n",
      "                                                       80.32889793198308,\n",
      "                                                       69.40417677651097,\n",
      "                                                       59.41982691706202,\n",
      "                                                       66.01372425810975,\n",
      "                                                       99.00223209222183,\n",
      "                                                       76.93012812888256,\n",
      "                                                       90.11051706806121,\n",
      "                                                       61.93609692299524,\n",
      "                                                       78.09671164885249,\n",
      "                                                       96.2578914477889,\n",
      "                                                       101.32799762833871,\n",
      "                                                       111.37374950734522,\n",
      "                                                       80.58641155309152,\n",
      "                                                       93.15669437568617,\n",
      "                                                       77.71352245367919,\n",
      "                                                       95.80973732839509,\n",
      "                                                       59.44444637224809,\n",
      "                                                       98.66607602746717,\n",
      "                                                       105.0537645851343,\n",
      "                                                       75.09825512484939,\n",
      "                                                       126.34248534510361,\n",
      "                                                       123.99843556499768,\n",
      "                                                       81.13095190954647,\n",
      "                                                       131.58041636955113,\n",
      "                                                       116.88313902319655,\n",
      "                                                       118.33199166941614,\n",
      "                                                       88.09479109803182,\n",
      "                                                       62.77827149266231,\n",
      "                                                       102.97785101222522,\n",
      "                                                       90.17980430733627]},\n",
      "                     'num_faulty_episodes': 0,\n",
      "                     'policy_reward_max': {},\n",
      "                     'policy_reward_mean': {},\n",
      "                     'policy_reward_min': {},\n",
      "                     'sampler_perf': {'mean_action_processing_ms': 0.025076823277430577,\n",
      "                                      'mean_env_render_ms': 0.0,\n",
      "                                      'mean_env_wait_ms': 0.18104401739922676,\n",
      "                                      'mean_inference_ms': 0.6443715833879256,\n",
      "                                      'mean_raw_obs_processing_ms': 0.8175234932761327}},\n",
      " 'time_since_restore': 1.7798089981079102,\n",
      " 'time_this_iter_s': 1.7798089981079102,\n",
      " 'time_total_s': 1.7798089981079102,\n",
      " 'timers': {'training_iteration_time_ms': 6.749},\n",
      " 'timestamp': 1663190902,\n",
      " 'timesteps_since_restore': 0,\n",
      " 'timesteps_total': 1000,\n",
      " 'training_iteration': 1,\n",
      " 'trial_id': 'default',\n",
      " 'warmup_time': 3.2505459785461426}\n"
     ]
    }
   ],
   "source": [
    "# print the results\n",
    "print(results_bandit.keys())\n",
    "pprint(results_bandit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-09-14 14:28:38</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:11.55        </td></tr>\n",
       "<tr><td>Memory:      </td><td>13.4/16.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/8.35 GiB heap, 0.0/2.0 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  num_recreated_wor...</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_modified-lts_2bb2e_00000</td><td>TERMINATED</td><td>127.0.0.1:90669</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.69629</td><td style=\"text-align: right;\">1000</td><td style=\"text-align: right;\"> 96.7388</td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">              152.03</td><td style=\"text-align: right;\">              45.379</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   _ATTRVALUE_LISTVALUE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   import imp\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/keras/utils/image_utils.py:36: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   'nearest': pil_image.NEAREST,\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/keras/utils/image_utils.py:37: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   'bilinear': pil_image.BILINEAR,\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/keras/utils/image_utils.py:38: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   'bicubic': pil_image.BICUBIC,\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/keras/utils/image_utils.py:39: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   'hamming': pil_image.HAMMING,\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/keras/utils/image_utils.py:40: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   'box': pil_image.BOX,\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/keras/utils/image_utils.py:41: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   'lanczos': pil_image.LANCZOS,\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow_probability/python/__init__.py:61: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m WARNING:tensorflow:From /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:561: calling function (from tensorflow.python.eager.def_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=90669)\u001b[0m experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
      "\u001b[2m\u001b[36m(DQN pid=90669)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/gin/tf/__init__.py:48: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(DQN pid=90669)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(DQN pid=90669)\u001b[0m 2022-09-14 14:28:36,724\tWARNING deprecation.py:47 -- DeprecationWarning: `ray.rllib.algorithms.dqn.dqn.DEFAULT_CONFIG` has been deprecated. Use `ray.rllib.algorithms.dqn.dqn.DQNConfig(...)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=90669)\u001b[0m 2022-09-14 14:28:36,724\tWARNING deprecation.py:47 -- DeprecationWarning: `config['multiagent']['replay_mode']` has been deprecated. config['replay_buffer_config']['replay_mode'] This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=90669)\u001b[0m 2022-09-14 14:28:36,724\tINFO simple_q.py:303 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DQN pid=90669)\u001b[0m 2022-09-14 14:28:36,725\tINFO algorithm.py:357 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(DQN pid=90669)\u001b[0m /Users/kourosh/dev/workspace-project-gpu-workspace-kh/python/ray/_private/ray_option_utils.py:284: DeprecationWarning: Setting 'object_store_memory' for actors is deprecated since it doesn't actually reserve the required object store memory. Use object spilling that's enabled by default (https://docs.ray.io/en/master/ray-core/objects/object-spilling.html) instead to bypass the object store memory size limitation.\n",
      "\u001b[2m\u001b[36m(DQN pid=90669)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(DQN pid=90669)\u001b[0m 2022-09-14 14:28:36,732\tWARNING env.py:142 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(DQN pid=90669)\u001b[0m 2022-09-14 14:28:36,757\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(DQN pid=90669)\u001b[0m 2022-09-14 14:28:36,774\tWARNING deprecation.py:47 -- DeprecationWarning: `ReplayBuffer.add_batch()` has been deprecated. Use `ReplayBuffer.add()` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=90669)\u001b[0m 2022-09-14 14:28:36,783\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>counters                                                                                                                  </th><th>custom_metrics  </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th>experiment_id                   </th><th>hostname               </th><th>info                                                                                                                                     </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip  </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_recreated_workers</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                          </th><th style=\"text-align: right;\">  pid</th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                      </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                               </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_modified-lts_2bb2e_00000</td><td style=\"text-align: right;\">                   1000</td><td>{&#x27;num_env_steps_sampled&#x27;: 1000, &#x27;num_env_steps_trained&#x27;: 0, &#x27;num_agent_steps_sampled&#x27;: 1000, &#x27;num_agent_steps_trained&#x27;: 0}</td><td>{}              </td><td>2022-09-14_14-28-38</td><td>True  </td><td style=\"text-align: right;\">                10</td><td>{}             </td><td style=\"text-align: right;\">              152.03</td><td style=\"text-align: right;\">              96.7388</td><td style=\"text-align: right;\">              45.379</td><td style=\"text-align: right;\">                 100</td><td style=\"text-align: right;\">             100</td><td>174bda7af47142629b2977f1624ed06c</td><td>Kouroshs-MacBook-Pro-13</td><td>{&#x27;learner&#x27;: {}, &#x27;num_env_steps_sampled&#x27;: 1000, &#x27;num_env_steps_trained&#x27;: 0, &#x27;num_agent_steps_sampled&#x27;: 1000, &#x27;num_agent_steps_trained&#x27;: 0}</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">                     1000</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">                   1000</td><td style=\"text-align: right;\">                             1000</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                                0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                            0</td><td>{&#x27;cpu_util_percent&#x27;: 50.63333333333333, &#x27;ram_util_percent&#x27;: 85.03333333333333}</td><td style=\"text-align: right;\">90669</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 0.7908210887775557, &#x27;mean_inference_ms&#x27;: 0.5980845574256065, &#x27;mean_action_processing_ms&#x27;: 0.024415872671030136, &#x27;mean_env_wait_ms&#x27;: 0.17454073979304394, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: 152.03002576729233, &#x27;episode_reward_min&#x27;: 45.37902833105916, &#x27;episode_reward_mean&#x27;: 96.73882525187815, &#x27;episode_len_mean&#x27;: 10.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 100, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [81.65120315170935, 85.61111748854398, 74.91607118946838, 89.13575840300888, 118.44153029546179, 68.46171157615501, 138.8878925294037, 139.98624252513432, 99.84210469383447, 78.18170219974192, 119.22357623969086, 119.23501496426628, 103.35782520073897, 84.16204677714872, 124.57188953661164, 78.7262337964444, 94.80280273877582, 101.49500379970449, 119.56116164500345, 100.23268882345356, 85.84518625320551, 107.65155452319165, 86.20286727949647, 79.29420149657773, 80.63934239411708, 62.70102263208694, 126.37056199776143, 135.2898330498901, 86.01055522898926, 109.18641719921149, 49.664377641648365, 59.49641019209891, 93.87350406860712, 120.40432870227788, 64.15293361989188, 79.60786191085019, 45.37902833105916, 88.88649928026709, 110.4237880951139, 73.33259733949126, 72.31037629284477, 88.23328701799235, 83.40147349419574, 100.70244613835797, 98.27981098556565, 131.6634332871043, 84.88624812629632, 115.21733644553524, 102.45668267317892, 98.49495688767637, 93.84816333712787, 113.12495156869731, 90.0471951637453, 59.11444048872145, 131.7580232674312, 72.19769433953564, 98.76793886832753, 91.73519415924402, 86.31204820246637, 58.81801333356553, 99.54376210474155, 66.59114847604471, 152.03002576729233, 123.74885529492943, 150.05561993562975, 104.59430299022672, 108.50687492497326, 124.75715643205645, 93.60714457306184, 89.91867730002153, 91.15164407088334, 76.56784666156547, 73.1297935453082, 101.76185112135785, 96.84671490516743, 99.69043609547856, 59.02757532861926, 99.40415992370897, 92.88371086532257, 105.80908575260936, 98.10729565369628, 73.418522635607, 149.96676189208821, 96.37492868008667, 118.26876451849562, 113.8995952316956, 133.03740449307256, 92.58226746864283, 106.86573570668166, 114.67636347833455, 64.5723890429767, 86.07360132053066, 82.33717258766808, 127.15024452525064, 91.32056276208866, 127.83916986551807, 78.11864857223085, 108.52610511371525, 103.64882319078384, 61.20561949191084], &#x27;episode_lengths&#x27;: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 0.7908210887775557, &#x27;mean_inference_ms&#x27;: 0.5980845574256065, &#x27;mean_action_processing_ms&#x27;: 0.024415872671030136, &#x27;mean_env_wait_ms&#x27;: 0.17454073979304394, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}</td><td style=\"text-align: right;\">             1.69629</td><td style=\"text-align: right;\">           1.69629</td><td style=\"text-align: right;\">       1.69629</td><td>{&#x27;training_iteration_time_ms&#x27;: 6.597}</td><td style=\"text-align: right;\"> 1663190918</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">             1000</td><td style=\"text-align: right;\">                   1</td><td>2bb2e_00000</td><td style=\"text-align: right;\">     0.041014</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 14:28:38,979\tINFO tune.py:762 -- Total run time: 11.75 seconds (11.52 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "# Using tune.Tuner(param_space=..., run_config=air.RunConfig)\n",
    "# air.RunConfig(local_dir=..., stop=...)\n",
    "# TODO: Code here\n",
    "tuner = tune.Tuner(\n",
    "    DQN,\n",
    "    param_space=bandit_config.to_dict(),\n",
    "    run_config=air.RunConfig(\n",
    "        local_dir='./results_notebook/online_rl/bandits_dqn',\n",
    "        stop={\"training_iteration\": 1},\n",
    "    )\n",
    ")\n",
    "results_bandit = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ray.tune.result_grid.ResultGrid at 0x10a805be0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_bandit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_timesteps_total': 1000,\n",
      " 'config': {'_disable_action_flattening': False,\n",
      "            '_disable_execution_plan_api': True,\n",
      "            '_disable_preprocessor_api': False,\n",
      "            '_fake_gpus': False,\n",
      "            '_tf_policy_handles_more_than_one_loss': False,\n",
      "            'action_space': None,\n",
      "            'actions_in_input_normalized': False,\n",
      "            'adam_epsilon': 1e-08,\n",
      "            'always_attach_evaluation_results': False,\n",
      "            'batch_mode': 'truncate_episodes',\n",
      "            'before_learn_on_batch': None,\n",
      "            'buffer_size': -1,\n",
      "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
      "            'clip_actions': False,\n",
      "            'clip_rewards': None,\n",
      "            'collect_metrics_timeout': -1,\n",
      "            'compress_observations': False,\n",
      "            'create_env_on_driver': False,\n",
      "            'custom_eval_function': None,\n",
      "            'custom_resources_per_worker': {},\n",
      "            'disable_env_checking': False,\n",
      "            'double_q': True,\n",
      "            'dueling': True,\n",
      "            'eager_max_retraces': 20,\n",
      "            'eager_tracing': False,\n",
      "            'enable_async_evaluation': False,\n",
      "            'enable_connectors': False,\n",
      "            'enable_tf1_exec_eagerly': False,\n",
      "            'env': 'modified-lts',\n",
      "            'env_config': {'num_candidates': 20,\n",
      "                           'resample_documents': True,\n",
      "                           'reward_scale': 1.0,\n",
      "                           'seed': 100,\n",
      "                           'slate_size': 1},\n",
      "            'env_task_fn': None,\n",
      "            'evaluation_config': {'_disable_action_flattening': False,\n",
      "                                  '_disable_execution_plan_api': True,\n",
      "                                  '_disable_preprocessor_api': False,\n",
      "                                  '_fake_gpus': False,\n",
      "                                  '_tf_policy_handles_more_than_one_loss': False,\n",
      "                                  'action_space': None,\n",
      "                                  'actions_in_input_normalized': False,\n",
      "                                  'adam_epsilon': 1e-08,\n",
      "                                  'always_attach_evaluation_results': False,\n",
      "                                  'batch_mode': 'truncate_episodes',\n",
      "                                  'before_learn_on_batch': None,\n",
      "                                  'buffer_size': -1,\n",
      "                                  'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
      "                                  'clip_actions': False,\n",
      "                                  'clip_rewards': None,\n",
      "                                  'collect_metrics_timeout': -1,\n",
      "                                  'compress_observations': False,\n",
      "                                  'create_env_on_driver': False,\n",
      "                                  'custom_eval_function': None,\n",
      "                                  'custom_resources_per_worker': {},\n",
      "                                  'disable_env_checking': False,\n",
      "                                  'double_q': True,\n",
      "                                  'dueling': True,\n",
      "                                  'eager_max_retraces': 20,\n",
      "                                  'eager_tracing': False,\n",
      "                                  'enable_async_evaluation': False,\n",
      "                                  'enable_connectors': False,\n",
      "                                  'enable_tf1_exec_eagerly': False,\n",
      "                                  'env': 'modified-lts',\n",
      "                                  'env_config': {'num_candidates': 20,\n",
      "                                                 'resample_documents': True,\n",
      "                                                 'reward_scale': 1.0,\n",
      "                                                 'seed': 100,\n",
      "                                                 'slate_size': 1},\n",
      "                                  'env_task_fn': None,\n",
      "                                  'evaluation_config': {'explore': False},\n",
      "                                  'evaluation_duration': 10,\n",
      "                                  'evaluation_duration_unit': 'episodes',\n",
      "                                  'evaluation_interval': None,\n",
      "                                  'evaluation_num_episodes': -1,\n",
      "                                  'evaluation_num_workers': 0,\n",
      "                                  'evaluation_parallel_to_training': False,\n",
      "                                  'evaluation_sample_timeout_s': 180.0,\n",
      "                                  'exploration_config': {'epsilon_timesteps': 10000,\n",
      "                                                         'final_epsilon': 0.02,\n",
      "                                                         'initial_epsilon': 1.0,\n",
      "                                                         'type': 'EpsilonGreedy'},\n",
      "                                  'explore': False,\n",
      "                                  'extra_python_environs_for_driver': {},\n",
      "                                  'extra_python_environs_for_worker': {},\n",
      "                                  'fake_sampler': False,\n",
      "                                  'framework': 'torch',\n",
      "                                  'gamma': 0.0,\n",
      "                                  'grad_clip': 40,\n",
      "                                  'hiddens': [256],\n",
      "                                  'horizon': None,\n",
      "                                  'ignore_worker_failures': False,\n",
      "                                  'in_evaluation': False,\n",
      "                                  'input': 'sampler',\n",
      "                                  'input_config': {},\n",
      "                                  'input_evaluation': -1,\n",
      "                                  'keep_per_episode_custom_metrics': False,\n",
      "                                  'learning_starts': -1,\n",
      "                                  'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                                                            'intra_op_parallelism_threads': 8},\n",
      "                                  'log_level': 'WARN',\n",
      "                                  'log_sys_usage': True,\n",
      "                                  'logger_config': None,\n",
      "                                  'logger_creator': None,\n",
      "                                  'lr': 0.0005,\n",
      "                                  'lr_schedule': None,\n",
      "                                  'metrics_episode_collection_timeout_s': 60.0,\n",
      "                                  'metrics_num_episodes_for_smoothing': 100,\n",
      "                                  'metrics_smoothing_episodes': -1,\n",
      "                                  'min_iter_time_s': -1,\n",
      "                                  'min_sample_timesteps_per_iteration': 1000,\n",
      "                                  'min_sample_timesteps_per_reporting': -1,\n",
      "                                  'min_time_s_per_iteration': None,\n",
      "                                  'min_time_s_per_reporting': -1,\n",
      "                                  'min_train_timesteps_per_iteration': 0,\n",
      "                                  'min_train_timesteps_per_reporting': -1,\n",
      "                                  'model': {'_disable_action_flattening': False,\n",
      "                                            '_disable_preprocessor_api': False,\n",
      "                                            '_time_major': False,\n",
      "                                            '_use_default_native_models': False,\n",
      "                                            'attention_dim': 64,\n",
      "                                            'attention_head_dim': 32,\n",
      "                                            'attention_init_gru_gate_bias': 2.0,\n",
      "                                            'attention_memory_inference': 50,\n",
      "                                            'attention_memory_training': 50,\n",
      "                                            'attention_num_heads': 1,\n",
      "                                            'attention_num_transformer_units': 1,\n",
      "                                            'attention_position_wise_mlp_dim': 32,\n",
      "                                            'attention_use_n_prev_actions': 0,\n",
      "                                            'attention_use_n_prev_rewards': 0,\n",
      "                                            'conv_activation': 'relu',\n",
      "                                            'conv_filters': None,\n",
      "                                            'custom_action_dist': None,\n",
      "                                            'custom_model': None,\n",
      "                                            'custom_model_config': {},\n",
      "                                            'custom_preprocessor': None,\n",
      "                                            'dim': 84,\n",
      "                                            'fcnet_activation': 'tanh',\n",
      "                                            'fcnet_hiddens': [256, 256],\n",
      "                                            'framestack': True,\n",
      "                                            'free_log_std': False,\n",
      "                                            'grayscale': False,\n",
      "                                            'lstm_cell_size': 256,\n",
      "                                            'lstm_use_prev_action': False,\n",
      "                                            'lstm_use_prev_action_reward': -1,\n",
      "                                            'lstm_use_prev_reward': False,\n",
      "                                            'max_seq_len': 20,\n",
      "                                            'no_final_linear': False,\n",
      "                                            'post_fcnet_activation': 'relu',\n",
      "                                            'post_fcnet_hiddens': [],\n",
      "                                            'use_attention': False,\n",
      "                                            'use_lstm': False,\n",
      "                                            'vf_share_layers': True,\n",
      "                                            'zero_mean': True},\n",
      "                                  'monitor': -1,\n",
      "                                  'multiagent': {'count_steps_by': 'env_steps',\n",
      "                                                 'observation_fn': None,\n",
      "                                                 'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x10aa95fa0>},\n",
      "                                                 'policies_to_train': None,\n",
      "                                                 'policy_map_cache': None,\n",
      "                                                 'policy_map_capacity': 100,\n",
      "                                                 'policy_mapping_fn': None,\n",
      "                                                 'replay_mode': 'independent'},\n",
      "                                  'n_step': 1,\n",
      "                                  'no_done_at_end': False,\n",
      "                                  'noisy': False,\n",
      "                                  'normalize_actions': True,\n",
      "                                  'num_atoms': 1,\n",
      "                                  'num_consecutive_worker_failures_tolerance': 100,\n",
      "                                  'num_cpus_for_driver': 1,\n",
      "                                  'num_cpus_per_worker': 1,\n",
      "                                  'num_envs_per_worker': 1,\n",
      "                                  'num_gpus': 0,\n",
      "                                  'num_gpus_per_worker': 0,\n",
      "                                  'num_steps_sampled_before_learning_starts': 1000,\n",
      "                                  'num_workers': 0,\n",
      "                                  'observation_filter': 'NoFilter',\n",
      "                                  'observation_space': None,\n",
      "                                  'off_policy_estimation_methods': {},\n",
      "                                  'optimizer': {},\n",
      "                                  'output': None,\n",
      "                                  'output_compress_columns': ['obs', 'new_obs'],\n",
      "                                  'output_config': {},\n",
      "                                  'output_max_file_size': 67108864,\n",
      "                                  'placement_strategy': 'PACK',\n",
      "                                  'postprocess_inputs': False,\n",
      "                                  'preprocessor_pref': 'deepmind',\n",
      "                                  'prioritized_replay': -1,\n",
      "                                  'prioritized_replay_alpha': -1,\n",
      "                                  'prioritized_replay_beta': -1,\n",
      "                                  'prioritized_replay_eps': -1,\n",
      "                                  'recreate_failed_workers': False,\n",
      "                                  'remote_env_batch_wait_ms': 0,\n",
      "                                  'remote_worker_envs': False,\n",
      "                                  'render_env': False,\n",
      "                                  'replay_batch_size': -1,\n",
      "                                  'replay_buffer_config': {'capacity': 50000,\n",
      "                                                           'prioritized_replay': -1,\n",
      "                                                           'prioritized_replay_alpha': 0.6,\n",
      "                                                           'prioritized_replay_beta': 0.4,\n",
      "                                                           'prioritized_replay_eps': 1e-06,\n",
      "                                                           'replay_mode': 'independent',\n",
      "                                                           'replay_sequence_length': 1,\n",
      "                                                           'type': <class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>,\n",
      "                                                           'worker_side_prioritization': False},\n",
      "                                  'replay_sequence_length': None,\n",
      "                                  'restart_failed_sub_environments': False,\n",
      "                                  'rollout_fragment_length': 4,\n",
      "                                  'sample_async': False,\n",
      "                                  'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      "                                  'sampler_perf_stats_ema_coef': None,\n",
      "                                  'seed': None,\n",
      "                                  'shuffle_buffer_size': 0,\n",
      "                                  'sigma0': 0.5,\n",
      "                                  'simple_optimizer': False,\n",
      "                                  'soft_horizon': False,\n",
      "                                  'store_buffer_in_checkpoints': False,\n",
      "                                  'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
      "                                  'synchronize_filters': True,\n",
      "                                  'target_network_update_freq': 500,\n",
      "                                  'tf_session_args': {'allow_soft_placement': True,\n",
      "                                                      'device_count': {'CPU': 1},\n",
      "                                                      'gpu_options': {'allow_growth': True},\n",
      "                                                      'inter_op_parallelism_threads': 2,\n",
      "                                                      'intra_op_parallelism_threads': 2,\n",
      "                                                      'log_device_placement': False},\n",
      "                                  'timesteps_per_iteration': -1,\n",
      "                                  'train_batch_size': 32,\n",
      "                                  'training_intensity': None,\n",
      "                                  'v_max': 10.0,\n",
      "                                  'v_min': -10.0,\n",
      "                                  'validate_workers_after_construction': True},\n",
      "            'evaluation_duration': 10,\n",
      "            'evaluation_duration_unit': 'episodes',\n",
      "            'evaluation_interval': None,\n",
      "            'evaluation_num_episodes': -1,\n",
      "            'evaluation_num_workers': 0,\n",
      "            'evaluation_parallel_to_training': False,\n",
      "            'evaluation_sample_timeout_s': 180.0,\n",
      "            'exploration_config': {'epsilon_timesteps': 10000,\n",
      "                                   'final_epsilon': 0.02,\n",
      "                                   'initial_epsilon': 1.0,\n",
      "                                   'type': 'EpsilonGreedy'},\n",
      "            'explore': True,\n",
      "            'extra_python_environs_for_driver': {},\n",
      "            'extra_python_environs_for_worker': {},\n",
      "            'fake_sampler': False,\n",
      "            'framework': 'torch',\n",
      "            'gamma': 0.0,\n",
      "            'grad_clip': 40,\n",
      "            'hiddens': [256],\n",
      "            'horizon': None,\n",
      "            'ignore_worker_failures': False,\n",
      "            'in_evaluation': False,\n",
      "            'input': 'sampler',\n",
      "            'input_config': {},\n",
      "            'input_evaluation': -1,\n",
      "            'keep_per_episode_custom_metrics': False,\n",
      "            'learning_starts': -1,\n",
      "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                                      'intra_op_parallelism_threads': 8},\n",
      "            'log_level': 'WARN',\n",
      "            'log_sys_usage': True,\n",
      "            'logger_config': None,\n",
      "            'logger_creator': None,\n",
      "            'lr': 0.0005,\n",
      "            'lr_schedule': None,\n",
      "            'metrics_episode_collection_timeout_s': 60.0,\n",
      "            'metrics_num_episodes_for_smoothing': 100,\n",
      "            'metrics_smoothing_episodes': -1,\n",
      "            'min_iter_time_s': -1,\n",
      "            'min_sample_timesteps_per_iteration': 1000,\n",
      "            'min_sample_timesteps_per_reporting': -1,\n",
      "            'min_time_s_per_iteration': None,\n",
      "            'min_time_s_per_reporting': -1,\n",
      "            'min_train_timesteps_per_iteration': 0,\n",
      "            'min_train_timesteps_per_reporting': -1,\n",
      "            'model': {'_disable_action_flattening': False,\n",
      "                      '_disable_preprocessor_api': False,\n",
      "                      '_time_major': False,\n",
      "                      '_use_default_native_models': False,\n",
      "                      'attention_dim': 64,\n",
      "                      'attention_head_dim': 32,\n",
      "                      'attention_init_gru_gate_bias': 2.0,\n",
      "                      'attention_memory_inference': 50,\n",
      "                      'attention_memory_training': 50,\n",
      "                      'attention_num_heads': 1,\n",
      "                      'attention_num_transformer_units': 1,\n",
      "                      'attention_position_wise_mlp_dim': 32,\n",
      "                      'attention_use_n_prev_actions': 0,\n",
      "                      'attention_use_n_prev_rewards': 0,\n",
      "                      'conv_activation': 'relu',\n",
      "                      'conv_filters': None,\n",
      "                      'custom_action_dist': None,\n",
      "                      'custom_model': None,\n",
      "                      'custom_model_config': {},\n",
      "                      'custom_preprocessor': None,\n",
      "                      'dim': 84,\n",
      "                      'fcnet_activation': 'tanh',\n",
      "                      'fcnet_hiddens': [256, 256],\n",
      "                      'framestack': True,\n",
      "                      'free_log_std': False,\n",
      "                      'grayscale': False,\n",
      "                      'lstm_cell_size': 256,\n",
      "                      'lstm_use_prev_action': False,\n",
      "                      'lstm_use_prev_action_reward': -1,\n",
      "                      'lstm_use_prev_reward': False,\n",
      "                      'max_seq_len': 20,\n",
      "                      'no_final_linear': False,\n",
      "                      'post_fcnet_activation': 'relu',\n",
      "                      'post_fcnet_hiddens': [],\n",
      "                      'use_attention': False,\n",
      "                      'use_lstm': False,\n",
      "                      'vf_share_layers': True,\n",
      "                      'zero_mean': True},\n",
      "            'monitor': -1,\n",
      "            'multiagent': {'count_steps_by': 'env_steps',\n",
      "                           'observation_fn': None,\n",
      "                           'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x10aae37f0>},\n",
      "                           'policies_to_train': None,\n",
      "                           'policy_map_cache': None,\n",
      "                           'policy_map_capacity': 100,\n",
      "                           'policy_mapping_fn': None,\n",
      "                           'replay_mode': 'independent'},\n",
      "            'n_step': 1,\n",
      "            'no_done_at_end': False,\n",
      "            'noisy': False,\n",
      "            'normalize_actions': True,\n",
      "            'num_atoms': 1,\n",
      "            'num_consecutive_worker_failures_tolerance': 100,\n",
      "            'num_cpus_for_driver': 1,\n",
      "            'num_cpus_per_worker': 1,\n",
      "            'num_envs_per_worker': 1,\n",
      "            'num_gpus': 0,\n",
      "            'num_gpus_per_worker': 0,\n",
      "            'num_steps_sampled_before_learning_starts': 1000,\n",
      "            'num_workers': 0,\n",
      "            'observation_filter': 'NoFilter',\n",
      "            'observation_space': None,\n",
      "            'off_policy_estimation_methods': {},\n",
      "            'optimizer': {},\n",
      "            'output': None,\n",
      "            'output_compress_columns': ['obs', 'new_obs'],\n",
      "            'output_config': {},\n",
      "            'output_max_file_size': 67108864,\n",
      "            'placement_strategy': 'PACK',\n",
      "            'postprocess_inputs': False,\n",
      "            'preprocessor_pref': 'deepmind',\n",
      "            'prioritized_replay': -1,\n",
      "            'prioritized_replay_alpha': -1,\n",
      "            'prioritized_replay_beta': -1,\n",
      "            'prioritized_replay_eps': -1,\n",
      "            'recreate_failed_workers': False,\n",
      "            'remote_env_batch_wait_ms': 0,\n",
      "            'remote_worker_envs': False,\n",
      "            'render_env': False,\n",
      "            'replay_batch_size': -1,\n",
      "            'replay_buffer_config': {'capacity': 50000,\n",
      "                                     'prioritized_replay': -1,\n",
      "                                     'prioritized_replay_alpha': 0.6,\n",
      "                                     'prioritized_replay_beta': 0.4,\n",
      "                                     'prioritized_replay_eps': 1e-06,\n",
      "                                     'replay_mode': 'independent',\n",
      "                                     'replay_sequence_length': 1,\n",
      "                                     'type': <class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>,\n",
      "                                     'worker_side_prioritization': False},\n",
      "            'replay_sequence_length': None,\n",
      "            'restart_failed_sub_environments': False,\n",
      "            'rollout_fragment_length': 4,\n",
      "            'sample_async': False,\n",
      "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      "            'sampler_perf_stats_ema_coef': None,\n",
      "            'seed': None,\n",
      "            'shuffle_buffer_size': 0,\n",
      "            'sigma0': 0.5,\n",
      "            'simple_optimizer': False,\n",
      "            'soft_horizon': False,\n",
      "            'store_buffer_in_checkpoints': False,\n",
      "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
      "            'synchronize_filters': True,\n",
      "            'target_network_update_freq': 500,\n",
      "            'tf_session_args': {'allow_soft_placement': True,\n",
      "                                'device_count': {'CPU': 1},\n",
      "                                'gpu_options': {'allow_growth': True},\n",
      "                                'inter_op_parallelism_threads': 2,\n",
      "                                'intra_op_parallelism_threads': 2,\n",
      "                                'log_device_placement': False},\n",
      "            'timesteps_per_iteration': -1,\n",
      "            'train_batch_size': 32,\n",
      "            'training_intensity': None,\n",
      "            'v_max': 10.0,\n",
      "            'v_min': -10.0,\n",
      "            'validate_workers_after_construction': True},\n",
      " 'counters': {'num_agent_steps_sampled': 1000,\n",
      "              'num_agent_steps_trained': 0,\n",
      "              'num_env_steps_sampled': 1000,\n",
      "              'num_env_steps_trained': 0},\n",
      " 'custom_metrics': {},\n",
      " 'date': '2022-09-14_14-28-38',\n",
      " 'done': True,\n",
      " 'episode_len_mean': 10.0,\n",
      " 'episode_media': {},\n",
      " 'episode_reward_max': 152.03002576729233,\n",
      " 'episode_reward_mean': 96.73882525187815,\n",
      " 'episode_reward_min': 45.37902833105916,\n",
      " 'episodes_this_iter': 100,\n",
      " 'episodes_total': 100,\n",
      " 'experiment_id': '174bda7af47142629b2977f1624ed06c',\n",
      " 'experiment_tag': '0',\n",
      " 'hist_stats': {'episode_lengths': [10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10,\n",
      "                                    10],\n",
      "                'episode_reward': [81.65120315170935,\n",
      "                                   85.61111748854398,\n",
      "                                   74.91607118946838,\n",
      "                                   89.13575840300888,\n",
      "                                   118.44153029546179,\n",
      "                                   68.46171157615501,\n",
      "                                   138.8878925294037,\n",
      "                                   139.98624252513432,\n",
      "                                   99.84210469383447,\n",
      "                                   78.18170219974192,\n",
      "                                   119.22357623969086,\n",
      "                                   119.23501496426628,\n",
      "                                   103.35782520073897,\n",
      "                                   84.16204677714872,\n",
      "                                   124.57188953661164,\n",
      "                                   78.7262337964444,\n",
      "                                   94.80280273877582,\n",
      "                                   101.49500379970449,\n",
      "                                   119.56116164500345,\n",
      "                                   100.23268882345356,\n",
      "                                   85.84518625320551,\n",
      "                                   107.65155452319165,\n",
      "                                   86.20286727949647,\n",
      "                                   79.29420149657773,\n",
      "                                   80.63934239411708,\n",
      "                                   62.70102263208694,\n",
      "                                   126.37056199776143,\n",
      "                                   135.2898330498901,\n",
      "                                   86.01055522898926,\n",
      "                                   109.18641719921149,\n",
      "                                   49.664377641648365,\n",
      "                                   59.49641019209891,\n",
      "                                   93.87350406860712,\n",
      "                                   120.40432870227788,\n",
      "                                   64.15293361989188,\n",
      "                                   79.60786191085019,\n",
      "                                   45.37902833105916,\n",
      "                                   88.88649928026709,\n",
      "                                   110.4237880951139,\n",
      "                                   73.33259733949126,\n",
      "                                   72.31037629284477,\n",
      "                                   88.23328701799235,\n",
      "                                   83.40147349419574,\n",
      "                                   100.70244613835797,\n",
      "                                   98.27981098556565,\n",
      "                                   131.6634332871043,\n",
      "                                   84.88624812629632,\n",
      "                                   115.21733644553524,\n",
      "                                   102.45668267317892,\n",
      "                                   98.49495688767637,\n",
      "                                   93.84816333712787,\n",
      "                                   113.12495156869731,\n",
      "                                   90.0471951637453,\n",
      "                                   59.11444048872145,\n",
      "                                   131.7580232674312,\n",
      "                                   72.19769433953564,\n",
      "                                   98.76793886832753,\n",
      "                                   91.73519415924402,\n",
      "                                   86.31204820246637,\n",
      "                                   58.81801333356553,\n",
      "                                   99.54376210474155,\n",
      "                                   66.59114847604471,\n",
      "                                   152.03002576729233,\n",
      "                                   123.74885529492943,\n",
      "                                   150.05561993562975,\n",
      "                                   104.59430299022672,\n",
      "                                   108.50687492497326,\n",
      "                                   124.75715643205645,\n",
      "                                   93.60714457306184,\n",
      "                                   89.91867730002153,\n",
      "                                   91.15164407088334,\n",
      "                                   76.56784666156547,\n",
      "                                   73.1297935453082,\n",
      "                                   101.76185112135785,\n",
      "                                   96.84671490516743,\n",
      "                                   99.69043609547856,\n",
      "                                   59.02757532861926,\n",
      "                                   99.40415992370897,\n",
      "                                   92.88371086532257,\n",
      "                                   105.80908575260936,\n",
      "                                   98.10729565369628,\n",
      "                                   73.418522635607,\n",
      "                                   149.96676189208821,\n",
      "                                   96.37492868008667,\n",
      "                                   118.26876451849562,\n",
      "                                   113.8995952316956,\n",
      "                                   133.03740449307256,\n",
      "                                   92.58226746864283,\n",
      "                                   106.86573570668166,\n",
      "                                   114.67636347833455,\n",
      "                                   64.5723890429767,\n",
      "                                   86.07360132053066,\n",
      "                                   82.33717258766808,\n",
      "                                   127.15024452525064,\n",
      "                                   91.32056276208866,\n",
      "                                   127.83916986551807,\n",
      "                                   78.11864857223085,\n",
      "                                   108.52610511371525,\n",
      "                                   103.64882319078384,\n",
      "                                   61.20561949191084]},\n",
      " 'hostname': 'Kouroshs-MacBook-Pro-13',\n",
      " 'info': {'learner': {},\n",
      "          'num_agent_steps_sampled': 1000,\n",
      "          'num_agent_steps_trained': 0,\n",
      "          'num_env_steps_sampled': 1000,\n",
      "          'num_env_steps_trained': 0},\n",
      " 'iterations_since_restore': 1,\n",
      " 'node_ip': '127.0.0.1',\n",
      " 'num_agent_steps_sampled': 1000,\n",
      " 'num_agent_steps_trained': 0,\n",
      " 'num_env_steps_sampled': 1000,\n",
      " 'num_env_steps_sampled_this_iter': 1000,\n",
      " 'num_env_steps_trained': 0,\n",
      " 'num_env_steps_trained_this_iter': 0,\n",
      " 'num_faulty_episodes': 0,\n",
      " 'num_healthy_workers': 0,\n",
      " 'num_recreated_workers': 0,\n",
      " 'num_steps_trained_this_iter': 0,\n",
      " 'perf': {'cpu_util_percent': 50.63333333333333,\n",
      "          'ram_util_percent': 85.03333333333333},\n",
      " 'pid': 90669,\n",
      " 'policy_reward_max': {},\n",
      " 'policy_reward_mean': {},\n",
      " 'policy_reward_min': {},\n",
      " 'sampler_perf': {'mean_action_processing_ms': 0.024415872671030136,\n",
      "                  'mean_env_render_ms': 0.0,\n",
      "                  'mean_env_wait_ms': 0.17454073979304394,\n",
      "                  'mean_inference_ms': 0.5980845574256065,\n",
      "                  'mean_raw_obs_processing_ms': 0.7908210887775557},\n",
      " 'sampler_results': {'custom_metrics': {},\n",
      "                     'episode_len_mean': 10.0,\n",
      "                     'episode_media': {},\n",
      "                     'episode_reward_max': 152.03002576729233,\n",
      "                     'episode_reward_mean': 96.73882525187815,\n",
      "                     'episode_reward_min': 45.37902833105916,\n",
      "                     'episodes_this_iter': 100,\n",
      "                     'hist_stats': {'episode_lengths': [10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10,\n",
      "                                                        10],\n",
      "                                    'episode_reward': [81.65120315170935,\n",
      "                                                       85.61111748854398,\n",
      "                                                       74.91607118946838,\n",
      "                                                       89.13575840300888,\n",
      "                                                       118.44153029546179,\n",
      "                                                       68.46171157615501,\n",
      "                                                       138.8878925294037,\n",
      "                                                       139.98624252513432,\n",
      "                                                       99.84210469383447,\n",
      "                                                       78.18170219974192,\n",
      "                                                       119.22357623969086,\n",
      "                                                       119.23501496426628,\n",
      "                                                       103.35782520073897,\n",
      "                                                       84.16204677714872,\n",
      "                                                       124.57188953661164,\n",
      "                                                       78.7262337964444,\n",
      "                                                       94.80280273877582,\n",
      "                                                       101.49500379970449,\n",
      "                                                       119.56116164500345,\n",
      "                                                       100.23268882345356,\n",
      "                                                       85.84518625320551,\n",
      "                                                       107.65155452319165,\n",
      "                                                       86.20286727949647,\n",
      "                                                       79.29420149657773,\n",
      "                                                       80.63934239411708,\n",
      "                                                       62.70102263208694,\n",
      "                                                       126.37056199776143,\n",
      "                                                       135.2898330498901,\n",
      "                                                       86.01055522898926,\n",
      "                                                       109.18641719921149,\n",
      "                                                       49.664377641648365,\n",
      "                                                       59.49641019209891,\n",
      "                                                       93.87350406860712,\n",
      "                                                       120.40432870227788,\n",
      "                                                       64.15293361989188,\n",
      "                                                       79.60786191085019,\n",
      "                                                       45.37902833105916,\n",
      "                                                       88.88649928026709,\n",
      "                                                       110.4237880951139,\n",
      "                                                       73.33259733949126,\n",
      "                                                       72.31037629284477,\n",
      "                                                       88.23328701799235,\n",
      "                                                       83.40147349419574,\n",
      "                                                       100.70244613835797,\n",
      "                                                       98.27981098556565,\n",
      "                                                       131.6634332871043,\n",
      "                                                       84.88624812629632,\n",
      "                                                       115.21733644553524,\n",
      "                                                       102.45668267317892,\n",
      "                                                       98.49495688767637,\n",
      "                                                       93.84816333712787,\n",
      "                                                       113.12495156869731,\n",
      "                                                       90.0471951637453,\n",
      "                                                       59.11444048872145,\n",
      "                                                       131.7580232674312,\n",
      "                                                       72.19769433953564,\n",
      "                                                       98.76793886832753,\n",
      "                                                       91.73519415924402,\n",
      "                                                       86.31204820246637,\n",
      "                                                       58.81801333356553,\n",
      "                                                       99.54376210474155,\n",
      "                                                       66.59114847604471,\n",
      "                                                       152.03002576729233,\n",
      "                                                       123.74885529492943,\n",
      "                                                       150.05561993562975,\n",
      "                                                       104.59430299022672,\n",
      "                                                       108.50687492497326,\n",
      "                                                       124.75715643205645,\n",
      "                                                       93.60714457306184,\n",
      "                                                       89.91867730002153,\n",
      "                                                       91.15164407088334,\n",
      "                                                       76.56784666156547,\n",
      "                                                       73.1297935453082,\n",
      "                                                       101.76185112135785,\n",
      "                                                       96.84671490516743,\n",
      "                                                       99.69043609547856,\n",
      "                                                       59.02757532861926,\n",
      "                                                       99.40415992370897,\n",
      "                                                       92.88371086532257,\n",
      "                                                       105.80908575260936,\n",
      "                                                       98.10729565369628,\n",
      "                                                       73.418522635607,\n",
      "                                                       149.96676189208821,\n",
      "                                                       96.37492868008667,\n",
      "                                                       118.26876451849562,\n",
      "                                                       113.8995952316956,\n",
      "                                                       133.03740449307256,\n",
      "                                                       92.58226746864283,\n",
      "                                                       106.86573570668166,\n",
      "                                                       114.67636347833455,\n",
      "                                                       64.5723890429767,\n",
      "                                                       86.07360132053066,\n",
      "                                                       82.33717258766808,\n",
      "                                                       127.15024452525064,\n",
      "                                                       91.32056276208866,\n",
      "                                                       127.83916986551807,\n",
      "                                                       78.11864857223085,\n",
      "                                                       108.52610511371525,\n",
      "                                                       103.64882319078384,\n",
      "                                                       61.20561949191084]},\n",
      "                     'num_faulty_episodes': 0,\n",
      "                     'policy_reward_max': {},\n",
      "                     'policy_reward_mean': {},\n",
      "                     'policy_reward_min': {},\n",
      "                     'sampler_perf': {'mean_action_processing_ms': 0.024415872671030136,\n",
      "                                      'mean_env_render_ms': 0.0,\n",
      "                                      'mean_env_wait_ms': 0.17454073979304394,\n",
      "                                      'mean_inference_ms': 0.5980845574256065,\n",
      "                                      'mean_raw_obs_processing_ms': 0.7908210887775557}},\n",
      " 'time_since_restore': 1.6962919235229492,\n",
      " 'time_this_iter_s': 1.6962919235229492,\n",
      " 'time_total_s': 1.6962919235229492,\n",
      " 'timers': {'training_iteration_time_ms': 6.597},\n",
      " 'timestamp': 1663190918,\n",
      " 'timesteps_since_restore': 0,\n",
      " 'timesteps_total': 1000,\n",
      " 'training_iteration': 1,\n",
      " 'trial_id': '2bb2e_00000',\n",
      " 'warmup_time': 0.04101395606994629}\n"
     ]
    }
   ],
   "source": [
    "pprint(results_bandit[0].metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune collects these results from every iteration and puts them in the output directory where the other logging artifcats are stored. \n",
    "\n",
    "To run this experiment longer until it's trained you can run the following command to launch the bandit experiment:\n",
    "\n",
    "\n",
    "```bash\n",
    "python tutorial_scripts/run_online_rl.py --seed 0 --gamma 0.0 --exp_name bandits --timesteps 10_000\n",
    "```\n",
    "\n",
    "This script take 5 minutes to run. It will create experiment artifacts under `./results_scripts/` which includes the checkpoints as well as tensorboard and tabular logs. You can later inspect this folder to monitor your experiments.\n",
    "\n",
    "The suggested way is to use tensorboard to monitor the metrics of your run and look for `episode_reward_mean`.\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir \"./results_scripts\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_recreated_workers</th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_faulty_episodes</th>\n",
       "      <th>num_healthy_workers</th>\n",
       "      <th>num_agent_steps_sampled</th>\n",
       "      <th>num_agent_steps_trained</th>\n",
       "      <th>...</th>\n",
       "      <th>evaluation/sampler_perf/mean_action_processing_ms</th>\n",
       "      <th>evaluation/sampler_perf/mean_env_wait_ms</th>\n",
       "      <th>evaluation/sampler_perf/mean_env_render_ms</th>\n",
       "      <th>sampler_results/hist_stats/episode_reward</th>\n",
       "      <th>sampler_results/hist_stats/episode_lengths</th>\n",
       "      <th>sampler_results/sampler_perf/mean_raw_obs_processing_ms</th>\n",
       "      <th>sampler_results/sampler_perf/mean_inference_ms</th>\n",
       "      <th>sampler_results/sampler_perf/mean_action_processing_ms</th>\n",
       "      <th>sampler_results/sampler_perf/mean_env_wait_ms</th>\n",
       "      <th>sampler_results/sampler_perf/mean_env_render_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>148.857003</td>\n",
       "      <td>49.961654</td>\n",
       "      <td>98.497645</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>0.421863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[80.06783496345842, 94.55144237747402, 115.734...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...</td>\n",
       "      <td>1.615976</td>\n",
       "      <td>1.926621</td>\n",
       "      <td>0.067211</td>\n",
       "      <td>0.413892</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>162.518395</td>\n",
       "      <td>49.026263</td>\n",
       "      <td>90.052531</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>102400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063795</td>\n",
       "      <td>0.414642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[104.50434231044349, 90.13660176239118, 77.679...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...</td>\n",
       "      <td>1.612668</td>\n",
       "      <td>1.907204</td>\n",
       "      <td>0.065739</td>\n",
       "      <td>0.413190</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>138.941288</td>\n",
       "      <td>47.053765</td>\n",
       "      <td>91.065332</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>204800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064125</td>\n",
       "      <td>0.418105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[80.37757864952177, 83.4086883528945, 82.16280...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...</td>\n",
       "      <td>1.622994</td>\n",
       "      <td>1.902245</td>\n",
       "      <td>0.065344</td>\n",
       "      <td>0.414438</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>140.064561</td>\n",
       "      <td>48.773252</td>\n",
       "      <td>84.834952</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>307200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064455</td>\n",
       "      <td>0.420479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[74.22016887537853, 76.9675069259837, 62.41210...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...</td>\n",
       "      <td>1.631680</td>\n",
       "      <td>1.913093</td>\n",
       "      <td>0.065588</td>\n",
       "      <td>0.417682</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.836997</td>\n",
       "      <td>45.018080</td>\n",
       "      <td>80.444693</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>409600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064498</td>\n",
       "      <td>0.420735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[73.06394030113951, 115.4952494291228, 93.7637...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...</td>\n",
       "      <td>1.638053</td>\n",
       "      <td>1.916961</td>\n",
       "      <td>0.065503</td>\n",
       "      <td>0.419723</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>0</td>\n",
       "      <td>77.308824</td>\n",
       "      <td>51.473253</td>\n",
       "      <td>57.409480</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>662000</td>\n",
       "      <td>67686400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069512</td>\n",
       "      <td>0.468326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[56.363397408474796, 56.472586083925, 55.73214...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...</td>\n",
       "      <td>1.829190</td>\n",
       "      <td>2.020992</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.455474</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>0</td>\n",
       "      <td>81.922776</td>\n",
       "      <td>51.625754</td>\n",
       "      <td>57.390007</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>663000</td>\n",
       "      <td>67788800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069526</td>\n",
       "      <td>0.468445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[58.08399044030793, 51.62575353461019, 55.3362...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...</td>\n",
       "      <td>1.829310</td>\n",
       "      <td>2.021095</td>\n",
       "      <td>0.067001</td>\n",
       "      <td>0.455496</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>0</td>\n",
       "      <td>80.536429</td>\n",
       "      <td>52.074962</td>\n",
       "      <td>57.349532</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>664000</td>\n",
       "      <td>67891200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069528</td>\n",
       "      <td>0.468463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[57.05626052342183, 57.895075154772854, 55.034...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...</td>\n",
       "      <td>1.829335</td>\n",
       "      <td>2.021136</td>\n",
       "      <td>0.067002</td>\n",
       "      <td>0.455504</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>0</td>\n",
       "      <td>80.235838</td>\n",
       "      <td>51.864473</td>\n",
       "      <td>57.193991</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>665000</td>\n",
       "      <td>67993600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069530</td>\n",
       "      <td>0.468486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[56.17971936322728, 57.32259647211729, 63.9087...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...</td>\n",
       "      <td>1.829405</td>\n",
       "      <td>2.021226</td>\n",
       "      <td>0.067003</td>\n",
       "      <td>0.455530</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>0</td>\n",
       "      <td>80.427360</td>\n",
       "      <td>49.259737</td>\n",
       "      <td>56.954195</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>666000</td>\n",
       "      <td>68096000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069537</td>\n",
       "      <td>0.468537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[58.24048331821, 56.8272174196875, 57.13431301...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...</td>\n",
       "      <td>1.829395</td>\n",
       "      <td>2.021243</td>\n",
       "      <td>0.067003</td>\n",
       "      <td>0.455528</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>666 rows Ã 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_recreated_workers  episode_reward_max  episode_reward_min  \\\n",
       "0                        0          148.857003           49.961654   \n",
       "1                        0          162.518395           49.026263   \n",
       "2                        0          138.941288           47.053765   \n",
       "3                        0          140.064561           48.773252   \n",
       "4                        0          137.836997           45.018080   \n",
       "..                     ...                 ...                 ...   \n",
       "661                      0           77.308824           51.473253   \n",
       "662                      0           81.922776           51.625754   \n",
       "663                      0           80.536429           52.074962   \n",
       "664                      0           80.235838           51.864473   \n",
       "665                      0           80.427360           49.259737   \n",
       "\n",
       "     episode_reward_mean  episode_len_mean  episodes_this_iter  \\\n",
       "0              98.497645              10.0                 100   \n",
       "1              90.052531              10.0                 100   \n",
       "2              91.065332              10.0                 100   \n",
       "3              84.834952              10.0                 100   \n",
       "4              80.444693              10.0                 100   \n",
       "..                   ...               ...                 ...   \n",
       "661            57.409480              10.0                 100   \n",
       "662            57.390007              10.0                 100   \n",
       "663            57.349532              10.0                 100   \n",
       "664            57.193991              10.0                 100   \n",
       "665            56.954195              10.0                 100   \n",
       "\n",
       "     num_faulty_episodes  num_healthy_workers  num_agent_steps_sampled  \\\n",
       "0                      0                    1                     1000   \n",
       "1                      0                    1                     2000   \n",
       "2                      0                    1                     3000   \n",
       "3                      0                    1                     4000   \n",
       "4                      0                    1                     5000   \n",
       "..                   ...                  ...                      ...   \n",
       "661                    0                    1                   662000   \n",
       "662                    0                    1                   663000   \n",
       "663                    0                    1                   664000   \n",
       "664                    0                    1                   665000   \n",
       "665                    0                    1                   666000   \n",
       "\n",
       "     num_agent_steps_trained  ...  \\\n",
       "0                          0  ...   \n",
       "1                     102400  ...   \n",
       "2                     204800  ...   \n",
       "3                     307200  ...   \n",
       "4                     409600  ...   \n",
       "..                       ...  ...   \n",
       "661                 67686400  ...   \n",
       "662                 67788800  ...   \n",
       "663                 67891200  ...   \n",
       "664                 67993600  ...   \n",
       "665                 68096000  ...   \n",
       "\n",
       "     evaluation/sampler_perf/mean_action_processing_ms  \\\n",
       "0                                             0.066004   \n",
       "1                                             0.063795   \n",
       "2                                             0.064125   \n",
       "3                                             0.064455   \n",
       "4                                             0.064498   \n",
       "..                                                 ...   \n",
       "661                                           0.069512   \n",
       "662                                           0.069526   \n",
       "663                                           0.069528   \n",
       "664                                           0.069530   \n",
       "665                                           0.069537   \n",
       "\n",
       "     evaluation/sampler_perf/mean_env_wait_ms  \\\n",
       "0                                    0.421863   \n",
       "1                                    0.414642   \n",
       "2                                    0.418105   \n",
       "3                                    0.420479   \n",
       "4                                    0.420735   \n",
       "..                                        ...   \n",
       "661                                  0.468326   \n",
       "662                                  0.468445   \n",
       "663                                  0.468463   \n",
       "664                                  0.468486   \n",
       "665                                  0.468537   \n",
       "\n",
       "     evaluation/sampler_perf/mean_env_render_ms  \\\n",
       "0                                           0.0   \n",
       "1                                           0.0   \n",
       "2                                           0.0   \n",
       "3                                           0.0   \n",
       "4                                           0.0   \n",
       "..                                          ...   \n",
       "661                                         0.0   \n",
       "662                                         0.0   \n",
       "663                                         0.0   \n",
       "664                                         0.0   \n",
       "665                                         0.0   \n",
       "\n",
       "             sampler_results/hist_stats/episode_reward  \\\n",
       "0    [80.06783496345842, 94.55144237747402, 115.734...   \n",
       "1    [104.50434231044349, 90.13660176239118, 77.679...   \n",
       "2    [80.37757864952177, 83.4086883528945, 82.16280...   \n",
       "3    [74.22016887537853, 76.9675069259837, 62.41210...   \n",
       "4    [73.06394030113951, 115.4952494291228, 93.7637...   \n",
       "..                                                 ...   \n",
       "661  [56.363397408474796, 56.472586083925, 55.73214...   \n",
       "662  [58.08399044030793, 51.62575353461019, 55.3362...   \n",
       "663  [57.05626052342183, 57.895075154772854, 55.034...   \n",
       "664  [56.17971936322728, 57.32259647211729, 63.9087...   \n",
       "665  [58.24048331821, 56.8272174196875, 57.13431301...   \n",
       "\n",
       "            sampler_results/hist_stats/episode_lengths  \\\n",
       "0    [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...   \n",
       "1    [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...   \n",
       "2    [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...   \n",
       "3    [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...   \n",
       "4    [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...   \n",
       "..                                                 ...   \n",
       "661  [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...   \n",
       "662  [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...   \n",
       "663  [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...   \n",
       "664  [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...   \n",
       "665  [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...   \n",
       "\n",
       "     sampler_results/sampler_perf/mean_raw_obs_processing_ms  \\\n",
       "0                                             1.615976         \n",
       "1                                             1.612668         \n",
       "2                                             1.622994         \n",
       "3                                             1.631680         \n",
       "4                                             1.638053         \n",
       "..                                                 ...         \n",
       "661                                           1.829190         \n",
       "662                                           1.829310         \n",
       "663                                           1.829335         \n",
       "664                                           1.829405         \n",
       "665                                           1.829395         \n",
       "\n",
       "     sampler_results/sampler_perf/mean_inference_ms  \\\n",
       "0                                          1.926621   \n",
       "1                                          1.907204   \n",
       "2                                          1.902245   \n",
       "3                                          1.913093   \n",
       "4                                          1.916961   \n",
       "..                                              ...   \n",
       "661                                        2.020992   \n",
       "662                                        2.021095   \n",
       "663                                        2.021136   \n",
       "664                                        2.021226   \n",
       "665                                        2.021243   \n",
       "\n",
       "     sampler_results/sampler_perf/mean_action_processing_ms  \\\n",
       "0                                             0.067211        \n",
       "1                                             0.065739        \n",
       "2                                             0.065344        \n",
       "3                                             0.065588        \n",
       "4                                             0.065503        \n",
       "..                                                 ...        \n",
       "661                                           0.067000        \n",
       "662                                           0.067001        \n",
       "663                                           0.067002        \n",
       "664                                           0.067003        \n",
       "665                                           0.067003        \n",
       "\n",
       "     sampler_results/sampler_perf/mean_env_wait_ms  \\\n",
       "0                                         0.413892   \n",
       "1                                         0.413190   \n",
       "2                                         0.414438   \n",
       "3                                         0.417682   \n",
       "4                                         0.419723   \n",
       "..                                             ...   \n",
       "661                                       0.455474   \n",
       "662                                       0.455496   \n",
       "663                                       0.455504   \n",
       "664                                       0.455530   \n",
       "665                                       0.455528   \n",
       "\n",
       "     sampler_results/sampler_perf/mean_env_render_ms  \n",
       "0                                                0.0  \n",
       "1                                                0.0  \n",
       "2                                                0.0  \n",
       "3                                                0.0  \n",
       "4                                                0.0  \n",
       "..                                               ...  \n",
       "661                                              0.0  \n",
       "662                                              0.0  \n",
       "663                                              0.0  \n",
       "664                                              0.0  \n",
       "665                                              0.0  \n",
       "\n",
       "[666 rows x 82 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the trained results and plot the metrics in notebook\n",
    "import pandas as pd\n",
    "\n",
    "# Load the results from the progress.csv in the result folder of your running script\n",
    "df = pd.read_csv(\"saved_runs/bandits/progress.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Bandits training performance')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data=df, x=\"training_iteration\", y=\"episode_reward_mean\", label=\"bandits\")\n",
    "plt.axhline(sweetest_baseline, color=\"red\", linestyle='--', label=\"sweetest baseline\")\n",
    "plt.axhline(random_baseline, color=\"k\", linestyle='--', label=\"random baseline\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Bandits training performance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the Bandit Training results to Baseline\n",
    "- Bandit Mean Reward=~56 \n",
    "- Kaleist (Argmin) Baseline Mean Reward = ~10.87+/-0.26\n",
    "- Random Baseline Mean Reward = ~99.90+/-23.75\n",
    "- Sweetest (Argmax) Baseline Mean Reward = ~56.56+/-1.37\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    ð¤  <b>Bandit mean reward is approx the same as the sweetest baseline!</b> \n",
    "</div>  \n",
    "\n",
    "Try the code block below to compare what the bandit recommends with what is the sweetest item... you will see that the bandit always recommends the sweetest item!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_disable_action_flattening': False,\n",
      " '_disable_execution_plan_api': True,\n",
      " '_disable_preprocessor_api': False,\n",
      " '_fake_gpus': False,\n",
      " '_tf_policy_handles_more_than_one_loss': False,\n",
      " 'action_space': None,\n",
      " 'actions_in_input_normalized': False,\n",
      " 'adam_epsilon': 1e-08,\n",
      " 'always_attach_evaluation_results': False,\n",
      " 'batch_mode': 'complete_episodes',\n",
      " 'before_learn_on_batch': None,\n",
      " 'buffer_size': -1,\n",
      " 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
      " 'clip_actions': False,\n",
      " 'clip_rewards': None,\n",
      " 'collect_metrics_timeout': -1,\n",
      " 'compress_observations': False,\n",
      " 'create_env_on_driver': True,\n",
      " 'custom_eval_function': None,\n",
      " 'custom_resources_per_worker': {},\n",
      " 'disable_env_checking': False,\n",
      " 'double_q': True,\n",
      " 'dueling': False,\n",
      " 'eager_max_retraces': 20,\n",
      " 'eager_tracing': False,\n",
      " 'enable_async_evaluation': False,\n",
      " 'enable_connectors': False,\n",
      " 'enable_tf1_exec_eagerly': False,\n",
      " 'env': 'modified-lts',\n",
      " 'env_config': {'num_candidates': 20,\n",
      "                'resample_documents': True,\n",
      "                'reward_scale': 1.0,\n",
      "                'seed': 0,\n",
      "                'slate_size': 1},\n",
      " 'env_task_fn': None,\n",
      " 'evaluation_config': {'explore': False},\n",
      " 'evaluation_duration': 100,\n",
      " 'evaluation_duration_unit': 'episodes',\n",
      " 'evaluation_interval': 1,\n",
      " 'evaluation_num_episodes': -1,\n",
      " 'evaluation_num_workers': 0,\n",
      " 'evaluation_parallel_to_training': True,\n",
      " 'evaluation_sample_timeout_s': 180.0,\n",
      " 'exploration_config': {'epsilon_timesteps': 10000,\n",
      "                        'final_epsilon': 0.02,\n",
      "                        'initial_epsilon': 1.0,\n",
      "                        'type': 'EpsilonGreedy'},\n",
      " 'explore': True,\n",
      " 'extra_python_environs_for_driver': {},\n",
      " 'extra_python_environs_for_worker': {},\n",
      " 'fake_sampler': False,\n",
      " 'framework': 'torch',\n",
      " 'gamma': 0.0,\n",
      " 'grad_clip': 40,\n",
      " 'hiddens': [256],\n",
      " 'horizon': None,\n",
      " 'ignore_worker_failures': False,\n",
      " 'in_evaluation': False,\n",
      " 'input': 'sampler',\n",
      " 'input_config': {},\n",
      " 'input_evaluation': -1,\n",
      " 'keep_per_episode_custom_metrics': False,\n",
      " 'learning_starts': -1,\n",
      " 'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                           'intra_op_parallelism_threads': 8},\n",
      " 'log_level': 'ERROR',\n",
      " 'log_sys_usage': True,\n",
      " 'logger_config': None,\n",
      " 'logger_creator': None,\n",
      " 'lr': 0.0003,\n",
      " 'lr_schedule': None,\n",
      " 'metrics_episode_collection_timeout_s': 60.0,\n",
      " 'metrics_num_episodes_for_smoothing': 100,\n",
      " 'metrics_smoothing_episodes': -1,\n",
      " 'min_iter_time_s': -1,\n",
      " 'min_sample_timesteps_per_iteration': 1000,\n",
      " 'min_sample_timesteps_per_reporting': -1,\n",
      " 'min_time_s_per_iteration': None,\n",
      " 'min_time_s_per_reporting': -1,\n",
      " 'min_train_timesteps_per_iteration': 0,\n",
      " 'min_train_timesteps_per_reporting': -1,\n",
      " 'model': {'fcnet_activation': 'relu', 'fcnet_hiddens': [1024, 1024, 1024]},\n",
      " 'monitor': -1,\n",
      " 'multiagent': {'count_steps_by': 'env_steps',\n",
      "                'observation_fn': None,\n",
      "                'policies': {},\n",
      "                'policies_to_train': None,\n",
      "                'policy_map_cache': None,\n",
      "                'policy_map_capacity': 100,\n",
      "                'policy_mapping_fn': None,\n",
      "                'replay_mode': 'independent'},\n",
      " 'n_step': 1,\n",
      " 'no_done_at_end': False,\n",
      " 'noisy': False,\n",
      " 'normalize_actions': True,\n",
      " 'num_atoms': 1,\n",
      " 'num_consecutive_worker_failures_tolerance': 100,\n",
      " 'num_cpus_for_driver': 1,\n",
      " 'num_cpus_per_worker': 1,\n",
      " 'num_envs_per_worker': 1,\n",
      " 'num_gpus': 0,\n",
      " 'num_gpus_per_worker': 0,\n",
      " 'num_steps_sampled_before_learning_starts': 1000,\n",
      " 'num_workers': 1,\n",
      " 'observation_filter': 'NoFilter',\n",
      " 'observation_space': None,\n",
      " 'off_policy_estimation_methods': {},\n",
      " 'optimizer': {},\n",
      " 'output': None,\n",
      " 'output_compress_columns': ['obs', 'new_obs'],\n",
      " 'output_config': {},\n",
      " 'output_max_file_size': 67108864,\n",
      " 'placement_strategy': 'PACK',\n",
      " 'postprocess_inputs': False,\n",
      " 'preprocessor_pref': 'deepmind',\n",
      " 'prioritized_replay': -1,\n",
      " 'prioritized_replay_alpha': -1,\n",
      " 'prioritized_replay_beta': -1,\n",
      " 'prioritized_replay_eps': -1,\n",
      " 'recreate_failed_workers': False,\n",
      " 'remote_env_batch_wait_ms': 0,\n",
      " 'remote_worker_envs': False,\n",
      " 'render_env': False,\n",
      " 'replay_batch_size': -1,\n",
      " 'replay_buffer_config': {'capacity': 50000,\n",
      "                          'prioritized_replay': -1,\n",
      "                          'prioritized_replay_alpha': 0.6,\n",
      "                          'prioritized_replay_beta': 0.4,\n",
      "                          'prioritized_replay_eps': 1e-06,\n",
      "                          'replay_sequence_length': 1,\n",
      "                          'type': 'MultiAgentPrioritizedReplayBuffer',\n",
      "                          'worker_side_prioritization': False},\n",
      " 'replay_sequence_length': None,\n",
      " 'restart_failed_sub_environments': False,\n",
      " 'rollout_fragment_length': 4,\n",
      " 'sample_async': False,\n",
      " 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      " 'sampler_perf_stats_ema_coef': None,\n",
      " 'seed': 0,\n",
      " 'shuffle_buffer_size': 0,\n",
      " 'sigma0': 0.5,\n",
      " 'simple_optimizer': -1,\n",
      " 'soft_horizon': False,\n",
      " 'store_buffer_in_checkpoints': False,\n",
      " 'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
      " 'synchronize_filters': True,\n",
      " 'target_network_update_freq': 1024,\n",
      " 'tf_session_args': {'allow_soft_placement': True,\n",
      "                     'device_count': {'CPU': 1},\n",
      "                     'gpu_options': {'allow_growth': True},\n",
      "                     'inter_op_parallelism_threads': 2,\n",
      "                     'intra_op_parallelism_threads': 2,\n",
      "                     'log_device_placement': False},\n",
      " 'timesteps_per_iteration': -1,\n",
      " 'train_batch_size': 1024,\n",
      " 'training_intensity': None,\n",
      " 'v_max': 10.0,\n",
      " 'v_min': -10.0,\n",
      " 'validate_workers_after_construction': True}\n"
     ]
    }
   ],
   "source": [
    "# build the algorithm and load from checkpoint\n",
    "with open(\"saved_runs/bandits/params.pkl\", 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "\n",
    "pprint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 14:28:56,633\tWARNING algorithm.py:2325 -- `evaluation_parallel_to_training` can only be done if `evaluation_num_workers` > 0! Setting `evaluation_parallel_to_training` to False.\n",
      "2022-09-14 14:28:56,634\tWARNING deprecation.py:47 -- DeprecationWarning: `config['multiagent']['replay_mode']` has been deprecated. config['replay_buffer_config']['replay_mode'] This will raise an error in the future!\n",
      "/Users/kourosh/dev/workspace-project-gpu-workspace-kh/python/ray/_private/ray_option_utils.py:284: DeprecationWarning: Setting 'object_store_memory' for actors is deprecated since it doesn't actually reserve the required object store memory. Use object spilling that's enabled by default (https://docs.ray.io/en/master/ray-core/objects/object-spilling.html) instead to bypass the object store memory size limitation.\n",
      "  warnings.warn(\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   _ATTRVALUE_LISTVALUE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   import imp\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/keras/utils/image_utils.py:36: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   'nearest': pil_image.NEAREST,\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/keras/utils/image_utils.py:37: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   'bilinear': pil_image.BILINEAR,\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/keras/utils/image_utils.py:38: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   'bicubic': pil_image.BICUBIC,\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/keras/utils/image_utils.py:39: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   'hamming': pil_image.HAMMING,\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/keras/utils/image_utils.py:40: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   'box': pil_image.BOX,\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/keras/utils/image_utils.py:41: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   'lanczos': pil_image.LANCZOS,\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow_probability/python/__init__.py:61: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m WARNING:tensorflow:From /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:561: calling function (from tensorflow.python.eager.def_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=90806)\u001b[0m experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=90806)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray/lib/python3.8/site-packages/gin/tf/__init__.py:48: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=90806)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "2022-09-14 14:29:01,525\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DQN"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_algo = DQN(params)\n",
    "bandit_algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 14:29:20,321\tINFO trainable.py:691 -- Restored on 127.0.0.1 from checkpoint: saved_runs/bandits2/checkpoint_000666\n",
      "2022-09-14 14:29:20,324\tINFO trainable.py:700 -- Current state after restoring: {'_iteration': 666, '_timesteps_total': None, '_time_total': 53552.765288591385, '_episodes_total': 66600}\n"
     ]
    }
   ],
   "source": [
    "# Load the checkpoint from the result folder of your running script\n",
    "checkpoint = \"saved_runs/bandits/checkpoint_000666\"\n",
    "bandit_algo.restore(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "observation_features:  [0.88634086 0.18800597 0.9635299  0.06722239 0.8350821  0.07456641\n",
      " 0.8011377  0.05048527 0.9591325  0.00305099 0.9197687  0.12076091\n",
      " 0.82102954 0.07638869 0.8072952  0.17808232 0.9961842  0.0119884\n",
      " 0.9781092  0.1153803 ]\n",
      "bandit's feature value=[0.9961842]; argmax feature=[0.9961842];\n",
      "--------------------------------------------------\n",
      "observation_features:  [0.9484959  0.1260368  0.9163684  0.00408783 0.8420053  0.10893697\n",
      " 0.95382303 0.05013905 0.85717916 0.17047901 0.9950013  0.17697066\n",
      " 0.8719016  0.11977179 0.8709591  0.06803805 0.8356162  0.04753884\n",
      " 0.8089725  0.10108629]\n",
      "bandit's feature value=[0.9950013]; argmax feature=[0.9950013];\n",
      "--------------------------------------------------\n",
      "observation_features:  [0.8752505  0.11856108 0.9259884  0.02852006 0.98676825 0.18927598\n",
      " 0.92045933 0.07755326 0.8726376  0.04086906 0.855353   0.04930717\n",
      " 0.8347216  0.19332194 0.9914025  0.11959474 0.94626015 0.06807704\n",
      " 0.8184111  0.0926996 ]\n",
      "bandit's feature value=[0.9914025]; argmax feature=[0.9914025];\n",
      "--------------------------------------------------\n",
      "observation_features:  [0.9017398  0.01769204 0.90560704 0.19843161 0.87900716 0.06711929\n",
      " 0.9610901  0.1508698  0.86261326 0.12680733 0.90808094 0.05935875\n",
      " 0.82215756 0.06252806 0.8913958  0.13178802 0.8508515  0.12822025\n",
      " 0.8400247  0.13152497]\n",
      "bandit's feature value=[0.9610901]; argmax feature=[0.9610901];\n",
      "--------------------------------------------------\n",
      "observation_features:  [0.95565784 0.15591969 0.9220656  0.06180007 0.939547   0.17192365\n",
      " 0.92506474 0.19648157 0.99530005 0.03333883 0.80463564 0.03214891\n",
      " 0.98469937 0.19070996 0.8421957  0.07210505 0.90987504 0.05436617\n",
      " 0.8921203  0.13923231]\n",
      "bandit's feature value=[0.99530005]; argmax feature=[0.99530005];\n",
      "--------------------------------------------------\n",
      "observation_features:  [9.0007120e-01 1.4321420e-01 9.0519118e-01 2.7980463e-04 8.7894005e-01\n",
      " 9.8433390e-02 8.8057607e-01 7.0859663e-02 9.0012288e-01 8.9035325e-02\n",
      " 8.1808656e-01 5.4712582e-02 9.8869544e-01 5.3089284e-03 8.0799973e-01\n",
      " 5.6628071e-02 9.1646886e-01 1.9817856e-01 9.9852842e-01 1.9862348e-01]\n",
      "bandit's feature value=[0.9985284]; argmax feature=[0.9985284];\n",
      "--------------------------------------------------\n",
      "observation_features:  [0.8220097  0.13289629 0.9047974  0.03462998 0.988592   0.04837202\n",
      " 0.99978644 0.11653876 0.8366558  0.07736909 0.83793473 0.08215413\n",
      " 0.918936   0.14331722 0.8973783  0.06191796 0.9154883  0.08834156\n",
      " 0.8719356  0.06426638]\n",
      "bandit's feature value=[0.99978644]; argmax feature=[0.99978644];\n",
      "--------------------------------------------------\n",
      "observation_features:  [0.8416414  0.09025172 0.8983686  0.17981526 0.94587207 0.15401796\n",
      " 0.87508786 0.06874791 0.931007   0.1422076  0.82270753 0.02660574\n",
      " 0.8912078  0.03194725 0.9923284  0.16752315 0.9040321  0.04365445\n",
      " 0.82698375 0.19581407]\n",
      "bandit's feature value=[0.9923284]; argmax feature=[0.9923284];\n",
      "--------------------------------------------------\n",
      "observation_features:  [0.9414087  0.17199512 0.87743455 0.0501668  0.8598876  0.1713791\n",
      " 0.8945968  0.13265541 0.9611457  0.0505961  0.8159147  0.14655212\n",
      " 0.99227947 0.19076094 0.89809984 0.12643841 0.946599   0.1804819\n",
      " 0.8324494  0.08117627]\n",
      "bandit's feature value=[0.99227947]; argmax feature=[0.99227947];\n",
      "--------------------------------------------------\n",
      "observation_features:  [0.88341814 0.13911821 0.8849695  0.17162284 0.9693865  0.01403982\n",
      " 0.8603505  0.19592473 0.8071254  0.09847853 0.99047536 0.16211475\n",
      " 0.8588661  0.11924671 0.8862356  0.1184795  0.9787504  0.11080424\n",
      " 0.8985733  0.06385409]\n",
      "bandit's feature value=[0.99047536]; argmax feature=[0.99047536];\n"
     ]
    }
   ],
   "source": [
    "env = ModifiedLongTermSatisfactionRecSimEnv(env_config)\n",
    "obs = env.reset()\n",
    "\n",
    "# Run a single episode.\n",
    "done = False\n",
    "while not done:\n",
    "    # use `compute_single_action` method of our Trainer.\n",
    "    # This is one way to perform inference on a learned policy.\n",
    "    # TODO: Code here\n",
    "    bandit_action = bandit_algo.compute_single_action(obs)\n",
    "    argmax_action = int(max(obs['doc'], key=lambda x: obs['doc'][x]))\n",
    "\n",
    "    feature_value_of_bandit = obs[\"doc\"][str(bandit_action)]\n",
    "    feature_value_of_greedy = obs[\"doc\"][str(argmax_action)]\n",
    "\n",
    "\n",
    "    # Print out the picked document's feature value and compare that to the highest possible feature value.\n",
    "    print(\"-\"*50)\n",
    "    print(\"observation_features: \", np.concatenate(list(obs[\"doc\"].values())))\n",
    "    print(f\"bandit's feature value={feature_value_of_bandit}; argmax feature={feature_value_of_greedy};\")\n",
    "\n",
    "    # Apply the computed action in the environment and continue.\n",
    "    obs, r, done, _ = env.step(bandit_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dummy Recsim environment, we did not have any user features.  This makes the contextual bandit without any user context, i.e. without any state.  A stateless bandit cannot remember things between timesteps, so it will sort of converge to the most greedy policy that recommends chocolotes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the problem with RL <a class=\"anchor\" id=\"dqn\"></a>\n",
    "\n",
    "So far the bandit solution has just converged to the perforamnce of greedy argmax policy. **How can we improve over the random policy baseline** Now let's run the DQN algorithm with $\\gamma = 0.99$. We run this script for 1M environment timesteps till convergence. It will take ~ 1hour to run this training job.\n",
    "\n",
    "**Exercise (1 min)** How would you modify the previous config object (`bandit_config`) to train an RL agent to optimize long-term engagement (hint: use `.training()` API)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-09-14 14:08:55 (running for 00:00:17.01)<br>Memory usage on this node: 13.3/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/8.32 GiB heap, 0.0/2.0 GiB objects<br>Result logdir: /Users/kourosh/dev/anyscale_academy/ray-rllib/acm_recsys_tutorial_2022/results_notebook/online_rl/dqn/DQN_2022-09-14_14-08-38<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  num_recreated_wor...</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_modified-lts_671b0_00000</td><td>TERMINATED</td><td>127.0.0.1:87634</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.61303</td><td style=\"text-align: right;\">1000</td><td style=\"text-align: right;\"> 99.8093</td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">             142.959</td><td style=\"text-align: right;\">             51.0457</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/util/placement_group.py:78: DeprecationWarning: placement_group parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return bundle_reservation_check.options(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/_private/ray_option_utils.py:266: DeprecationWarning: Setting 'object_store_memory' for actors is deprecated since it doesn't actually reserve the required object store memory. Use object spilling that's enabled by default (https://docs.ray.io/en/releases-2.0.0/ray-core/objects/object-spilling.html) instead to bypass the object store memory size limitation.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/actor.py:637: DeprecationWarning: placement_group parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/actor.py:637: DeprecationWarning: placement_group_bundle_index parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/actor.py:637: DeprecationWarning: placement_group_capture_child_tasks parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   _ATTRVALUE_LISTVALUE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   import imp\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:36: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   'nearest': pil_image.NEAREST,\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:37: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   'bilinear': pil_image.BILINEAR,\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:38: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   'bicubic': pil_image.BICUBIC,\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:39: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   'hamming': pil_image.HAMMING,\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:40: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   'box': pil_image.BOX,\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:41: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   'lanczos': pil_image.LANCZOS,\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow_probability/__init__.py:58: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow_probability/python/mcmc/sample_halton_sequence.py:374: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\u001b[2m\u001b[36m(pid=87634)\u001b[0m   sieve = np.ones(n // 3 + (n % 6 == 2), dtype=np.bool)\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/gin/tf/__init__.py:48: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m 2022-09-14 14:08:52,263\tWARNING deprecation.py:47 -- DeprecationWarning: `ray.rllib.algorithms.dqn.dqn.DEFAULT_CONFIG` has been deprecated. Use `ray.rllib.algorithms.dqn.dqn.DQNConfig(...)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m 2022-09-14 14:08:52,263\tWARNING deprecation.py:47 -- DeprecationWarning: `config['multiagent']['replay_mode']` has been deprecated. config['replay_buffer_config']['replay_mode'] This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m 2022-09-14 14:08:52,264\tINFO simple_q.py:293 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m 2022-09-14 14:08:52,267\tINFO algorithm.py:351 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/_private/ray_option_utils.py:266: DeprecationWarning: Setting 'object_store_memory' for actors is deprecated since it doesn't actually reserve the required object store memory. Use object spilling that's enabled by default (https://docs.ray.io/en/releases-2.0.0/ray-core/objects/object-spilling.html) instead to bypass the object store memory size limitation.\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m 2022-09-14 14:08:52,280\tWARNING env.py:142 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m 2022-09-14 14:08:52,321\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m 2022-09-14 14:08:52,350\tWARNING deprecation.py:47 -- DeprecationWarning: `ReplayBuffer.add_batch()` has been deprecated. Use `ReplayBuffer.add()` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m 2022-09-14 14:08:52,359\tWARNING multi_agent_prioritized_replay_buffer.py:220 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_modified-lts_671b0_00000:\n",
      "  agent_timesteps_total: 1000\n",
      "  counters:\n",
      "    last_target_update_ts: 1000\n",
      "    num_agent_steps_sampled: 1000\n",
      "    num_agent_steps_trained: 32\n",
      "    num_env_steps_sampled: 1000\n",
      "    num_env_steps_trained: 32\n",
      "    num_target_updates: 1\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-14_14-08-54\n",
      "  done: true\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 142.95924904647663\n",
      "  episode_reward_mean: 99.80930260753946\n",
      "  episode_reward_min: 51.045706115732166\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: d00664721d804eaf8baf6db631d081e4\n",
      "  hostname: Kouroshs-MacBook-Pro-13\n",
      "  info:\n",
      "    last_target_update_ts: 1000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 40.0\n",
      "          max_q: 0.587704598903656\n",
      "          mean_q: -0.3412080705165863\n",
      "          min_q: -1.316676378250122\n",
      "        mean_td_error: -14.340478897094727\n",
      "        model: {}\n",
      "        num_agent_steps_trained: 32.0\n",
      "        td_error: [-1.6475883722305298, -2.1412103176116943, -3.0756161212921143, -22.532344818115234,\n",
      "          -19.332195281982422, -4.6281609535217285, -17.081340789794922, -10.205001831054688,\n",
      "          -32.18067169189453, -11.900308609008789, -10.277835845947266, -2.2524795532226562,\n",
      "          -3.0889298915863037, -26.728652954101562, -27.32392692565918, -10.521056175231934,\n",
      "          -2.843743085861206, -5.937435150146484, -2.834545612335205, -10.277835845947266,\n",
      "          -36.546661376953125, -2.970632314682007, -21.60882568359375, -38.42585372924805,\n",
      "          -10.522065162658691, -2.3687524795532227, -1.545008897781372, -12.605607986450195,\n",
      "          -32.1558723449707, -1.7617833614349365, -3.741828441619873, -67.83155822753906]\n",
      "    num_agent_steps_sampled: 1000\n",
      "    num_agent_steps_trained: 32\n",
      "    num_env_steps_sampled: 1000\n",
      "    num_env_steps_trained: 32\n",
      "    num_target_updates: 1\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 1000\n",
      "  num_agent_steps_trained: 32\n",
      "  num_env_steps_sampled: 1000\n",
      "  num_env_steps_sampled_this_iter: 1000\n",
      "  num_env_steps_trained: 32\n",
      "  num_env_steps_trained_this_iter: 32\n",
      "  num_faulty_episodes: 0\n",
      "  num_healthy_workers: 0\n",
      "  num_recreated_workers: 0\n",
      "  num_steps_trained_this_iter: 32\n",
      "  perf:\n",
      "    cpu_util_percent: 65.25\n",
      "    ram_util_percent: 83.75\n",
      "  pid: 87634\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039328347433816184\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.26843621656968525\n",
      "    mean_inference_ms: 0.9887947307361832\n",
      "    mean_raw_obs_processing_ms: 1.128431562181715\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 142.95924904647663\n",
      "    episode_reward_mean: 99.80930260753946\n",
      "    episode_reward_min: 51.045706115732166\n",
      "    episodes_this_iter: 100\n",
      "    hist_stats:\n",
      "      episode_lengths: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "      episode_reward: [142.82140520823282, 118.79649889433985, 96.08563575347209, 109.63964221576862,\n",
      "        68.90383257917489, 110.54726871015623, 82.41518761886068, 104.27587448292759,\n",
      "        130.43063797227524, 94.1570927483861, 100.20888907303294, 119.40801129866, 99.63524768613817,\n",
      "        101.05245480511068, 122.7129450401749, 95.87132598584526, 122.73694087293917,\n",
      "        95.22584450426224, 111.92994942620057, 132.04953675450128, 80.0306716646244,\n",
      "        103.72943306371079, 71.97234596005222, 101.01894065685607, 91.96404222410507,\n",
      "        101.6383963245272, 112.2938291818112, 76.55705535718404, 100.3079848333377,\n",
      "        96.81201534087295, 107.37549504413658, 112.43197371121092, 91.04536139795091,\n",
      "        75.08128930831019, 86.07203320614653, 86.11291859502192, 139.50896696466745,\n",
      "        116.22026632242236, 142.95924904647663, 109.20623703530461, 97.83864271118539,\n",
      "        118.11822723199012, 96.5535602557827, 115.92114714344085, 87.39437683902332,\n",
      "        65.80254911682248, 123.84396072100745, 101.79964502112516, 64.51143270185237,\n",
      "        125.36591193471254, 76.19294661275028, 122.28110444265961, 84.80734936026016,\n",
      "        94.15720756107478, 64.99112026997325, 100.70676776242466, 68.68432086725835,\n",
      "        106.18993606953018, 109.81122396035914, 88.17957458628072, 105.96931824564163,\n",
      "        106.3384265103192, 51.045706115732166, 124.1795604537601, 95.9752515854708,\n",
      "        92.544641326244, 73.64767486457478, 124.94483101545441, 117.8221969856634, 86.24175414602897,\n",
      "        64.4633709070464, 84.80538050129208, 138.14993341029046, 110.02295947129863,\n",
      "        75.64960618215925, 138.63700920643322, 86.04021687775534, 95.7190905280978,\n",
      "        116.37095445992816, 104.55429582822316, 130.10584704533832, 103.70335531751269,\n",
      "        80.20212849512968, 62.89079636018156, 105.94297989144106, 122.5016266525284,\n",
      "        75.47346858186171, 77.4130901327444, 75.89722589648497, 74.04548810207478, 98.31717244645365,\n",
      "        83.18459674717748, 97.51290624941042, 120.72971782053874, 76.27962666534499,\n",
      "        80.5957007158652, 110.28984568352499, 118.20599686621051, 119.10315215691523,\n",
      "        101.01962826709232]\n",
      "    num_faulty_episodes: 0\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.039328347433816184\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.26843621656968525\n",
      "      mean_inference_ms: 0.9887947307361832\n",
      "      mean_raw_obs_processing_ms: 1.128431562181715\n",
      "  time_since_restore: 2.6130282878875732\n",
      "  time_this_iter_s: 2.6130282878875732\n",
      "  time_total_s: 2.6130282878875732\n",
      "  timers:\n",
      "    learn_throughput: 2427.171\n",
      "    learn_time_ms: 13.184\n",
      "    load_throughput: 38468.824\n",
      "    load_time_ms: 0.832\n",
      "    synch_weights_time_ms: 0.019\n",
      "    training_iteration_time_ms: 17.54\n",
      "  timestamp: 1663189734\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1000\n",
      "  training_iteration: 1\n",
      "  trial_id: 671b0_00000\n",
      "  warmup_time: 0.07596802711486816\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQN pid=87634)\u001b[0m 2022-09-14 14:08:54,917\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n",
      "2022-09-14 14:08:56,000\tINFO tune.py:758 -- Total run time: 17.60 seconds (16.99 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "# TODO: Code here\n",
    "dqn_config = bandit_config.training(gamma=0.99)\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    DQN,\n",
    "    param_space=dqn_config.to_dict(),\n",
    "    run_config=air.RunConfig(\n",
    "        local_dir='./results_notebook/online_rl/dqn',\n",
    "        stop={\"training_iteration\": 1},  # this is enough for it to converge\n",
    "    )\n",
    ")\n",
    "dqn_results = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the same script as before, with `gamma=0.99` passed in as a parameter. We should also run the script longer (1M steps) as it will take longer for DQN to converge. \n",
    "```bash\n",
    "python tutorial_scripts/run_online_rl.py --seed 0 --gamma 0.99 --exp_name dqn --timesteps 1_000_000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Take a look at the results and compare them to bandits via tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the results\n",
    "bandit_df = pd.read_csv(\"saved_runs/bandits/progress.csv\")\n",
    "dqn_df = pd.read_csv(\"saved_runs/dqn/progress.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'RL vs. Bandits training performance')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results and compare to baselines\n",
    "sns.lineplot(data=bandit_df, x=\"training_iteration\", y=\"episode_reward_mean\", label=\"Bandits\")\n",
    "sns.lineplot(data=dqn_df, x=\"training_iteration\", y=\"episode_reward_mean\", label=\"DQN\")\n",
    "plt.axhline(random_baseline, color=\"red\", linestyle='--', label=\"random baseline\")\n",
    "plt.axhline(sweetest_baseline, color=\"blue\", linestyle='--', label=\"sweetest baseline\")\n",
    "plt.legend()\n",
    "plt.title('RL vs. Bandits training performance')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Sweetest** straight line, is the mean reward achieved by the greedy policy, selecting always the item with most immediate reward value.\n",
    "- **Bandit** short term reward hovers around the \"sweetest baseline\".\n",
    "- **Random** straight line, items are randomly chosen to be recommended at each timestep. Since this baseline mixes the sweetest and kaliest options the engagement is kept higher than either of the greedy methods, obtaining larger rewards.\n",
    "- **DQN (RL)**, such as DQN that optimize for long-term engagement significantly improves upon random baselines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions and Break (5 min) <a class=\"anchor\" id=\"break\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline RL with RecSys <a class=\"anchor\" id=\"offline-rl\"></a>\n",
    "\n",
    "<img src=\"images/offline_rl.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### If we don't have a live environment, how do we know, how well our trained policy will perform?\n",
    "\n",
    "One of the challenges in offline RL is the evaluation of the trained policy. In online RL (when a simulator\n",
    "is available), one can either use the data collected for training to compute episode total rewards. Remember\n",
    "that observations, actions, rewards, and done flags are all part of this training data. Alternatively,\n",
    "one could run a separate worker (with the same trained policy) and run it on a fresh evaluation-only environment.\n",
    "In this latter case, we would also have the chance to switch off any exploratory behavior (e.g. stochasticity used\n",
    "for better action entropy).\n",
    "\n",
    "In offline RL, no such data from a live environment is available to us. There are two common ways of addressing this dilemma:\n",
    "\n",
    "1) We deploy the learned policies into production, or maybe just a portion of our production system (similar to A/B testing), and see what happens.\n",
    "\n",
    "2) We use a method called \"off policy evaluation\" (OPE) to compute an estimate on how the new policy would perform if we were to deploy it into a real environment. There are different OPE methods available in RLlib off-the-shelf.\n",
    "\n",
    "3) The third option - which we will use here - is kind of cheating and only possible if you actually do have a simulator available (but you only want to use it for evaluation, not for training, because you want to see how cool offline RL is :) )\n",
    "\n",
    "In this tutorial, we will use the third option to show the effectiveness of offline RL in improving over existing policies running in production. We will also see how much benefit we can get by improving our dataset quality, starting from a totally random policy all the way to 20% expert demonstrations adn 80% random. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the currently running policies in production to collect some \"historical data\" that we can use to train RL agents with. Offline RL can be used to improve upon the existing policies deployed in production. We have prepared some datasets in advance for the purpose of this tutorial. They were all generated using `<path to the script>`. In this script we can mix the percentage of the \"expert\" data vs. random data to investigate the effect of dataset quality on the final performance of our models.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an exemplar dataset we have prepared before:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 14:09:02,640\tWARNING read_api.py:291 -- â ï¸  The number of blocks in this dataset (1) limits its parallelism to 1 concurrent tasks. This is much less than the number of available CPU slots in the cluster. Use `.repartition(n)` to increase the number of dataset blocks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colimns:  Index(['type', 'obs', 'new_obs', 'actions', 'rewards', 'dones', 'eps_id', 't',\n",
      "       'action_prob'],\n",
      "      dtype='object')\n",
      "Number of rows:  100\n",
      "Value of the first row\n",
      "--------------------\n",
      "type                                                 SampleBatch\n",
      "obs            BCJNGGhAMAQAAAAAAACKIgIAAGGABZUlBAABAPEcjBVudW...\n",
      "new_obs        BCJNGGhALQQAAAAAAABmHgIAAGGABZUiBAABAPEcjBVudW...\n",
      "actions                                                      [0]\n",
      "rewards                                      [22.45008736559994]\n",
      "dones                                                    [False]\n",
      "eps_id                                                       [0]\n",
      "t                                                            [0]\n",
      "action_prob                                               [0.05]\n",
      "Name: 0, dtype: object\n",
      "Value of the second row:\n",
      "--------------------\n",
      "type                                                 SampleBatch\n",
      "obs            BCJNGGhALQQAAAAAAABmHgIAAGGABZUiBAABAPEcjBVudW...\n",
      "new_obs        BCJNGGhALQQAAAAAAABmHAIAAGGABZUiBAABAPEcjBVudW...\n",
      "actions                                                      [7]\n",
      "rewards                                     [1.4457165728302563]\n",
      "dones                                                    [False]\n",
      "eps_id                                                       [0]\n",
      "t                                                            [1]\n",
      "action_prob                                               [0.05]\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "prefix = \"s3://air-example-data/rllib/acm_recsys22_tutorial_data/\"\n",
    "train_data_path = prefix + \"sampled_data_train_random_transitions_small\"\n",
    "\n",
    "dset = data.read_json(train_data_path)\n",
    "df = dset.to_pandas()\n",
    "print('Colimns: ', df.columns)\n",
    "print('Number of rows: ', len(df))\n",
    "print('Value of the first row')\n",
    "print('-'*20)\n",
    "print(df.iloc[0])\n",
    "print('Value of the second row:')\n",
    "print('-'*20)\n",
    "print(df.iloc[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dataset schema, we can see that RLlib always expects a `type` column that is `SampleBatch`. It will have the normal transition entities per each row (i.e. observation, next_observation, action, reward, done values). It will also contain an episode_id, a timestep indicator, and an action_prob that show the probablity of the action that we chosen at the time of data collection. For random policy the action prob will always be 1/20 (0.05). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an understaning of the dataset example format, we can use RLlib to train an offline RL algorithm. RLlib provides several out of the box offline RL algorithms that you can use. Beside those offline-RL-specific algorithms, we can also use any off-policy algorithm (e.g. DQN) to do offline-RL. The only difference between online and offline version is that instead of using an enviornement sampler, we use a dataset sampler to get the data from. In the next section, we will use DQN, with the difference that we pass a dataset path to the input config."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the summary of the differences:\n",
    "\n",
    "- Change the input config from a sample to offline dataset is configured by `.offline_data()` API:\n",
    "\n",
    "```python\n",
    "    .offline_data(\n",
    "        input_='dataset',\n",
    "        input_config={\n",
    "            'format': 'json',\n",
    "            'paths': train_data_path\n",
    "        }\n",
    "    )\n",
    "```\n",
    "\n",
    "- The environment is not passed to the enviornement anymore. Instead we need to pass in the expected action and observation space to construct the policies. We can create them manually based on our knowledge of our system. In this case we actually cheat and use the environment attributes to get the correct action and observatin spaces.\n",
    "\n",
    "```python \n",
    "    .environment(\n",
    "        action_space=action_space,\n",
    "        observation_space=observation_space,\n",
    "    )\n",
    "```\n",
    "\n",
    "- evaluation config: Since during the evaluation we still need to use the enviroenement simulations, we need to specify it explicitly here. RLlib by default will use the training settings during evaluation and to avoid that default behavior we need to explicitly specify the simulation environment configs. \n",
    "\n",
    "```python\n",
    "    .evaluation(\n",
    "        evaluation_config={\n",
    "            \"input\": \"sampler\",\n",
    "            \"explore\": False,\n",
    "            \"env\": \"modified-lts\",\n",
    "            \"env_config\": env_config,\n",
    "        },\n",
    "    )\n",
    "```\n",
    "\n",
    "- (Advanced) configuring the replay buffer to become a dummy buffer. By default RLlib uses a large replay buffer that is useful in online RL but doesn't add much value in the offline case. It is recommended to by-pass this behavior by configuring the replay buffer size to be the same as the dataset sampling size, so that the sampling flow does not get disrupted by the replay buffer behavior.\n",
    "\n",
    "```python\n",
    "    .training(\n",
    "        replay_buffer_config={\n",
    "            \"capacity\": 512,\n",
    "            \"learning_starts\": 0\n",
    "        }\n",
    "    )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the script below takes about 1 hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ModifiedLongTermSatisfactionRecSimEnv(env_config)\n",
    "action_space = env.action_space\n",
    "observation_space = env.observation_space\n",
    "\n",
    "dqn_config_offline = (\n",
    "    dqn_config\n",
    "    .offline_data(\n",
    "        input_='dataset',\n",
    "        input_config={\n",
    "            'format': 'json',\n",
    "            'paths': train_data_path,\n",
    "        }\n",
    "    )\n",
    "    .environment(\n",
    "        action_space=action_space,\n",
    "        observation_space=observation_space,\n",
    "    )\n",
    "    .evaluation(\n",
    "        evaluation_interval=10, \n",
    "        evaluation_duration=10, \n",
    "        evaluation_duration_unit=\"episodes\",\n",
    "        evaluation_parallel_to_training=True,\n",
    "        evaluation_config={\n",
    "            \"input\": \"sampler\",\n",
    "            \"explore\": False,\n",
    "            \"env\": \"modified-lts\",\n",
    "            \"env_config\": env_config,\n",
    "        },\n",
    "    )\n",
    "    .debugging(seed=seed, log_level=\"ERROR\")\n",
    "    .training(\n",
    "        gamma=1.0,\n",
    "        num_atoms=1,\n",
    "        double_q=True,\n",
    "        dueling=False,\n",
    "        model=dict(\n",
    "            fcnet_hiddens=[1024, 1024, 1024],\n",
    "            fcnet_activation='relu', \n",
    "        ),\n",
    "        train_batch_size=512,\n",
    "        lr=3e-4,\n",
    "        target_network_update_freq=512,\n",
    "        replay_buffer_config={\n",
    "            \"capacity\": 512,\n",
    "            \"learning_starts\": 0\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the long-running learning script run:\n",
    "\n",
    "```bash\n",
    "python tutorial_scripts/run_offline_rl.py --dataset_suffix sampled_data_train_random_transitions\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-09-14 14:09:27 (running for 00:00:23.77)<br>Memory usage on this node: 13.4/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/8.32 GiB heap, 0.0/2.0 GiB objects<br>Result logdir: /Users/kourosh/dev/anyscale_academy/ray-rllib/acm_recsys_tutorial_2022/results_notebook/offline_rl/DQN_2022-09-14_14-09-03<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  num_recreated_wor...</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_modified-lts_75ee4_00000</td><td>TERMINATED</td><td>127.0.0.1:87694</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.42812</td><td style=\"text-align: right;\">1024</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">                 nan</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/util/placement_group.py:78: DeprecationWarning: placement_group parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return bundle_reservation_check.options(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/_private/ray_option_utils.py:266: DeprecationWarning: Setting 'object_store_memory' for actors is deprecated since it doesn't actually reserve the required object store memory. Use object spilling that's enabled by default (https://docs.ray.io/en/releases-2.0.0/ray-core/objects/object-spilling.html) instead to bypass the object store memory size limitation.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/actor.py:637: DeprecationWarning: placement_group parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/actor.py:637: DeprecationWarning: placement_group_bundle_index parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/actor.py:637: DeprecationWarning: placement_group_capture_child_tasks parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   _ATTRVALUE_LISTVALUE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   import imp\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:36: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   'nearest': pil_image.NEAREST,\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:37: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   'bilinear': pil_image.BILINEAR,\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:38: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   'bicubic': pil_image.BICUBIC,\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:39: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   'hamming': pil_image.HAMMING,\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:40: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   'box': pil_image.BOX,\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/keras/utils/image_utils.py:41: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   'lanczos': pil_image.LANCZOS,\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow_probability/__init__.py:58: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/tensorflow_probability/python/mcmc/sample_halton_sequence.py:374: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\u001b[2m\u001b[36m(pid=87694)\u001b[0m   sieve = np.ones(n // 3 + (n % 6 == 2), dtype=np.bool)\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/gin/tf/__init__.py:48: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m 2022-09-14 14:09:12,674\tWARNING deprecation.py:47 -- DeprecationWarning: `ray.rllib.algorithms.dqn.dqn.DEFAULT_CONFIG` has been deprecated. Use `ray.rllib.algorithms.dqn.dqn.DQNConfig(...)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/rllib/utils/debug/deterministic.py:42: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m   if LooseVersion(torch.__version__) >= LooseVersion(\"1.8.0\"):\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m 2022-09-14 14:09:12,675\tWARNING algorithm.py:2114 -- `evaluation_parallel_to_training` can only be done if `evaluation_num_workers` > 0! Setting `evaluation_parallel_to_training` to False.\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m 2022-09-14 14:09:12,676\tWARNING deprecation.py:47 -- DeprecationWarning: `config['multiagent']['replay_mode']` has been deprecated. config['replay_buffer_config']['replay_mode'] This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m 2022-09-14 14:09:12,676\tINFO simple_q.py:293 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m 2022-09-14 14:09:12,678\tINFO algorithm.py:351 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/ray-2/lib/python3.8/site-packages/ray/_private/ray_option_utils.py:266: DeprecationWarning: Setting 'object_store_memory' for actors is deprecated since it doesn't actually reserve the required object store memory. Use object spilling that's enabled by default (https://docs.ray.io/en/releases-2.0.0/ray-core/objects/object-spilling.html) instead to bypass the object store memory size limitation.\n",
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m DatasetReader 0 has 100, samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQN pid=87694)\u001b[0m 2022-09-14 14:09:17,271\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_modified-lts_75ee4_00000:\n",
      "  agent_timesteps_total: 1024\n",
      "  counters:\n",
      "    last_target_update_ts: 1024\n",
      "    num_agent_steps_sampled: 1024\n",
      "    num_agent_steps_trained: 1024\n",
      "    num_env_steps_sampled: 1024\n",
      "    num_env_steps_trained: 1024\n",
      "    num_target_updates: 2\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-14_14-09-26\n",
      "  done: true\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: f7393cf8e4374f09897d4d26f4bac9bf\n",
      "  hostname: Kouroshs-MacBook-Pro-13\n",
      "  info:\n",
      "    last_target_update_ts: 1024\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0003\n",
      "          grad_gnorm: 40.0\n",
      "          max_q: 17.398069381713867\n",
      "          mean_q: 0.5301390886306763\n",
      "          min_q: -3.08048152923584\n",
      "        mean_td_error: -13.04154109954834\n",
      "        model: {}\n",
      "        num_agent_steps_trained: 512.0\n",
      "        td_error: [-2.5246975421905518, -15.832113265991211, -2.9286468029022217, -1.7219157218933105,\n",
      "          -4.7678351402282715, -2.867734432220459, -3.785020589828491, -2.311821222305298,\n",
      "          -2.578303813934326, -0.10062360763549805, -1.5532351732254028, -2.895843029022217,\n",
      "          -1.9734052419662476, -2.389592409133911, -2.867734432220459, -2.4410769939422607,\n",
      "          -4.14689826965332, -0.6847338676452637, -3.685330390930176, -34.133575439453125,\n",
      "          -27.677404403686523, -0.6847338676452637, -2.300475835800171, -36.87446975708008,\n",
      "          -80.83019256591797, -1.135479211807251, -34.133575439453125, -9.623801231384277,\n",
      "          -80.83019256591797, -3.1824049949645996, -10.576726913452148, -3.1533682346343994,\n",
      "          -49.37401580810547, -23.009357452392578, -49.37401580810547, -5.817642688751221,\n",
      "          -15.491028785705566, -3.567211151123047, -10.576726913452148, -55.56748580932617,\n",
      "          -53.11589050292969, -1.7219157218933105, -2.895843029022217, -51.195518493652344,\n",
      "          -10.576726913452148, -22.60820770263672, -53.11589050292969, -27.677404403686523,\n",
      "          -3.5373010635375977, -2.312549352645874, -53.11589050292969, -3.169973373413086,\n",
      "          -61.502071380615234, -2.4410910606384277, -2.5911331176757812, -28.612890243530273,\n",
      "          -2.300475835800171, -3.3312034606933594, -22.60820770263672, -1.927714228630066,\n",
      "          -32.955265045166016, -3.1824049949645996, -42.27695083618164, -1.276259422302246,\n",
      "          -9.16895580291748, -2.343522548675537, -2.4410769939422607, -1.135479211807251,\n",
      "          -3.567211151123047, -1.3226743936538696, 1.77516508102417, -2.300475835800171,\n",
      "          -73.47428131103516, -2.578303813934326, -13.988373756408691, -9.16895580291748,\n",
      "          -80.83019256591797, -1.276259422302246, -3.503541946411133, -3.1824049949645996,\n",
      "          -2.300475835800171, -49.37401580810547, -4.214771270751953, -1.311438798904419,\n",
      "          -2.312549352645874, -50.07960891723633, -2.329728364944458, -42.27695083618164,\n",
      "          -15.234942436218262, -2.3673818111419678, -38.11575698852539, -73.47428131103516,\n",
      "          -2.578303813934326, -2.605522394180298, -3.144289970397949, -2.343522548675537,\n",
      "          -2.312549352645874, -2.867734432220459, -3.685330390930176, -24.746192932128906,\n",
      "          -61.502071380615234, -80.83019256591797, -15.491028785705566, -2.5246975421905518,\n",
      "          -9.4075927734375, -3.144289970397949, -2.5911331176757812, -1.9351129531860352,\n",
      "          -0.10062360763549805, -1.977062702178955, -1.9769949913024902, -1.9351129531860352,\n",
      "          -3.3312034606933594, -9.4075927734375, -1.5532351732254028, -0.6847338676452637,\n",
      "          -3.75954532623291, -1.192234992980957, -1.927714228630066, -1.8868589401245117,\n",
      "          -2.605522394180298, -24.46055030822754, -34.133575439453125, -23.009357452392578,\n",
      "          -1.7219157218933105, -2.1288492679595947, -1.8868589401245117, -4.14689826965332,\n",
      "          -2.329728364944458, -1.9351129531860352, -3.169973373413086, -15.491028785705566,\n",
      "          -42.27695083618164, -13.988373756408691, -2.867734432220459, -42.27695083618164,\n",
      "          -36.87446975708008, -0.10062360763549805, -23.009357452392578, -2.895843029022217,\n",
      "          -2.5911331176757812, -10.576726913452148, -1.192234992980957, -26.344017028808594,\n",
      "          -1.9351129531860352, -2.596219301223755, -4.214771270751953, -2.895843029022217,\n",
      "          -1.135479211807251, -26.344017028808594, -2.329728364944458, -5.817642688751221,\n",
      "          -2.272246837615967, -2.597764015197754, -0.14541101455688477, -11.272283554077148,\n",
      "          -30.51406478881836, -2.329728364944458, -1.927714228630066, -24.746192932128906,\n",
      "          -2.343522548675537, -2.4410769939422607, -1.9734052419662476, -1.927714228630066,\n",
      "          -42.27695083618164, -26.344017028808594, -1.276259422302246, -2.343522548675537,\n",
      "          -3.685330390930176, -24.46055030822754, -11.272283554077148, -2.597764015197754,\n",
      "          -2.578303813934326, -2.946082353591919, -1.977062702178955, -3.5373010635375977,\n",
      "          -2.389592409133911, -2.832310199737549, -2.9286468029022217, -1.276259422302246,\n",
      "          -1.135479211807251, -2.311821222305298, -3.144289970397949, -2.300475835800171,\n",
      "          -2.832310199737549, -2.596219301223755, -2.311821222305298, -40.6142463684082,\n",
      "          -8.945487976074219, -2.57388973236084, -34.133575439453125, -2.300475835800171,\n",
      "          -2.81644344329834, -36.87446975708008, -10.576726913452148, -30.51406478881836,\n",
      "          -2.389592409133911, -0.6847338676452637, -2.81644344329834, -2.57388973236084,\n",
      "          1.77516508102417, -1.9769949913024902, -2.4410910606384277, -2.1288492679595947,\n",
      "          -36.87446975708008, -26.344017028808594, -51.195518493652344, -11.272283554077148,\n",
      "          -0.14541101455688477, -8.945487976074219, -13.988373756408691, -38.11575698852539,\n",
      "          -13.988373756408691, -2.343522548675537, -3.75954532623291, -4.7678351402282715,\n",
      "          -2.81644344329834, -40.6142463684082, -5.817642688751221, -9.623801231384277,\n",
      "          -2.5246975421905518, -38.11575698852539, -2.3673818111419678, -2.946082353591919,\n",
      "          1.77516508102417, -12.777097702026367, -26.344017028808594, -2.329728364944458,\n",
      "          -2.272246837615967, -15.234942436218262, -1.986715316772461, -12.777097702026367,\n",
      "          -1.691193699836731, -4.214771270751953, -2.1288492679595947, -2.895843029022217,\n",
      "          -11.272283554077148, -1.9351129531860352, -3.3312034606933594, -11.272283554077148,\n",
      "          -3.785020589828491, -2.1288492679595947, -2.320448160171509, -3.1533682346343994,\n",
      "          -3.1824049949645996, -0.10062360763549805, -2.312549352645874, -2.3673818111419678,\n",
      "          -27.677404403686523, -2.678253650665283, -4.14689826965332, -3.1533682346343994,\n",
      "          -2.312549352645874, -28.612890243530273, -1.135479211807251, -9.623801231384277,\n",
      "          -5.817642688751221, -23.009357452392578, -1.927714228630066, -2.300475835800171,\n",
      "          -2.4410910606384277, -32.955265045166016, -1.927714228630066, -1.135479211807251,\n",
      "          -2.605522394180298, -2.946082353591919, -42.27695083618164, -53.11589050292969,\n",
      "          -2.343522548675537, -42.27695083618164, -15.832113265991211, -2.57388973236084,\n",
      "          -3.1533682346343994, -9.4075927734375, -1.7219157218933105, -2.895843029022217,\n",
      "          -3.75954532623291, -9.16895580291748, -2.895843029022217, -9.4075927734375,\n",
      "          -3.75954532623291, -9.623801231384277, -28.612890243530273, -2.81644344329834,\n",
      "          -2.9286468029022217, -1.311438798904419, -1.7316410541534424, -49.37401580810547,\n",
      "          -2.343522548675537, -2.312549352645874, -4.14689826965332, -3.3312034606933594,\n",
      "          -12.777097702026367, -5.817642688751221, -9.4075927734375, -1.135479211807251,\n",
      "          -2.946082353591919, -2.4410910606384277, -3.144289970397949, -2.272246837615967,\n",
      "          -58.38572692871094, -27.677404403686523, -58.38572692871094, -2.946082353591919,\n",
      "          -1.9734052419662476, -2.605522394180298, -12.777097702026367, -2.3673818111419678,\n",
      "          -1.5532351732254028, -2.311821222305298, -15.491028785705566, -1.9769949913024902,\n",
      "          -2.5911331176757812, -2.946082353591919, -51.195518493652344, -2.4410910606384277,\n",
      "          -1.276259422302246, -32.955265045166016, -2.5246975421905518, -4.14689826965332,\n",
      "          -2.678253650665283, -32.955265045166016, -2.272246837615967, -49.77021026611328,\n",
      "          -3.785020589828491, -1.7219157218933105, -23.009357452392578, -1.927714228630066,\n",
      "          -80.83019256591797, -3.6408185958862305, -32.955265045166016, -40.6142463684082,\n",
      "          -11.272283554077148, -2.946082353591919, -73.47428131103516, -15.234942436218262,\n",
      "          -3.75954532623291, -15.234942436218262, -1.8868589401245117, -2.343522548675537,\n",
      "          -0.45891237258911133, -1.135479211807251, -34.133575439453125, -2.389592409133911,\n",
      "          -3.75954532623291, -1.691193699836731, -55.56748580932617, -2.578303813934326,\n",
      "          -2.867734432220459, -2.9286468029022217, -3.785020589828491, -32.955265045166016,\n",
      "          -73.47428131103516, -2.5911331176757812, -36.87446975708008, -1.311438798904419,\n",
      "          -2.5246975421905518, -58.38572692871094, -61.502071380615234, -50.07960891723633,\n",
      "          -2.597764015197754, -3.685330390930176, -1.5532351732254028, -61.502071380615234,\n",
      "          -11.272283554077148, -9.16895580291748, -1.8868589401245117, -9.623801231384277,\n",
      "          -3.169973373413086, -2.4410910606384277, -4.7678351402282715, -34.133575439453125,\n",
      "          -1.986715316772461, -1.927714228630066, -36.87446975708008, -24.46055030822754,\n",
      "          -35.1298713684082, -9.16895580291748, -10.576726913452148, -1.7219157218933105,\n",
      "          -2.343522548675537, 1.77516508102417, -0.6847338676452637, -8.945487976074219,\n",
      "          -2.272246837615967, -38.11575698852539, -1.9734052419662476, -3.685330390930176,\n",
      "          -2.320448160171509, -1.9769949913024902, -1.7219157218933105, -1.3226743936538696,\n",
      "          -36.87446975708008, -4.14689826965332, -30.51406478881836, -2.9286468029022217,\n",
      "          -1.311438798904419, -13.988373756408691, -8.945487976074219, -24.746192932128906,\n",
      "          -53.11589050292969, -24.746192932128906, -11.272283554077148, -1.9351129531860352,\n",
      "          -2.5246975421905518, -22.60820770263672, -4.14689826965332, -1.691193699836731,\n",
      "          -38.11575698852539, -12.777097702026367, -2.81644344329834, 1.77516508102417,\n",
      "          -2.946082353591919, -3.6408185958862305, -32.955265045166016, -22.60820770263672,\n",
      "          -3.75954532623291, -1.9734052419662476, -3.785020589828491, -1.8868589401245117,\n",
      "          -2.320448160171509, -3.503541946411133, -3.75954532623291, -1.7219157218933105,\n",
      "          -2.867734432220459, -1.9769949913024902, -2.3673818111419678, -2.389592409133911,\n",
      "          -49.77021026611328, -2.605522394180298, -53.11589050292969, -2.4410769939422607,\n",
      "          -23.009357452392578, -2.596219301223755, -27.677404403686523, -10.576726913452148,\n",
      "          -2.895843029022217, -27.677404403686523, -2.946082353591919, -1.276259422302246,\n",
      "          -40.6142463684082, -55.56748580932617, -4.214771270751953, -1.8868589401245117,\n",
      "          -3.0267162322998047, -11.272283554077148, -26.344017028808594, -4.214771270751953,\n",
      "          -3.3312034606933594, 1.77516508102417, -3.6408185958862305, -3.144289970397949,\n",
      "          -2.4410769939422607, -2.9286468029022217, -3.3312034606933594, -2.832310199737549,\n",
      "          -4.14689826965332, -9.623801231384277, -80.83019256591797, -38.11575698852539,\n",
      "          -2.3673818111419678, -1.8868589401245117, -3.685330390930176, -5.817642688751221,\n",
      "          -15.234942436218262, -58.38572692871094, -8.945487976074219, -32.955265045166016,\n",
      "          -2.57388973236084, -1.8868589401245117, -10.576726913452148, -53.11589050292969,\n",
      "          -2.272246837615967, -73.47428131103516, -2.329728364944458, -2.678253650665283,\n",
      "          -1.691193699836731, -49.37401580810547, -2.312549352645874, -58.38572692871094,\n",
      "          -11.272283554077148, -2.57388973236084, -2.4410910606384277, -2.343522548675537,\n",
      "          -2.596219301223755, -22.60820770263672, -11.272283554077148, -55.56748580932617,\n",
      "          -2.81644344329834, -50.07960891723633, -1.5532351732254028, 1.77516508102417,\n",
      "          -2.832310199737549, -2.1288492679595947, -11.272283554077148, -11.272283554077148,\n",
      "          -2.4410910606384277, -2.678253650665283, -4.14689826965332, -3.0267162322998047,\n",
      "          -2.3673818111419678, -3.169973373413086, -2.3673818111419678, -32.955265045166016,\n",
      "          -2.343522548675537, -26.344017028808594, -2.678253650665283, -1.8868589401245117,\n",
      "          -1.9769949913024902, -3.0267162322998047, -73.47428131103516, -3.144289970397949]\n",
      "    num_agent_steps_sampled: 1024\n",
      "    num_agent_steps_trained: 1024\n",
      "    num_env_steps_sampled: 1024\n",
      "    num_env_steps_trained: 1024\n",
      "    num_target_updates: 2\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 1024\n",
      "  num_agent_steps_trained: 1024\n",
      "  num_env_steps_sampled: 1024\n",
      "  num_env_steps_sampled_this_iter: 1024\n",
      "  num_env_steps_trained: 1024\n",
      "  num_env_steps_trained_this_iter: 1024\n",
      "  num_faulty_episodes: 0\n",
      "  num_healthy_workers: 0\n",
      "  num_recreated_workers: 0\n",
      "  num_steps_trained_this_iter: 1024\n",
      "  perf:\n",
      "    cpu_util_percent: 38.12857142857143\n",
      "    ram_util_percent: 83.80714285714286\n",
      "  pid: 87694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: .nan\n",
      "    episode_media: {}\n",
      "    episode_reward_max: .nan\n",
      "    episode_reward_mean: .nan\n",
      "    episode_reward_min: .nan\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths: []\n",
      "      episode_reward: []\n",
      "    num_faulty_episodes: 0\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf: {}\n",
      "  time_since_restore: 9.428117990493774\n",
      "  time_this_iter_s: 9.428117990493774\n",
      "  time_total_s: 9.428117990493774\n",
      "  timers:\n",
      "    learn_throughput: 7257.673\n",
      "    learn_time_ms: 70.546\n",
      "    load_throughput: 2072860.664\n",
      "    load_time_ms: 0.247\n",
      "    synch_weights_time_ms: 0.022\n",
      "    training_iteration_time_ms: 4711.518\n",
      "  timestamp: 1663189766\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1024\n",
      "  training_iteration: 1\n",
      "  trial_id: 75ee4_00000\n",
      "  warmup_time: 4.627590179443359\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 14:09:27,236\tWARNING worker.py:1829 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 88f3073d3997f9161bc41c389f2f55e8b52fe10a01000000 Worker ID: 134c0cdb96857a86ccc0ad04f2d9638b4aba55845206cec4e38e3de1 Node ID: 4c51b4fd99d01a8f82171f0de6a2fc03c95f7ab3d52fa98843c58b29 Worker IP address: 127.0.0.1 Worker port: 65415 Worker PID: 87710 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n",
      "2022-09-14 14:09:27,239\tINFO tune.py:758 -- Total run time: 23.96 seconds (23.69 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "tuner = tune.Tuner(\n",
    "    DQN,\n",
    "    param_space=dqn_config_offline.to_dict(),\n",
    "    run_config=air.RunConfig(\n",
    "        local_dir=\"./results_notebook/offline_rl/\",\n",
    "        stop={\"training_iteration\": 1},\n",
    "    )\n",
    ")\n",
    "dqn_offline_results = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the offline training results. From the plot below we can see that by running offline RL on randomly collected transitions we can improve over the random policy. This is extremely useful in practical scenarios where our goal is to improve over existing production policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_offline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_offline_results[0].metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['num_recreated_workers', 'episode_reward_max', 'episode_reward_min',\n",
      "       'episode_reward_mean', 'episode_len_mean', 'episodes_this_iter',\n",
      "       'num_faulty_episodes', 'num_healthy_workers', 'num_agent_steps_sampled',\n",
      "       'num_agent_steps_trained', 'num_env_steps_sampled',\n",
      "       'num_env_steps_trained', 'num_env_steps_sampled_this_iter',\n",
      "       'num_env_steps_trained_this_iter', 'timesteps_total',\n",
      "       'num_steps_trained_this_iter', 'agent_timesteps_total', 'done',\n",
      "       'episodes_total', 'training_iteration', 'trial_id', 'experiment_id',\n",
      "       'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid',\n",
      "       'hostname', 'node_ip', 'time_since_restore', 'timesteps_since_restore',\n",
      "       'iterations_since_restore', 'warmup_time',\n",
      "       'evaluation/episode_reward_max', 'evaluation/episode_reward_min',\n",
      "       'evaluation/episode_reward_mean', 'evaluation/episode_len_mean',\n",
      "       'evaluation/episodes_this_iter', 'evaluation/num_faulty_episodes',\n",
      "       'evaluation/num_agent_steps_sampled_this_iter',\n",
      "       'evaluation/num_env_steps_sampled_this_iter',\n",
      "       'evaluation/timesteps_this_iter', 'evaluation/num_healthy_workers',\n",
      "       'evaluation/num_recreated_workers', 'info/num_env_steps_sampled',\n",
      "       'info/num_env_steps_trained', 'info/num_agent_steps_sampled',\n",
      "       'info/num_agent_steps_trained', 'info/last_target_update_ts',\n",
      "       'info/num_target_updates', 'sampler_results/episode_reward_max',\n",
      "       'sampler_results/episode_reward_min',\n",
      "       'sampler_results/episode_reward_mean',\n",
      "       'sampler_results/episode_len_mean',\n",
      "       'sampler_results/episodes_this_iter',\n",
      "       'sampler_results/num_faulty_episodes', 'hist_stats/episode_reward',\n",
      "       'hist_stats/episode_lengths', 'timers/training_iteration_time_ms',\n",
      "       'timers/load_time_ms', 'timers/load_throughput', 'timers/learn_time_ms',\n",
      "       'timers/learn_throughput', 'timers/synch_weights_time_ms',\n",
      "       'counters/num_env_steps_sampled', 'counters/num_env_steps_trained',\n",
      "       'counters/num_agent_steps_sampled', 'counters/num_agent_steps_trained',\n",
      "       'counters/last_target_update_ts', 'counters/num_target_updates',\n",
      "       'perf/cpu_util_percent', 'perf/ram_util_percent',\n",
      "       'evaluation/hist_stats/episode_reward',\n",
      "       'evaluation/hist_stats/episode_lengths',\n",
      "       'evaluation/sampler_perf/mean_raw_obs_processing_ms',\n",
      "       'evaluation/sampler_perf/mean_inference_ms',\n",
      "       'evaluation/sampler_perf/mean_action_processing_ms',\n",
      "       'evaluation/sampler_perf/mean_env_wait_ms',\n",
      "       'evaluation/sampler_perf/mean_env_render_ms',\n",
      "       'sampler_results/hist_stats/episode_reward',\n",
      "       'sampler_results/hist_stats/episode_lengths',\n",
      "       'info/learner/default_policy/td_error',\n",
      "       'info/learner/default_policy/mean_td_error',\n",
      "       'info/learner/default_policy/num_agent_steps_trained',\n",
      "       'info/learner/default_policy/learner_stats/allreduce_latency',\n",
      "       'info/learner/default_policy/learner_stats/grad_gnorm',\n",
      "       'info/learner/default_policy/learner_stats/mean_q',\n",
      "       'info/learner/default_policy/learner_stats/min_q',\n",
      "       'info/learner/default_policy/learner_stats/max_q',\n",
      "       'info/learner/default_policy/learner_stats/cur_lr'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_recreated_workers</th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_faulty_episodes</th>\n",
       "      <th>num_healthy_workers</th>\n",
       "      <th>num_agent_steps_sampled</th>\n",
       "      <th>num_agent_steps_trained</th>\n",
       "      <th>...</th>\n",
       "      <th>sampler_results/hist_stats/episode_lengths</th>\n",
       "      <th>info/learner/default_policy/td_error</th>\n",
       "      <th>info/learner/default_policy/mean_td_error</th>\n",
       "      <th>info/learner/default_policy/num_agent_steps_trained</th>\n",
       "      <th>info/learner/default_policy/learner_stats/allreduce_latency</th>\n",
       "      <th>info/learner/default_policy/learner_stats/grad_gnorm</th>\n",
       "      <th>info/learner/default_policy/learner_stats/mean_q</th>\n",
       "      <th>info/learner/default_policy/learner_stats/min_q</th>\n",
       "      <th>info/learner/default_policy/learner_stats/max_q</th>\n",
       "      <th>info/learner/default_policy/learner_stats/cur_lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-2.3538213e+00 -1.1375945e+00 -1.2462333e+01 ...</td>\n",
       "      <td>-10.580702</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.213455</td>\n",
       "      <td>-4.432943</td>\n",
       "      <td>6.774650</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-40.506775   -61.97426    -38.595753    -3.70...</td>\n",
       "      <td>-11.315735</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.039853</td>\n",
       "      <td>-10.420587</td>\n",
       "      <td>17.475670</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1536</td>\n",
       "      <td>1536</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-31.038172    -3.1823516  -32.29229    -21.26...</td>\n",
       "      <td>-13.161014</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.195285</td>\n",
       "      <td>-3.818083</td>\n",
       "      <td>14.747209</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[  -4.3287826   -19.507774    -47.811214     -...</td>\n",
       "      <td>-13.706473</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.172622</td>\n",
       "      <td>-4.584808</td>\n",
       "      <td>24.536005</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2560</td>\n",
       "      <td>2560</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-4.65406561e+00  1.47419739e+00 -2.03024578e+...</td>\n",
       "      <td>-13.847671</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.783419</td>\n",
       "      <td>-4.468198</td>\n",
       "      <td>37.622391</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>998400</td>\n",
       "      <td>998400</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-1.43014526e+00  7.04738808e+00  1.69252281e+...</td>\n",
       "      <td>-1.033876</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>84.962700</td>\n",
       "      <td>2.396049</td>\n",
       "      <td>177.688889</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>998912</td>\n",
       "      <td>998912</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ -2.5442238   -5.1743317    2.5995522    2.14...</td>\n",
       "      <td>0.221676</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>85.822052</td>\n",
       "      <td>3.665074</td>\n",
       "      <td>178.535477</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>999424</td>\n",
       "      <td>999424</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-5.74981689e-01 -3.20867157e+00  7.30127335e+...</td>\n",
       "      <td>0.515675</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>81.784767</td>\n",
       "      <td>2.501043</td>\n",
       "      <td>181.170700</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>999936</td>\n",
       "      <td>999936</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ 1.62049751e+01  1.76564312e+00  7.05337524e-...</td>\n",
       "      <td>0.951557</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>78.297279</td>\n",
       "      <td>4.202184</td>\n",
       "      <td>178.099579</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1000448</td>\n",
       "      <td>1000448</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ 4.46736383e+00  4.58789062e+00  3.16465378e+...</td>\n",
       "      <td>1.076135</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>85.379669</td>\n",
       "      <td>3.286350</td>\n",
       "      <td>176.398636</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1954 rows Ã 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_recreated_workers  episode_reward_max  episode_reward_min  \\\n",
       "0                         0                 NaN                 NaN   \n",
       "1                         0                 NaN                 NaN   \n",
       "2                         0                 NaN                 NaN   \n",
       "3                         0                 NaN                 NaN   \n",
       "4                         0                 NaN                 NaN   \n",
       "...                     ...                 ...                 ...   \n",
       "1949                      0                 NaN                 NaN   \n",
       "1950                      0                 NaN                 NaN   \n",
       "1951                      0                 NaN                 NaN   \n",
       "1952                      0                 NaN                 NaN   \n",
       "1953                      0                 NaN                 NaN   \n",
       "\n",
       "      episode_reward_mean  episode_len_mean  episodes_this_iter  \\\n",
       "0                     NaN               NaN                   0   \n",
       "1                     NaN               NaN                   0   \n",
       "2                     NaN               NaN                   0   \n",
       "3                     NaN               NaN                   0   \n",
       "4                     NaN               NaN                   0   \n",
       "...                   ...               ...                 ...   \n",
       "1949                  NaN               NaN                   0   \n",
       "1950                  NaN               NaN                   0   \n",
       "1951                  NaN               NaN                   0   \n",
       "1952                  NaN               NaN                   0   \n",
       "1953                  NaN               NaN                   0   \n",
       "\n",
       "      num_faulty_episodes  num_healthy_workers  num_agent_steps_sampled  \\\n",
       "0                       0                    1                      512   \n",
       "1                       0                    1                     1024   \n",
       "2                       0                    1                     1536   \n",
       "3                       0                    1                     2048   \n",
       "4                       0                    1                     2560   \n",
       "...                   ...                  ...                      ...   \n",
       "1949                    0                    1                   998400   \n",
       "1950                    0                    1                   998912   \n",
       "1951                    0                    1                   999424   \n",
       "1952                    0                    1                   999936   \n",
       "1953                    0                    1                  1000448   \n",
       "\n",
       "      num_agent_steps_trained  ...  \\\n",
       "0                         512  ...   \n",
       "1                        1024  ...   \n",
       "2                        1536  ...   \n",
       "3                        2048  ...   \n",
       "4                        2560  ...   \n",
       "...                       ...  ...   \n",
       "1949                   998400  ...   \n",
       "1950                   998912  ...   \n",
       "1951                   999424  ...   \n",
       "1952                   999936  ...   \n",
       "1953                  1000448  ...   \n",
       "\n",
       "      sampler_results/hist_stats/episode_lengths  \\\n",
       "0                                             []   \n",
       "1                                             []   \n",
       "2                                             []   \n",
       "3                                             []   \n",
       "4                                             []   \n",
       "...                                          ...   \n",
       "1949                                          []   \n",
       "1950                                          []   \n",
       "1951                                          []   \n",
       "1952                                          []   \n",
       "1953                                          []   \n",
       "\n",
       "                   info/learner/default_policy/td_error  \\\n",
       "0     [-2.3538213e+00 -1.1375945e+00 -1.2462333e+01 ...   \n",
       "1     [-40.506775   -61.97426    -38.595753    -3.70...   \n",
       "2     [-31.038172    -3.1823516  -32.29229    -21.26...   \n",
       "3     [  -4.3287826   -19.507774    -47.811214     -...   \n",
       "4     [-4.65406561e+00  1.47419739e+00 -2.03024578e+...   \n",
       "...                                                 ...   \n",
       "1949  [-1.43014526e+00  7.04738808e+00  1.69252281e+...   \n",
       "1950  [ -2.5442238   -5.1743317    2.5995522    2.14...   \n",
       "1951  [-5.74981689e-01 -3.20867157e+00  7.30127335e+...   \n",
       "1952  [ 1.62049751e+01  1.76564312e+00  7.05337524e-...   \n",
       "1953  [ 4.46736383e+00  4.58789062e+00  3.16465378e+...   \n",
       "\n",
       "      info/learner/default_policy/mean_td_error  \\\n",
       "0                                    -10.580702   \n",
       "1                                    -11.315735   \n",
       "2                                    -13.161014   \n",
       "3                                    -13.706473   \n",
       "4                                    -13.847671   \n",
       "...                                         ...   \n",
       "1949                                  -1.033876   \n",
       "1950                                   0.221676   \n",
       "1951                                   0.515675   \n",
       "1952                                   0.951557   \n",
       "1953                                   1.076135   \n",
       "\n",
       "      info/learner/default_policy/num_agent_steps_trained  \\\n",
       "0                                                 512.0     \n",
       "1                                                 512.0     \n",
       "2                                                 512.0     \n",
       "3                                                 512.0     \n",
       "4                                                 512.0     \n",
       "...                                                 ...     \n",
       "1949                                              512.0     \n",
       "1950                                              512.0     \n",
       "1951                                              512.0     \n",
       "1952                                              512.0     \n",
       "1953                                              512.0     \n",
       "\n",
       "      info/learner/default_policy/learner_stats/allreduce_latency  \\\n",
       "0                                                   0.0             \n",
       "1                                                   0.0             \n",
       "2                                                   0.0             \n",
       "3                                                   0.0             \n",
       "4                                                   0.0             \n",
       "...                                                 ...             \n",
       "1949                                                0.0             \n",
       "1950                                                0.0             \n",
       "1951                                                0.0             \n",
       "1952                                                0.0             \n",
       "1953                                                0.0             \n",
       "\n",
       "      info/learner/default_policy/learner_stats/grad_gnorm  \\\n",
       "0                                                  40.0      \n",
       "1                                                  40.0      \n",
       "2                                                  40.0      \n",
       "3                                                  40.0      \n",
       "4                                                  40.0      \n",
       "...                                                 ...      \n",
       "1949                                               40.0      \n",
       "1950                                               40.0      \n",
       "1951                                               40.0      \n",
       "1952                                               40.0      \n",
       "1953                                               40.0      \n",
       "\n",
       "      info/learner/default_policy/learner_stats/mean_q  \\\n",
       "0                                             0.213455   \n",
       "1                                             1.039853   \n",
       "2                                             1.195285   \n",
       "3                                             2.172622   \n",
       "4                                             2.783419   \n",
       "...                                                ...   \n",
       "1949                                         84.962700   \n",
       "1950                                         85.822052   \n",
       "1951                                         81.784767   \n",
       "1952                                         78.297279   \n",
       "1953                                         85.379669   \n",
       "\n",
       "      info/learner/default_policy/learner_stats/min_q  \\\n",
       "0                                           -4.432943   \n",
       "1                                          -10.420587   \n",
       "2                                           -3.818083   \n",
       "3                                           -4.584808   \n",
       "4                                           -4.468198   \n",
       "...                                               ...   \n",
       "1949                                         2.396049   \n",
       "1950                                         3.665074   \n",
       "1951                                         2.501043   \n",
       "1952                                         4.202184   \n",
       "1953                                         3.286350   \n",
       "\n",
       "      info/learner/default_policy/learner_stats/max_q  \\\n",
       "0                                            6.774650   \n",
       "1                                           17.475670   \n",
       "2                                           14.747209   \n",
       "3                                           24.536005   \n",
       "4                                           37.622391   \n",
       "...                                               ...   \n",
       "1949                                       177.688889   \n",
       "1950                                       178.535477   \n",
       "1951                                       181.170700   \n",
       "1952                                       178.099579   \n",
       "1953                                       176.398636   \n",
       "\n",
       "      info/learner/default_policy/learner_stats/cur_lr  \n",
       "0                                               0.0003  \n",
       "1                                               0.0003  \n",
       "2                                               0.0003  \n",
       "3                                               0.0003  \n",
       "4                                               0.0003  \n",
       "...                                                ...  \n",
       "1949                                            0.0003  \n",
       "1950                                            0.0003  \n",
       "1951                                            0.0003  \n",
       "1952                                            0.0003  \n",
       "1953                                            0.0003  \n",
       "\n",
       "[1954 rows x 90 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot the results and compare to baselines\n",
    "offline_dqn_df = pd.read_csv(\"saved_runs/dqn_offline/random_data/progress.csv\")\n",
    "print(offline_dqn_df.columns)\n",
    "offline_dqn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Offline RL vs. Baselines training performance')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sns.lineplot(data=offline_dqn_df, x=\"training_iteration\", y=\"evaluation/episode_reward_mean\", label=\"Offline_DQN\")\n",
    "sns.lineplot(data=dqn_df, x=\"training_iteration\", y=\"episode_reward_mean\", label=\"Online_DQN\")\n",
    "sns.lineplot(data=bandit_df, x=\"training_iteration\", y=\"episode_reward_mean\", label=\"Bandits\")\n",
    "plt.axhline(random_baseline, color=\"red\", linestyle='--', label=\"random baseline\")\n",
    "plt.legend()\n",
    "plt.title('Offline RL vs. Baselines training performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=offline_dqn_df, x=\"training_iteration\", y=\"info/learner/default_policy/learner_stats/mean_q\", label=\"q_value\")\n",
    "plt.legend()\n",
    "plt.title('Average Q value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- Bandits converges to a short-sighted solution\n",
    "    -  Optimizes imediate reward. \n",
    "- DQN takes long-term reward into account\n",
    "    -  Achieves a policy better than random.\n",
    "    -  Can become even better than our heuristic based baseline (even_argmin).\n",
    "- Offline RL is a viable option that works when we don't have simulators for training\n",
    "    -  Since it doesn't explore freely it won't perform as good as an online RL method. \n",
    "    -  Its performance is bounded to the quality of the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you!\n",
    "\n",
    "<a href=\"https://docs.google.com/forms/d/1pxsMIPMxTTd2HH6710UOApx_smPDPPO0fpVWYKzvOgI/edit\">Survey</a> - Let us know how useful you have found this tutorial.\n",
    "\n",
    "**We would love to connect with you!**\n",
    "\n",
    "**Twitter** - @anyscalecompute | @raydistributed <br>\n",
    "<b><a href=\"https://github.com/ray-project/ray\">Github</a></b> - ð give us a star!<br>\n",
    "<b><a href=\"https://www.ray.io/community\">Slack</a></b> - [+invitation link](https://docs.google.com/forms/d/e/1FAIpQLSfAcoiLCHOguOm8e7Jnn-JJdZaCxPGjgVCvFijHB5PLaQLeig/viewform)<br>\n",
    "<b><a href=\"https://discuss.ray.io/\">Discuss</a></b> - searchable questions <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d33966b1efccf1b078b90327a99b4ed3697643ca9825566d91b27949ee9bb425"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

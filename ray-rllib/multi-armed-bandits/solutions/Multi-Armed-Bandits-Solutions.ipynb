{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray RLlib - Multi-Armed Bandits - Exercise Solutions\n",
    "\n",
    "© 2019-2020, Anyscale. All Rights Reserved\n",
    "\n",
    "![Anyscale Academy](../../../images/AnyscaleAcademy_Logo_clearbanner_141x100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore a very simple contextual bandit example with 3 arms. We'll run trials using RLlib and [Tune](http://tune.io), Ray's hyperparameter tuning library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time, random\n",
    "from ray import tune\n",
    "from ray.tune.progress_reporter import JupyterNotebookReporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03: Simple Multi-Armed Bandits - Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, set up a function to generate the rewards for n arms. To keep it somewhat simple, just use the original rewards for -1 in `SimpleBandit`, `[-10,0,10]` and repeat it as much as necessary, and optionally offset the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleContextualBandit2 (gym.Env):\n",
    "    def __init__ (self, config=None):\n",
    "        self.action_space = Discrete(3)     # 3 arms\n",
    "        self.observation_space = Box(low=-1., high=1., shape=(2, ), dtype=np.float64)  # Random (x,y), where x,y from -1 to 1\n",
    "        self.current_context = None\n",
    "        self.rewards_for_context = {\n",
    "            -1.: [-10, 0, 10],\n",
    "            1.: [10, 0, -10],\n",
    "        }\n",
    "\n",
    "    def reset (self):\n",
    "        self.current_context = random.choice([-1., 1.])\n",
    "        return np.array([-self.current_context, self.current_context])\n",
    "\n",
    "    def step (self, action):\n",
    "        reward = self.rewards_for_context[self.current_context][action]\n",
    "        self.current_context = random.choice([-1.,1.])\n",
    "        return (np.array([-self.current_context, self.current_context]), reward, True,\n",
    "                {\n",
    "                    \"regret\": 10 - reward\n",
    "                })\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'SimpleContextualBandit2(action_space={self.action_space}, observation_space={self.observation_space}, current_context={self.current_context}, rewards per context={self.rewards_for_context})'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Initial observation = [-1.  1.], bandit = SimpleContextualBandit2(action_space=Discrete(3), observation_space=Box(2,), current_context=1.0, rewards per context={-1.0: [-10, 0, 10], 1.0: [10, 0, -10]})'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit = SimpleContextualBandit2()\n",
    "observation = bandit.reset()\n",
    "f'Initial observation = {observation}, bandit = {repr(bandit)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = {\n",
    "    \"training_iteration\": 200,\n",
    "    \"timesteps_total\": 100000,\n",
    "    \"episode_reward_mean\": 10.0,\n",
    "}\n",
    "\n",
    "config = {\n",
    "    \"env\": SimpleContextualBandit2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-08 13:58:52,018\tINFO resource_spec.py:212 -- Starting Ray with 4.44 GiB memory available for workers and up to 2.22 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-06-08 13:58:52,344\tINFO services.py:1170 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8266\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                  </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_SimpleContextualBandit2_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13285)\u001b[0m 2020-06-08 13:59:00,475\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=13285)\u001b[0m 2020-06-08 13:59:00,478\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=13285)\u001b[0m 2020-06-08 13:59:00,486\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=13285)\u001b[0m 2020-06-08 13:59:00,486\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "Result for contrib_LinUCB_SimpleContextualBandit2_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_13-59-00\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 10.0\n",
      "  episode_reward_mean: 9.9\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: 91d770ae39234ca1bfd77582362df8dc\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.246\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.246\n",
      "    learner:\n",
      "      cumulative_regret: 10.0\n",
      "      update_latency: 0.0001289844512939453\n",
      "    num_steps_sampled: 100\n",
      "    num_steps_trained: 100\n",
      "    opt_peak_throughput: 4070.954\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 1463.827\n",
      "    sample_time_ms: 0.683\n",
      "    update_time_ms: 0.001\n",
      "  iterations_since_restore: 1\n",
      "  learner:\n",
      "    cumulative_regret: 10.0\n",
      "    update_latency: 0.0001289844512939453\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 100\n",
      "  num_steps_trained: 100\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 4070.954\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 33.7\n",
      "    ram_util_percent: 58.1\n",
      "  pid: 13285\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 1463.827\n",
      "  sample_time_ms: 0.683\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.026233125441145186\n",
      "    mean_inference_ms: 0.39734698758266956\n",
      "    mean_processing_ms: 0.2800993400044961\n",
      "  time_since_restore: 0.10699796676635742\n",
      "  time_this_iter_s: 0.10699796676635742\n",
      "  time_total_s: 0.10699796676635742\n",
      "  timestamp: 1591649940\n",
      "  timesteps_since_restore: 100\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 100\n",
      "  training_iteration: 1\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.001\n",
      "  \n",
      "Result for contrib_LinUCB_SimpleContextualBandit2_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_13-59-00\n",
      "  done: true\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 10.0\n",
      "  episode_reward_mean: 10.0\n",
      "  episode_reward_min: 10.0\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 200\n",
      "  experiment_id: 91d770ae39234ca1bfd77582362df8dc\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.285\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.285\n",
      "    learner:\n",
      "      cumulative_regret: 10.0\n",
      "      update_latency: 0.0002300739288330078\n",
      "    num_steps_sampled: 200\n",
      "    num_steps_trained: 200\n",
      "    opt_peak_throughput: 3514.289\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 1118.72\n",
      "    sample_time_ms: 0.894\n",
      "    update_time_ms: 0.001\n",
      "  iterations_since_restore: 2\n",
      "  learner:\n",
      "    cumulative_regret: 10.0\n",
      "    update_latency: 0.0002300739288330078\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 200\n",
      "  num_steps_trained: 200\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 3514.289\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 13285\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 1118.72\n",
      "  sample_time_ms: 0.894\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.028240146921641788\n",
      "    mean_inference_ms: 0.4231502760702105\n",
      "    mean_processing_ms: 0.28765142260499255\n",
      "  time_since_restore: 0.2399148941040039\n",
      "  time_this_iter_s: 0.13291692733764648\n",
      "  time_total_s: 0.2399148941040039\n",
      "  timestamp: 1591649940\n",
      "  timesteps_since_restore: 200\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 200\n",
      "  training_iteration: 2\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.3/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                  </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_SimpleContextualBandit2_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        0.239915</td><td style=\"text-align: right;\"> 200</td><td style=\"text-align: right;\">      10</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trials took 8.765048027038574 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "analysis = tune.run(\"contrib/LinUCB\", config=config, stop=stop, \n",
    "                    progress_reporter=JupyterNotebookReporter(overwrite=False),  # This is the default, actually.\n",
    "                    verbose=2)  # Change to 0 or 1 to reduce the output.\n",
    "\n",
    "print(\"The trials took\", time.time() - start_time, \"seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_steps_trained</th>\n",
       "      <th>num_steps_sampled</th>\n",
       "      <th>sample_time_ms</th>\n",
       "      <th>grad_time_ms</th>\n",
       "      <th>update_time_ms</th>\n",
       "      <th>...</th>\n",
       "      <th>info/sample_peak_throughput</th>\n",
       "      <th>info/opt_samples</th>\n",
       "      <th>learner/cumulative_regret</th>\n",
       "      <th>learner/update_latency</th>\n",
       "      <th>perf/cpu_util_percent</th>\n",
       "      <th>perf/ram_util_percent</th>\n",
       "      <th>info/learner/cumulative_regret</th>\n",
       "      <th>info/learner/update_latency</th>\n",
       "      <th>config/env</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>1118.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00023</td>\n",
       "      <td>&lt;class '__main__.SimpleContextualBandit2'&gt;</td>\n",
       "      <td>/Users/deanwampler/ray_results/contrib/LinUCB/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       "0                10.0                10.0                 10.0   \n",
       "\n",
       "   episode_len_mean  episodes_this_iter  num_steps_trained  num_steps_sampled  \\\n",
       "0               1.0                 100                200                200   \n",
       "\n",
       "   sample_time_ms  grad_time_ms  update_time_ms  ...  \\\n",
       "0           0.894         0.285           0.001  ...   \n",
       "\n",
       "   info/sample_peak_throughput  info/opt_samples  learner/cumulative_regret  \\\n",
       "0                      1118.72               1.0                       10.0   \n",
       "\n",
       "   learner/update_latency  perf/cpu_util_percent  perf/ram_util_percent  \\\n",
       "0                 0.00023                    NaN                    NaN   \n",
       "\n",
       "   info/learner/cumulative_regret  info/learner/update_latency  \\\n",
       "0                            10.0                      0.00023   \n",
       "\n",
       "                                   config/env  \\\n",
       "0  <class '__main__.SimpleContextualBandit2'>   \n",
       "\n",
       "                                              logdir  \n",
       "0  /Users/deanwampler/ray_results/contrib/LinUCB/...  \n",
       "\n",
       "[1 rows x 54 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = analysis.dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It trains just as easily as the original implementation that didn't switch contexts between steps. Is this surprising? Probably not, because the relationship between the reward and the context remains linear, so what LinUCB learns for one context is correct for the second context, too. Also, _Tune_ runs many episodes, so it studies both contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03: Simple Multi-Armed Bandits - Exercise 2\n",
    "\n",
    "Recall the `rewards_for_context` we used:\n",
    "\n",
    "```python\n",
    "self.rewards_for_context = {\n",
    "    -1.: [-10, 0, 10],\n",
    "    1.: [10, 0, -10],\n",
    "}\n",
    "```\n",
    "\n",
    "We said that Linear Upper Confidence Bound assumes a linear dependency between the expected reward of an action and its context. It models the representation space using a set of linear predictors.\n",
    "\n",
    "Change the values for the rewards as follows, so they no longer have the same simple linear relationship:\n",
    "\n",
    "```python\n",
    "self.rewards_for_context = {\n",
    "    -1.: [-10, 10, 0],\n",
    "    1.: [0, 10, -10],\n",
    "}\n",
    "```\n",
    "\n",
    "Also remove the change made for exercise 1, the line `self.current_context = random.choice([-1.,1.])` in the `step` method.\n",
    "\n",
    "Run the training again and look at the results for the reward mean in TensorBoard. How successful was the training? How smooth is the plot for `episode_reward_mean`? How many steps were taken in the training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleContextualBanditNonlinear (gym.Env):\n",
    "    def __init__ (self, config=None):\n",
    "        self.action_space = Discrete(3)     # 3 arms\n",
    "        self.observation_space = Box(low=-1., high=1., shape=(2, ), dtype=np.float64)  # Random (x,y), where x,y from -1 to 1\n",
    "        self.current_context = None\n",
    "        self.rewards_for_context = {   # Changed here:\n",
    "            -1.: [-10, 10, 0],\n",
    "            1.: [0, 10, -10],\n",
    "        }\n",
    "\n",
    "    def reset (self):\n",
    "        self.current_context = random.choice([-1., 1.])\n",
    "        return np.array([-self.current_context, self.current_context])\n",
    "\n",
    "    def step (self, action):\n",
    "        reward = self.rewards_for_context[self.current_context][action]\n",
    "        return (np.array([-self.current_context, self.current_context]), reward, True,\n",
    "                {\n",
    "                    \"regret\": 10 - reward\n",
    "                })\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'SimpleContextualBanditNonlinear(action_space={self.action_space}, observation_space={self.observation_space}, current_context={self.current_context}, rewards per context={self.rewards_for_context})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Initial observation = [ 1. -1.], bandit = SimpleContextualBanditNonlinear(action_space=Discrete(3), observation_space=Box(2,), current_context=-1.0, rewards per context={-1.0: [-10, 10, 0], 1.0: [0, 10, -10]})'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit = SimpleContextualBanditNonlinear()\n",
    "observation = bandit.reset()\n",
    "f'Initial observation = {observation}, bandit = {repr(bandit)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation = [ 1. -1.], reward =    0, done = True , info = {'regret': 10}\n",
      "observation = [ 1. -1.], reward =   10, done = True , info = {'regret': 0}\n",
      "observation = [ 1. -1.], reward =   10, done = True , info = {'regret': 0}\n",
      "observation = [ 1. -1.], reward =   10, done = True , info = {'regret': 0}\n",
      "observation = [ 1. -1.], reward =  -10, done = True , info = {'regret': 20}\n",
      "observation = [ 1. -1.], reward =    0, done = True , info = {'regret': 10}\n",
      "observation = [ 1. -1.], reward =  -10, done = True , info = {'regret': 20}\n",
      "observation = [ 1. -1.], reward =    0, done = True , info = {'regret': 10}\n",
      "observation = [ 1. -1.], reward =    0, done = True , info = {'regret': 10}\n",
      "observation = [ 1. -1.], reward =   10, done = True , info = {'regret': 0}\n"
     ]
    }
   ],
   "source": [
    "print(f'current_context = {bandit.current_context}')\n",
    "for i in range(10):\n",
    "    action = bandit.action_space.sample()\n",
    "    observation, reward, done, info = bandit.step(action)\n",
    "    print(f'observation = {observation}, action = {action}, reward = {reward:4d}, done = {str(done):5s}, info = {info}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `stop` defined above is unchanged.\n",
    "\n",
    "config = {\n",
    "    \"env\": SimpleContextualBanditNonlinear,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                          </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_SimpleContextualBanditNonlinear_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13289)\u001b[0m 2020-06-08 14:01:10,502\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=13289)\u001b[0m 2020-06-08 14:01:10,505\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=13289)\u001b[0m 2020-06-08 14:01:10,512\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=13289)\u001b[0m 2020-06-08 14:01:10,512\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "Result for contrib_LinUCB_SimpleContextualBanditNonlinear_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_14-01-10\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 10.0\n",
      "  episode_reward_mean: 5.4\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: 1ff2fc0067bd458aaaabe106df9751e1\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.255\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.255\n",
      "    learner:\n",
      "      cumulative_regret: 460.0\n",
      "      update_latency: 0.00013589859008789062\n",
      "    num_steps_sampled: 100\n",
      "    num_steps_trained: 100\n",
      "    opt_peak_throughput: 3925.781\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 1370.419\n",
      "    sample_time_ms: 0.73\n",
      "    update_time_ms: 0.001\n",
      "  iterations_since_restore: 1\n",
      "  learner:\n",
      "    cumulative_regret: 460.0\n",
      "    update_latency: 0.00013589859008789062\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 100\n",
      "  num_steps_trained: 100\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 3925.781\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 21.2\n",
      "    ram_util_percent: 66.1\n",
      "  pid: 13289\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 1370.419\n",
      "  sample_time_ms: 0.73\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.026556524899926506\n",
      "    mean_inference_ms: 0.40512509865335905\n",
      "    mean_processing_ms: 0.3051167667502224\n",
      "  time_since_restore: 0.11366605758666992\n",
      "  time_this_iter_s: 0.11366605758666992\n",
      "  time_total_s: 0.11366605758666992\n",
      "  timestamp: 1591650070\n",
      "  timesteps_since_restore: 100\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 100\n",
      "  training_iteration: 1\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                          </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_SimpleContextualBanditNonlinear_00000</td><td>RUNNING </td><td>192.168.1.149:13289</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         1.88235</td><td style=\"text-align: right;\">1700</td><td style=\"text-align: right;\">     5.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for contrib_LinUCB_SimpleContextualBanditNonlinear_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_14-01-15\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 10.0\n",
      "  episode_reward_mean: 5.0\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 4400\n",
      "  experiment_id: 1ff2fc0067bd458aaaabe106df9751e1\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.306\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.306\n",
      "    learner:\n",
      "      cumulative_regret: 21780.0\n",
      "      update_latency: 0.0001728534698486328\n",
      "    num_steps_sampled: 4400\n",
      "    num_steps_trained: 4400\n",
      "    opt_peak_throughput: 3264.304\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 1297.462\n",
      "    sample_time_ms: 0.771\n",
      "    update_time_ms: 0.001\n",
      "  iterations_since_restore: 44\n",
      "  learner:\n",
      "    cumulative_regret: 21780.0\n",
      "    update_latency: 0.0001728534698486328\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 4400\n",
      "  num_steps_trained: 4400\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 3264.304\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 13289\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 1297.462\n",
      "  sample_time_ms: 0.771\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.026051820990335556\n",
      "    mean_inference_ms: 0.3962962092716188\n",
      "    mean_processing_ms: 0.27339584690363555\n",
      "  time_since_restore: 4.819295883178711\n",
      "  time_this_iter_s: 0.11878013610839844\n",
      "  time_total_s: 4.819295883178711\n",
      "  timestamp: 1591650075\n",
      "  timesteps_since_restore: 4400\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 4400\n",
      "  training_iteration: 44\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                          </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_SimpleContextualBanditNonlinear_00000</td><td>RUNNING </td><td>192.168.1.149:13289</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">          6.5581</td><td style=\"text-align: right;\">6000</td><td style=\"text-align: right;\">     4.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for contrib_LinUCB_SimpleContextualBanditNonlinear_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_14-01-20\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 10.0\n",
      "  episode_reward_mean: 4.8\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 8700\n",
      "  experiment_id: 1ff2fc0067bd458aaaabe106df9751e1\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.321\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.321\n",
      "    learner:\n",
      "      cumulative_regret: 42800.0\n",
      "      update_latency: 0.000209808349609375\n",
      "    num_steps_sampled: 8700\n",
      "    num_steps_trained: 8700\n",
      "    opt_peak_throughput: 3111.501\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 1437.045\n",
      "    sample_time_ms: 0.696\n",
      "    update_time_ms: 0.001\n",
      "  iterations_since_restore: 87\n",
      "  learner:\n",
      "    cumulative_regret: 42800.0\n",
      "    update_latency: 0.000209808349609375\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 8700\n",
      "  num_steps_trained: 8700\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 3111.501\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 13289\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 1437.045\n",
      "  sample_time_ms: 0.696\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.025820860902737816\n",
      "    mean_inference_ms: 0.3948773670273257\n",
      "    mean_processing_ms: 0.27368307360259037\n",
      "  time_since_restore: 9.56510329246521\n",
      "  time_this_iter_s: 0.11979913711547852\n",
      "  time_total_s: 9.56510329246521\n",
      "  timestamp: 1591650080\n",
      "  timesteps_since_restore: 8700\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 8700\n",
      "  training_iteration: 87\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                          </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_SimpleContextualBanditNonlinear_00000</td><td>RUNNING </td><td>192.168.1.149:13289</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         11.2425</td><td style=\"text-align: right;\">10200</td><td style=\"text-align: right;\">     5.1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for contrib_LinUCB_SimpleContextualBanditNonlinear_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_14-01-25\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 10.0\n",
      "  episode_reward_mean: 5.4\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 12800\n",
      "  experiment_id: 1ff2fc0067bd458aaaabe106df9751e1\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.406\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.406\n",
      "    learner:\n",
      "      cumulative_regret: 63530.0\n",
      "      update_latency: 0.00024175643920898438\n",
      "    num_steps_sampled: 12800\n",
      "    num_steps_trained: 12800\n",
      "    opt_peak_throughput: 2461.59\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 1320.625\n",
      "    sample_time_ms: 0.757\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 128\n",
      "  learner:\n",
      "    cumulative_regret: 63530.0\n",
      "    update_latency: 0.00024175643920898438\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 12800\n",
      "  num_steps_trained: 12800\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 2461.59\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 13289\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 1320.625\n",
      "  sample_time_ms: 0.757\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.025643193063377624\n",
      "    mean_inference_ms: 0.39395564478381084\n",
      "    mean_processing_ms: 0.2722754887087011\n",
      "  time_since_restore: 14.228108882904053\n",
      "  time_this_iter_s: 0.11670994758605957\n",
      "  time_total_s: 14.228108882904053\n",
      "  timestamp: 1591650085\n",
      "  timesteps_since_restore: 12800\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 12800\n",
      "  training_iteration: 128\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.002\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                          </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_SimpleContextualBanditNonlinear_00000</td><td>RUNNING </td><td>192.168.1.149:13289</td><td style=\"text-align: right;\">   142</td><td style=\"text-align: right;\">          15.898</td><td style=\"text-align: right;\">14200</td><td style=\"text-align: right;\">     5.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for contrib_LinUCB_SimpleContextualBanditNonlinear_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_14-01-30\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 10.0\n",
      "  episode_reward_mean: 4.9\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 16700\n",
      "  experiment_id: 1ff2fc0067bd458aaaabe106df9751e1\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.38\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.38\n",
      "    learner:\n",
      "      cumulative_regret: 83060.0\n",
      "      update_latency: 0.00027298927307128906\n",
      "    num_steps_sampled: 16700\n",
      "    num_steps_trained: 16700\n",
      "    opt_peak_throughput: 2634.613\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 1390.085\n",
      "    sample_time_ms: 0.719\n",
      "    update_time_ms: 0.001\n",
      "  iterations_since_restore: 167\n",
      "  learner:\n",
      "    cumulative_regret: 83060.0\n",
      "    update_latency: 0.00027298927307128906\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 16700\n",
      "  num_steps_trained: 16700\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 2634.613\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 13289\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 1390.085\n",
      "  sample_time_ms: 0.719\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.025714716435363848\n",
      "    mean_inference_ms: 0.39547637910673294\n",
      "    mean_processing_ms: 0.2726013592906816\n",
      "  time_since_restore: 18.9075710773468\n",
      "  time_this_iter_s: 0.1164698600769043\n",
      "  time_total_s: 18.9075710773468\n",
      "  timestamp: 1591650090\n",
      "  timesteps_since_restore: 16700\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 16700\n",
      "  training_iteration: 167\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                          </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_SimpleContextualBanditNonlinear_00000</td><td>RUNNING </td><td>192.168.1.149:13289</td><td style=\"text-align: right;\">   181</td><td style=\"text-align: right;\">         20.6512</td><td style=\"text-align: right;\">18100</td><td style=\"text-align: right;\">     5.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for contrib_LinUCB_SimpleContextualBanditNonlinear_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_14-01-35\n",
      "  done: true\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 10.0\n",
      "  episode_reward_mean: 5.7\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 20000\n",
      "  experiment_id: 1ff2fc0067bd458aaaabe106df9751e1\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.445\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.445\n",
      "    learner:\n",
      "      cumulative_regret: 99230.0\n",
      "      update_latency: 0.0003299713134765625\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 20000\n",
      "    opt_peak_throughput: 2245.946\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 1244.97\n",
      "    sample_time_ms: 0.803\n",
      "    update_time_ms: 0.001\n",
      "  iterations_since_restore: 200\n",
      "  learner:\n",
      "    cumulative_regret: 99230.0\n",
      "    update_latency: 0.0003299713134765625\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 20000\n",
      "  num_steps_trained: 20000\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 2245.946\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 22.1\n",
      "    ram_util_percent: 66.1\n",
      "  pid: 13289\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 1244.97\n",
      "  sample_time_ms: 0.803\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.02568786450966758\n",
      "    mean_inference_ms: 0.3963143674977202\n",
      "    mean_processing_ms: 0.2727537749737574\n",
      "  time_since_restore: 22.98465323448181\n",
      "  time_this_iter_s: 0.12446212768554688\n",
      "  time_total_s: 22.98465323448181\n",
      "  timestamp: 1591650095\n",
      "  timesteps_since_restore: 20000\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 200\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                          </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_SimpleContextualBanditNonlinear_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   200</td><td style=\"text-align: right;\">         22.9847</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">     5.7</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trials took 27.73778510093689 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "analysis = tune.run(\"contrib/LinUCB\", config=config, stop=stop, \n",
    "                    progress_reporter=JupyterNotebookReporter(overwrite=False),  # This is the default, actually.\n",
    "                    verbose=2)  # Change to 0 or 1 to reduce the output.\n",
    "\n",
    "print(\"The trials took\", time.time() - start_time, \"seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_steps_trained</th>\n",
       "      <th>num_steps_sampled</th>\n",
       "      <th>sample_time_ms</th>\n",
       "      <th>grad_time_ms</th>\n",
       "      <th>update_time_ms</th>\n",
       "      <th>...</th>\n",
       "      <th>info/sample_peak_throughput</th>\n",
       "      <th>info/opt_samples</th>\n",
       "      <th>learner/cumulative_regret</th>\n",
       "      <th>learner/update_latency</th>\n",
       "      <th>perf/cpu_util_percent</th>\n",
       "      <th>perf/ram_util_percent</th>\n",
       "      <th>info/learner/cumulative_regret</th>\n",
       "      <th>info/learner/update_latency</th>\n",
       "      <th>config/env</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>1244.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99230.0</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>22.1</td>\n",
       "      <td>66.1</td>\n",
       "      <td>99230.0</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>&lt;class '__main__.SimpleContextualBanditNonline...</td>\n",
       "      <td>/Users/deanwampler/ray_results/contrib/LinUCB/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       "0                10.0                 0.0                  5.7   \n",
       "\n",
       "   episode_len_mean  episodes_this_iter  num_steps_trained  num_steps_sampled  \\\n",
       "0               1.0                 100              20000              20000   \n",
       "\n",
       "   sample_time_ms  grad_time_ms  update_time_ms  ...  \\\n",
       "0           0.803         0.445           0.001  ...   \n",
       "\n",
       "   info/sample_peak_throughput  info/opt_samples  learner/cumulative_regret  \\\n",
       "0                      1244.97               1.0                    99230.0   \n",
       "\n",
       "   learner/update_latency  perf/cpu_util_percent  perf/ram_util_percent  \\\n",
       "0                 0.00033                   22.1                   66.1   \n",
       "\n",
       "   info/learner/cumulative_regret  info/learner/update_latency  \\\n",
       "0                         99230.0                      0.00033   \n",
       "\n",
       "                                          config/env  \\\n",
       "0  <class '__main__.SimpleContextualBanditNonline...   \n",
       "\n",
       "                                              logdir  \n",
       "0  /Users/deanwampler/ray_results/contrib/LinUCB/...  \n",
       "\n",
       "[1 rows x 54 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = analysis.dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It ran the maximum of 20,000 steps and the best it does is about 4.8, not 10.0. the `episode_reward_mean` is chaotic:\n",
    "\n",
    "![Nonlinear model with LinUCB](../../../images/rllib/TensorBoard2.png).\n",
    "\n",
    "Because LinUCB expcts a linear relationship between the context and each reward, it's not surprising that it fails to converge to the desired reward mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03: Simple Multi-Armed Bandits - Exercise 3\n",
    "\n",
    "We briefly discussed another algorithm for selecting the next action, _Thompson Sampling_, in the [previous lesson](../02-Exploration-vs-Exploitation-Strategies.ipynb). Repeat exercises 1 and 2 using linear version, called _Linear Thompson Sampling_ ([RLlib documentation](https://docs.ray.io/en/latest/rllib-algorithms.html?highlight=greedy#linear-thompson-sampling-contrib-lints)). To make this change, look at this code we used above:\n",
    "\n",
    "```python\n",
    "analysis = tune.run(\"contrib/LinUCB\", config=config, stop=stop, \n",
    "                    progress_reporter=JupyterNotebookReporter(overwrite=False),  # This is the default, actually.\n",
    "                    verbose=2)  # Change to 0 or 1 to reduce the output.\n",
    "```\n",
    "\n",
    "Change `contrib/LinUCB` to `contrib/LinTS`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bandit = SimpleContextualBandit2()\n",
    "observation = bandit.reset()\n",
    "\n",
    "# `stop` defined above is unchanged.\n",
    "\n",
    "config = {\n",
    "    \"env\": SimpleContextualBandit2,\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "analysis = tune.run(\"contrib/LinTS\", config=config, stop=stop, \n",
    "                    progress_reporter=JupyterNotebookReporter(overwrite=False),  # This is the default, actually.\n",
    "                    verbose=2)  # Change to 0 or 1 to reduce the output.\n",
    "\n",
    "print(\"The trials took\", time.time() - start_time, \"seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinTS<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                 </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinTS_SimpleContextualBandit2_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13291)\u001b[0m 2020-06-08 14:02:51,052\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=13291)\u001b[0m 2020-06-08 14:02:51,056\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=13291)\u001b[0m 2020-06-08 14:02:51,063\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=13291)\u001b[0m 2020-06-08 14:02:51,063\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "Result for contrib_LinTS_SimpleContextualBandit2_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_14-02-51\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 10.0\n",
      "  episode_reward_mean: 9.9\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: 481647293a464969a3d73baab12f468b\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.25\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.25\n",
      "    learner:\n",
      "      cumulative_regret: 10.0\n",
      "      update_latency: 0.00013208389282226562\n",
      "    num_steps_sampled: 100\n",
      "    num_steps_trained: 100\n",
      "    opt_peak_throughput: 3997.24\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 1419.632\n",
      "    sample_time_ms: 0.704\n",
      "    update_time_ms: 0.001\n",
      "  iterations_since_restore: 1\n",
      "  learner:\n",
      "    cumulative_regret: 10.0\n",
      "    update_latency: 0.00013208389282226562\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 100\n",
      "  num_steps_trained: 100\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 3997.24\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 20.7\n",
      "    ram_util_percent: 66.2\n",
      "  pid: 13291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 1419.632\n",
      "  sample_time_ms: 0.704\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.027198602657506954\n",
      "    mean_inference_ms: 0.392460587001083\n",
      "    mean_processing_ms: 0.2814212647995147\n",
      "  time_since_restore: 0.10828185081481934\n",
      "  time_this_iter_s: 0.10828185081481934\n",
      "  time_total_s: 0.10828185081481934\n",
      "  timestamp: 1591650171\n",
      "  timesteps_since_restore: 100\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 100\n",
      "  training_iteration: 1\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.001\n",
      "  \n",
      "Result for contrib_LinTS_SimpleContextualBandit2_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_14-02-51\n",
      "  done: true\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 10.0\n",
      "  episode_reward_mean: 10.0\n",
      "  episode_reward_min: 10.0\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 200\n",
      "  experiment_id: 481647293a464969a3d73baab12f468b\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.232\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.232\n",
      "    learner:\n",
      "      cumulative_regret: 10.0\n",
      "      update_latency: 0.00013113021850585938\n",
      "    num_steps_sampled: 200\n",
      "    num_steps_trained: 200\n",
      "    opt_peak_throughput: 4304.057\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 1366.312\n",
      "    sample_time_ms: 0.732\n",
      "    update_time_ms: 0.001\n",
      "  iterations_since_restore: 2\n",
      "  learner:\n",
      "    cumulative_regret: 10.0\n",
      "    update_latency: 0.00013113021850585938\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 200\n",
      "  num_steps_trained: 200\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 4304.057\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 13291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 1366.312\n",
      "  sample_time_ms: 0.732\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.027585385450676302\n",
      "    mean_inference_ms: 0.3913362227862153\n",
      "    mean_processing_ms: 0.2777339214116187\n",
      "  time_since_restore: 0.21352815628051758\n",
      "  time_this_iter_s: 0.10524630546569824\n",
      "  time_total_s: 0.21352815628051758\n",
      "  timestamp: 1591650171\n",
      "  timesteps_since_restore: 200\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 200\n",
      "  training_iteration: 2\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinTS<br>Number of trials: 1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                 </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinTS_SimpleContextualBandit2_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        0.213528</td><td style=\"text-align: right;\"> 200</td><td style=\"text-align: right;\">      10</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trials took 3.132218837738037 seconds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_steps_trained</th>\n",
       "      <th>num_steps_sampled</th>\n",
       "      <th>sample_time_ms</th>\n",
       "      <th>grad_time_ms</th>\n",
       "      <th>update_time_ms</th>\n",
       "      <th>...</th>\n",
       "      <th>info/sample_peak_throughput</th>\n",
       "      <th>info/opt_samples</th>\n",
       "      <th>learner/cumulative_regret</th>\n",
       "      <th>learner/update_latency</th>\n",
       "      <th>perf/cpu_util_percent</th>\n",
       "      <th>perf/ram_util_percent</th>\n",
       "      <th>info/learner/cumulative_regret</th>\n",
       "      <th>info/learner/update_latency</th>\n",
       "      <th>config/env</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>1366.312</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>&lt;class '__main__.SimpleContextualBandit2'&gt;</td>\n",
       "      <td>/Users/deanwampler/ray_results/contrib/LinTS/c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       "0                10.0                10.0                 10.0   \n",
       "\n",
       "   episode_len_mean  episodes_this_iter  num_steps_trained  num_steps_sampled  \\\n",
       "0               1.0                 100                200                200   \n",
       "\n",
       "   sample_time_ms  grad_time_ms  update_time_ms  ...  \\\n",
       "0           0.732         0.232           0.001  ...   \n",
       "\n",
       "   info/sample_peak_throughput  info/opt_samples  learner/cumulative_regret  \\\n",
       "0                     1366.312               1.0                       10.0   \n",
       "\n",
       "   learner/update_latency  perf/cpu_util_percent  perf/ram_util_percent  \\\n",
       "0                0.000131                    NaN                    NaN   \n",
       "\n",
       "   info/learner/cumulative_regret  info/learner/update_latency  \\\n",
       "0                            10.0                     0.000131   \n",
       "\n",
       "                                   config/env  \\\n",
       "0  <class '__main__.SimpleContextualBandit2'>   \n",
       "\n",
       "                                              logdir  \n",
       "0  /Users/deanwampler/ray_results/contrib/LinTS/c...  \n",
       "\n",
       "[1 rows x 54 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = analysis.dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the training only takes 200 steps and converge to the desired reward mean of `10.0`.\n",
    "\n",
    "Now let's try the nonlinear bandit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandit = SimpleContextualBanditNonlinear()\n",
    "observation = bandit.reset()\n",
    "\n",
    "# `stop` defined above is unchanged.\n",
    "\n",
    "config = {\n",
    "    \"env\": SimpleContextualBanditNonlinear,\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "analysis = tune.run(\"contrib/LinTS\", config=config, stop=stop, \n",
    "                    progress_reporter=JupyterNotebookReporter(overwrite=False),  # This is the default, actually.\n",
    "                    verbose=2)  # Change to 0 or 1 to reduce the output.\n",
    "\n",
    "print(\"The trials took\", time.time() - start_time, \"seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_steps_trained</th>\n",
       "      <th>num_steps_sampled</th>\n",
       "      <th>sample_time_ms</th>\n",
       "      <th>grad_time_ms</th>\n",
       "      <th>update_time_ms</th>\n",
       "      <th>...</th>\n",
       "      <th>info/sample_peak_throughput</th>\n",
       "      <th>info/opt_samples</th>\n",
       "      <th>learner/cumulative_regret</th>\n",
       "      <th>learner/update_latency</th>\n",
       "      <th>perf/cpu_util_percent</th>\n",
       "      <th>perf/ram_util_percent</th>\n",
       "      <th>info/learner/cumulative_regret</th>\n",
       "      <th>info/learner/update_latency</th>\n",
       "      <th>config/env</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.003</td>\n",
       "      <td>...</td>\n",
       "      <td>1350.692</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100750.0</td>\n",
       "      <td>0.00042</td>\n",
       "      <td>16.9</td>\n",
       "      <td>68.7</td>\n",
       "      <td>100750.0</td>\n",
       "      <td>0.00042</td>\n",
       "      <td>&lt;class '__main__.SimpleContextualBanditNonline...</td>\n",
       "      <td>/Users/deanwampler/ray_results/contrib/LinTS/c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       "0                10.0               -10.0                  4.5   \n",
       "\n",
       "   episode_len_mean  episodes_this_iter  num_steps_trained  num_steps_sampled  \\\n",
       "0               1.0                 100              20000              20000   \n",
       "\n",
       "   sample_time_ms  grad_time_ms  update_time_ms  ...  \\\n",
       "0            0.74         0.446           0.003  ...   \n",
       "\n",
       "   info/sample_peak_throughput  info/opt_samples  learner/cumulative_regret  \\\n",
       "0                     1350.692               1.0                   100750.0   \n",
       "\n",
       "   learner/update_latency  perf/cpu_util_percent  perf/ram_util_percent  \\\n",
       "0                 0.00042                   16.9                   68.7   \n",
       "\n",
       "   info/learner/cumulative_regret  info/learner/update_latency  \\\n",
       "0                        100750.0                      0.00042   \n",
       "\n",
       "                                          config/env  \\\n",
       "0  <class '__main__.SimpleContextualBanditNonline...   \n",
       "\n",
       "                                              logdir  \n",
       "0  /Users/deanwampler/ray_results/contrib/LinTS/c...  \n",
       "\n",
       "[1 rows x 54 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = analysis.dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This run with Thompson sampling yields similar results with the reward mean about 4.5 and failure chaotic results over 20000 steps as shown in the TensorBoard graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04: Linear Upper Confidence Bound - Exercise 1\n",
    "\n",
    "Change the `training_iterations` from 20 to 50. Does the characteristic behavior of cumulative regret change at higher steps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.rllib.contrib.bandits.agents.lin_ucb import UCB_CONFIG\n",
    "from ray.rllib.contrib.bandits.envs import ParametricItemRecoEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training for 50 time steps\n"
     ]
    }
   ],
   "source": [
    "UCB_CONFIG[\"env\"] = ParametricItemRecoEnv\n",
    "\n",
    "# Actual training_iterations will be 50 * timesteps_per_iteration (100 by default) = 5,000\n",
    "training_iterations = 50\n",
    "\n",
    "print(\"Running training for %s time steps\" % training_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 5 (4 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00001</td><td>PENDING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00002</td><td>PENDING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00003</td><td>PENDING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00004</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=80282)\u001b[0m 2020-06-10 14:39:59,214\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=80282)\u001b[0m 2020-06-10 14:39:59,221\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=80282)\u001b[0m /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=80282)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=80284)\u001b[0m 2020-06-10 14:39:59,229\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=80284)\u001b[0m 2020-06-10 14:39:59,235\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=80284)\u001b[0m /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=80284)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=80285)\u001b[0m 2020-06-10 14:39:59,216\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=80285)\u001b[0m 2020-06-10 14:39:59,221\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=80285)\u001b[0m /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=80285)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=80283)\u001b[0m 2020-06-10 14:39:59,218\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=80283)\u001b[0m 2020-06-10 14:39:59,224\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=80283)\u001b[0m /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=80283)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=80288)\u001b[0m 2020-06-10 14:39:59,211\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=80288)\u001b[0m 2020-06-10 14:39:59,216\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=80288)\u001b[0m /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=80288)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=80282)\u001b[0m 2020-06-10 14:39:59,288\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=80282)\u001b[0m 2020-06-10 14:39:59,288\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=80285)\u001b[0m 2020-06-10 14:39:59,289\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=80285)\u001b[0m 2020-06-10 14:39:59,289\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=80283)\u001b[0m 2020-06-10 14:39:59,288\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=80283)\u001b[0m 2020-06-10 14:39:59,289\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=80288)\u001b[0m 2020-06-10 14:39:59,283\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=80288)\u001b[0m 2020-06-10 14:39:59,283\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=80284)\u001b[0m 2020-06-10 14:39:59,312\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=80284)\u001b[0m 2020-06-10 14:39:59,313\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-39-59\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.8989514652605076\n",
      "  episode_reward_mean: 0.8556404383478644\n",
      "  episode_reward_min: 0.7136448401530575\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: c2df8311aa46490ebcd32e5bcdd6a560\n",
      "  experiment_tag: '1'\n",
      "  grad_time_ms: 0.505\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.505\n",
      "    learner:\n",
      "      cumulative_regret: 3.153487377220074\n",
      "      update_latency: 0.0002696514129638672\n",
      "    num_steps_sampled: 100\n",
      "    num_steps_trained: 100\n",
      "    opt_peak_throughput: 1980.127\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 720.857\n",
      "    sample_time_ms: 1.387\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 1\n",
      "  learner:\n",
      "    cumulative_regret: 3.153487377220074\n",
      "    update_latency: 0.0002696514129638672\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 100\n",
      "  num_steps_trained: 100\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1980.127\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 41.2\n",
      "    ram_util_percent: 71.7\n",
      "  pid: 80285\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 720.857\n",
      "  sample_time_ms: 1.387\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.22497507605222192\n",
      "    mean_inference_ms: 0.8537816529226775\n",
      "    mean_processing_ms: 0.7838777976460978\n",
      "  time_since_restore: 0.2732231616973877\n",
      "  time_this_iter_s: 0.2732231616973877\n",
      "  time_total_s: 0.2732231616973877\n",
      "  timestamp: 1591825199\n",
      "  timesteps_since_restore: 100\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 100\n",
      "  training_iteration: 1\n",
      "  trial_id: '00001'\n",
      "  update_time_ms: 0.002\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 5 (5 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00000</td><td>RUNNING </td><td>                   </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00001</td><td>RUNNING </td><td>192.168.1.149:80285</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.273223</td><td style=\"text-align: right;\"> 100</td><td style=\"text-align: right;\"> 0.85564</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00002</td><td>RUNNING </td><td>                   </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00003</td><td>RUNNING </td><td>                   </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00004</td><td>RUNNING </td><td>                   </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-39-59\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9130084799930833\n",
      "  episode_reward_mean: 0.85169154951746\n",
      "  episode_reward_min: 0.6321990038185692\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: a696831a2d8f458aa1154d8dc84e8e7f\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.513\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.513\n",
      "    learner:\n",
      "      cumulative_regret: 3.75249494289159\n",
      "      update_latency: 0.00026988983154296875\n",
      "    num_steps_sampled: 100\n",
      "    num_steps_trained: 100\n",
      "    opt_peak_throughput: 1950.658\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 693.354\n",
      "    sample_time_ms: 1.442\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 1\n",
      "  learner:\n",
      "    cumulative_regret: 3.75249494289159\n",
      "    update_latency: 0.00026988983154296875\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 100\n",
      "  num_steps_trained: 100\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1950.658\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 41.2\n",
      "    ram_util_percent: 71.7\n",
      "  pid: 80283\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 693.354\n",
      "  sample_time_ms: 1.442\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.20805443867598428\n",
      "    mean_inference_ms: 0.820018277309909\n",
      "    mean_processing_ms: 0.8403900826331409\n",
      "  time_since_restore: 0.27815699577331543\n",
      "  time_this_iter_s: 0.27815699577331543\n",
      "  time_total_s: 0.27815699577331543\n",
      "  timestamp: 1591825199\n",
      "  timesteps_since_restore: 100\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 100\n",
      "  training_iteration: 1\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00003:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-39-59\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9321029404414258\n",
      "  episode_reward_mean: 0.851282641275108\n",
      "  episode_reward_min: 0.552502632098615\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: dcf572c1339a48efb3221cfde5907b73\n",
      "  experiment_tag: '3'\n",
      "  grad_time_ms: 0.544\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.544\n",
      "    learner:\n",
      "      cumulative_regret: 3.0936020522633565\n",
      "      update_latency: 0.0003190040588378906\n",
      "    num_steps_sampled: 100\n",
      "    num_steps_trained: 100\n",
      "    opt_peak_throughput: 1839.446\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 686.848\n",
      "    sample_time_ms: 1.456\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 1\n",
      "  learner:\n",
      "    cumulative_regret: 3.0936020522633565\n",
      "    update_latency: 0.0003190040588378906\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 100\n",
      "  num_steps_trained: 100\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1839.446\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 41.2\n",
      "    ram_util_percent: 71.7\n",
      "  pid: 80288\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 686.848\n",
      "  sample_time_ms: 1.456\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.21049055722680432\n",
      "    mean_inference_ms: 0.8782915549703165\n",
      "    mean_processing_ms: 0.8474812649264192\n",
      "  time_since_restore: 0.28823018074035645\n",
      "  time_this_iter_s: 0.28823018074035645\n",
      "  time_total_s: 0.28823018074035645\n",
      "  timestamp: 1591825199\n",
      "  timesteps_since_restore: 100\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 100\n",
      "  training_iteration: 1\n",
      "  trial_id: '00003'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00004:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-39-59\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.8777501761402411\n",
      "  episode_reward_mean: 0.8116217712794851\n",
      "  episode_reward_min: 0.5394192400704426\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: 143155dd06b94fa2a5a1cd9ab939ba8b\n",
      "  experiment_tag: '4'\n",
      "  grad_time_ms: 0.448\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.448\n",
      "    learner:\n",
      "      cumulative_regret: 3.737993665890806\n",
      "      update_latency: 0.0002338886260986328\n",
      "    num_steps_sampled: 100\n",
      "    num_steps_trained: 100\n",
      "    opt_peak_throughput: 2230.064\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 792.5\n",
      "    sample_time_ms: 1.262\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 1\n",
      "  learner:\n",
      "    cumulative_regret: 3.737993665890806\n",
      "    update_latency: 0.0002338886260986328\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 100\n",
      "  num_steps_trained: 100\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 2230.064\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 41.3\n",
      "    ram_util_percent: 71.7\n",
      "  pid: 80282\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 792.5\n",
      "  sample_time_ms: 1.262\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.20022675542548157\n",
      "    mean_inference_ms: 0.8525659542272587\n",
      "    mean_processing_ms: 0.785669477859346\n",
      "  time_since_restore: 0.27759480476379395\n",
      "  time_this_iter_s: 0.27759480476379395\n",
      "  time_total_s: 0.27759480476379395\n",
      "  timestamp: 1591825199\n",
      "  timesteps_since_restore: 100\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 100\n",
      "  training_iteration: 1\n",
      "  trial_id: '00004'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00002:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-39-59\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9525972607474534\n",
      "  episode_reward_mean: 0.8739010634451754\n",
      "  episode_reward_min: 0.6870326190536842\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: 30cdd44713174e5382cc8ef5e82ef19e\n",
      "  experiment_tag: '2'\n",
      "  grad_time_ms: 0.523\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.523\n",
      "    learner:\n",
      "      cumulative_regret: 3.8179310410023506\n",
      "      update_latency: 0.00030112266540527344\n",
      "    num_steps_sampled: 100\n",
      "    num_steps_trained: 100\n",
      "    opt_peak_throughput: 1912.587\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 673.275\n",
      "    sample_time_ms: 1.485\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 1\n",
      "  learner:\n",
      "    cumulative_regret: 3.8179310410023506\n",
      "    update_latency: 0.00030112266540527344\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 100\n",
      "  num_steps_trained: 100\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1912.587\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 41.3\n",
      "    ram_util_percent: 71.7\n",
      "  pid: 80284\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 673.275\n",
      "  sample_time_ms: 1.485\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.19822026243304264\n",
      "    mean_inference_ms: 0.689943238060073\n",
      "    mean_processing_ms: 0.7404006353699337\n",
      "  time_since_restore: 0.25630903244018555\n",
      "  time_this_iter_s: 0.25630903244018555\n",
      "  time_total_s: 0.25630903244018555\n",
      "  timestamp: 1591825199\n",
      "  timesteps_since_restore: 100\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 100\n",
      "  training_iteration: 1\n",
      "  trial_id: '00002'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00003:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-40-04\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9321029404414258\n",
      "  episode_reward_mean: 0.8866066724396856\n",
      "  episode_reward_min: 0.7882203929094757\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 1600\n",
      "  experiment_id: dcf572c1339a48efb3221cfde5907b73\n",
      "  experiment_tag: '3'\n",
      "  grad_time_ms: 0.698\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.698\n",
      "    learner:\n",
      "      cumulative_regret: 4.111900930345845\n",
      "      update_latency: 0.00034618377685546875\n",
      "    num_steps_sampled: 1600\n",
      "    num_steps_trained: 1600\n",
      "    opt_peak_throughput: 1431.845\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 670.445\n",
      "    sample_time_ms: 1.492\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 16\n",
      "  learner:\n",
      "    cumulative_regret: 4.111900930345845\n",
      "    update_latency: 0.00034618377685546875\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 1600\n",
      "  num_steps_trained: 1600\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1431.845\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 80288\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 670.445\n",
      "  sample_time_ms: 1.492\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.22994407186800062\n",
      "    mean_inference_ms: 0.8109588313296318\n",
      "    mean_processing_ms: 0.9624673603922781\n",
      "  time_since_restore: 4.977951526641846\n",
      "  time_this_iter_s: 0.22200918197631836\n",
      "  time_total_s: 4.977951526641846\n",
      "  timestamp: 1591825204\n",
      "  timesteps_since_restore: 1600\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 1600\n",
      "  training_iteration: 16\n",
      "  trial_id: '00003'\n",
      "  update_time_ms: 0.002\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 5 (5 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00000</td><td>RUNNING </td><td>192.168.1.149:80283</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         4.96707</td><td style=\"text-align: right;\">1500</td><td style=\"text-align: right;\">0.888318</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00001</td><td>RUNNING </td><td>192.168.1.149:80285</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         4.95175</td><td style=\"text-align: right;\">1500</td><td style=\"text-align: right;\">0.887565</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00002</td><td>RUNNING </td><td>192.168.1.149:80284</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         4.88446</td><td style=\"text-align: right;\">1500</td><td style=\"text-align: right;\">0.909507</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00003</td><td>RUNNING </td><td>192.168.1.149:80288</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         4.97795</td><td style=\"text-align: right;\">1600</td><td style=\"text-align: right;\">0.886607</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00004</td><td>RUNNING </td><td>192.168.1.149:80282</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         4.8785 </td><td style=\"text-align: right;\">1500</td><td style=\"text-align: right;\">0.85026 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-40-04\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.8989514652605076\n",
      "  episode_reward_mean: 0.8875141480598222\n",
      "  episode_reward_min: 0.8489871972592722\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 1600\n",
      "  experiment_id: c2df8311aa46490ebcd32e5bcdd6a560\n",
      "  experiment_tag: '1'\n",
      "  grad_time_ms: 0.801\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.801\n",
      "    learner:\n",
      "      cumulative_regret: 6.35025204543502\n",
      "      update_latency: 0.0005362033843994141\n",
      "    num_steps_sampled: 1600\n",
      "    num_steps_trained: 1600\n",
      "    opt_peak_throughput: 1247.785\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 602.517\n",
      "    sample_time_ms: 1.66\n",
      "    update_time_ms: 0.003\n",
      "  iterations_since_restore: 16\n",
      "  learner:\n",
      "    cumulative_regret: 6.35025204543502\n",
      "    update_latency: 0.0005362033843994141\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 1600\n",
      "  num_steps_trained: 1600\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1247.785\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 80285\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 602.517\n",
      "  sample_time_ms: 1.66\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.24001602825710447\n",
      "    mean_inference_ms: 0.9021741162978583\n",
      "    mean_processing_ms: 0.8564506151912957\n",
      "  time_since_restore: 5.157718896865845\n",
      "  time_this_iter_s: 0.2059650421142578\n",
      "  time_total_s: 5.157718896865845\n",
      "  timestamp: 1591825204\n",
      "  timesteps_since_restore: 1600\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 1600\n",
      "  training_iteration: 16\n",
      "  trial_id: '00001'\n",
      "  update_time_ms: 0.003\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00002:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-40-04\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9525972607474534\n",
      "  episode_reward_mean: 0.9031543396450704\n",
      "  episode_reward_min: 0.8399945365560937\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 1600\n",
      "  experiment_id: 30cdd44713174e5382cc8ef5e82ef19e\n",
      "  experiment_tag: '2'\n",
      "  grad_time_ms: 0.675\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.675\n",
      "    learner:\n",
      "      cumulative_regret: 6.046954066167421\n",
      "      update_latency: 0.0005469322204589844\n",
      "    num_steps_sampled: 1600\n",
      "    num_steps_trained: 1600\n",
      "    opt_peak_throughput: 1481.353\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 595.148\n",
      "    sample_time_ms: 1.68\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 16\n",
      "  learner:\n",
      "    cumulative_regret: 6.046954066167421\n",
      "    update_latency: 0.0005469322204589844\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 1600\n",
      "  num_steps_trained: 1600\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1481.353\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 80284\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 595.148\n",
      "  sample_time_ms: 1.68\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.22040911572639238\n",
      "    mean_inference_ms: 0.8510337033769175\n",
      "    mean_processing_ms: 0.9373401865819185\n",
      "  time_since_restore: 5.102633953094482\n",
      "  time_this_iter_s: 0.21817803382873535\n",
      "  time_total_s: 5.102633953094482\n",
      "  timestamp: 1591825204\n",
      "  timesteps_since_restore: 1600\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 1600\n",
      "  training_iteration: 16\n",
      "  trial_id: '00002'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00004:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-40-04\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.8777501761402411\n",
      "  episode_reward_mean: 0.8500895353232013\n",
      "  episode_reward_min: 0.7606959960591636\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 1600\n",
      "  experiment_id: 143155dd06b94fa2a5a1cd9ab939ba8b\n",
      "  experiment_tag: '4'\n",
      "  grad_time_ms: 0.756\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.756\n",
      "    learner:\n",
      "      cumulative_regret: 5.502817355243203\n",
      "      update_latency: 0.0005211830139160156\n",
      "    num_steps_sampled: 1600\n",
      "    num_steps_trained: 1600\n",
      "    opt_peak_throughput: 1322.749\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 645.923\n",
      "    sample_time_ms: 1.548\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 16\n",
      "  learner:\n",
      "    cumulative_regret: 5.502817355243203\n",
      "    update_latency: 0.0005211830139160156\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 1600\n",
      "  num_steps_trained: 1600\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1322.749\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 80282\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 645.923\n",
      "  sample_time_ms: 1.548\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.23117130953844167\n",
      "    mean_inference_ms: 0.8654411251585157\n",
      "    mean_processing_ms: 0.8800534588481987\n",
      "  time_since_restore: 5.104334831237793\n",
      "  time_this_iter_s: 0.22583699226379395\n",
      "  time_total_s: 5.104334831237793\n",
      "  timestamp: 1591825204\n",
      "  timesteps_since_restore: 1600\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 1600\n",
      "  training_iteration: 16\n",
      "  trial_id: '00004'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-40-04\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9130084799930833\n",
      "  episode_reward_mean: 0.8845531145474481\n",
      "  episode_reward_min: 0.8283102401581812\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 1600\n",
      "  experiment_id: a696831a2d8f458aa1154d8dc84e8e7f\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.653\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.653\n",
      "    learner:\n",
      "      cumulative_regret: 5.723229363906896\n",
      "      update_latency: 0.000377655029296875\n",
      "    num_steps_sampled: 1600\n",
      "    num_steps_trained: 1600\n",
      "    opt_peak_throughput: 1530.656\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 717.245\n",
      "    sample_time_ms: 1.394\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 16\n",
      "  learner:\n",
      "    cumulative_regret: 5.723229363906896\n",
      "    update_latency: 0.000377655029296875\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 1600\n",
      "  num_steps_trained: 1600\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1530.656\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 80283\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 717.245\n",
      "  sample_time_ms: 1.394\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.23751553708802603\n",
      "    mean_inference_ms: 0.8745604496609783\n",
      "    mean_processing_ms: 0.9537563705206067\n",
      "  time_since_restore: 5.19525146484375\n",
      "  time_this_iter_s: 0.22818398475646973\n",
      "  time_total_s: 5.19525146484375\n",
      "  timestamp: 1591825204\n",
      "  timesteps_since_restore: 1600\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 1600\n",
      "  training_iteration: 16\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.002\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 5 (5 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00000</td><td>RUNNING </td><td>192.168.1.149:80283</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         9.71592</td><td style=\"text-align: right;\">3300</td><td style=\"text-align: right;\">0.888259</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00001</td><td>RUNNING </td><td>192.168.1.149:80285</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         9.88724</td><td style=\"text-align: right;\">3400</td><td style=\"text-align: right;\">0.889061</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00002</td><td>RUNNING </td><td>192.168.1.149:80284</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         9.51818</td><td style=\"text-align: right;\">3300</td><td style=\"text-align: right;\">0.905144</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00003</td><td>RUNNING </td><td>192.168.1.149:80288</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         9.65986</td><td style=\"text-align: right;\">3400</td><td style=\"text-align: right;\">0.891363</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00004</td><td>RUNNING </td><td>192.168.1.149:80282</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         9.65147</td><td style=\"text-align: right;\">3300</td><td style=\"text-align: right;\">0.848303</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00004:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-40-09\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.8777501761402411\n",
      "  episode_reward_mean: 0.8497868334009115\n",
      "  episode_reward_min: 0.7606959960591636\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 3400\n",
      "  experiment_id: 143155dd06b94fa2a5a1cd9ab939ba8b\n",
      "  experiment_tag: '4'\n",
      "  grad_time_ms: 0.996\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.996\n",
      "    learner:\n",
      "      cumulative_regret: 5.793794073964872\n",
      "      update_latency: 0.0009129047393798828\n",
      "    num_steps_sampled: 3400\n",
      "    num_steps_trained: 3400\n",
      "    opt_peak_throughput: 1004.215\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 659.192\n",
      "    sample_time_ms: 1.517\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 34\n",
      "  learner:\n",
      "    cumulative_regret: 5.793794073964872\n",
      "    update_latency: 0.0009129047393798828\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 3400\n",
      "  num_steps_trained: 3400\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1004.215\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 80282\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 659.192\n",
      "  sample_time_ms: 1.517\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.19816691929436683\n",
      "    mean_inference_ms: 0.7881346396648407\n",
      "    mean_processing_ms: 0.7801665098868341\n",
      "  time_since_restore: 9.887753963470459\n",
      "  time_this_iter_s: 0.2362821102142334\n",
      "  time_total_s: 9.887753963470459\n",
      "  timestamp: 1591825209\n",
      "  timesteps_since_restore: 3400\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 3400\n",
      "  training_iteration: 34\n",
      "  trial_id: '00004'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-40-09\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9130084799930833\n",
      "  episode_reward_mean: 0.8871785768649368\n",
      "  episode_reward_min: 0.8011682424403331\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 3400\n",
      "  experiment_id: a696831a2d8f458aa1154d8dc84e8e7f\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.883\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.883\n",
      "    learner:\n",
      "      cumulative_regret: 6.105727435079917\n",
      "      update_latency: 0.0008380413055419922\n",
      "    num_steps_sampled: 3400\n",
      "    num_steps_trained: 3400\n",
      "    opt_peak_throughput: 1132.219\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 656.9\n",
      "    sample_time_ms: 1.522\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 34\n",
      "  learner:\n",
      "    cumulative_regret: 6.105727435079917\n",
      "    update_latency: 0.0008380413055419922\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 3400\n",
      "  num_steps_trained: 3400\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1132.219\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 80283\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 656.9\n",
      "  sample_time_ms: 1.522\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.20401395793803753\n",
      "    mean_inference_ms: 0.7351439548078547\n",
      "    mean_processing_ms: 0.7995673748578299\n",
      "  time_since_restore: 9.948009729385376\n",
      "  time_this_iter_s: 0.23209309577941895\n",
      "  time_total_s: 9.948009729385376\n",
      "  timestamp: 1591825209\n",
      "  timesteps_since_restore: 3400\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 3400\n",
      "  training_iteration: 34\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00003:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-40-09\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9321029404414258\n",
      "  episode_reward_mean: 0.8943439481409959\n",
      "  episode_reward_min: 0.8062676326587939\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 3500\n",
      "  experiment_id: dcf572c1339a48efb3221cfde5907b73\n",
      "  experiment_tag: '3'\n",
      "  grad_time_ms: 0.946\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.946\n",
      "    learner:\n",
      "      cumulative_regret: 4.316561169595664\n",
      "      update_latency: 0.0005538463592529297\n",
      "    num_steps_sampled: 3500\n",
      "    num_steps_trained: 3500\n",
      "    opt_peak_throughput: 1056.713\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 741.226\n",
      "    sample_time_ms: 1.349\n",
      "    update_time_ms: 0.003\n",
      "  iterations_since_restore: 35\n",
      "  learner:\n",
      "    cumulative_regret: 4.316561169595664\n",
      "    update_latency: 0.0005538463592529297\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 3500\n",
      "  num_steps_trained: 3500\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1056.713\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 70.5\n",
      "    ram_util_percent: 70.2\n",
      "  pid: 80288\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 741.226\n",
      "  sample_time_ms: 1.349\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.1956991589569903\n",
      "    mean_inference_ms: 0.7279174595483883\n",
      "    mean_processing_ms: 0.7815411417050485\n",
      "  time_since_restore: 9.893676280975342\n",
      "  time_this_iter_s: 0.23381686210632324\n",
      "  time_total_s: 9.893676280975342\n",
      "  timestamp: 1591825209\n",
      "  timesteps_since_restore: 3500\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 3500\n",
      "  training_iteration: 35\n",
      "  trial_id: '00003'\n",
      "  update_time_ms: 0.003\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-40-09\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.8989514652605076\n",
      "  episode_reward_mean: 0.8891120375592091\n",
      "  episode_reward_min: 0.846045095122079\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 3500\n",
      "  experiment_id: c2df8311aa46490ebcd32e5bcdd6a560\n",
      "  experiment_tag: '1'\n",
      "  grad_time_ms: 1.05\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 1.05\n",
      "    learner:\n",
      "      cumulative_regret: 7.148378146491512\n",
      "      update_latency: 0.0008172988891601562\n",
      "    num_steps_sampled: 3500\n",
      "    num_steps_trained: 3500\n",
      "    opt_peak_throughput: 951.953\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 655.995\n",
      "    sample_time_ms: 1.524\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 35\n",
      "  learner:\n",
      "    cumulative_regret: 7.148378146491512\n",
      "    update_latency: 0.0008172988891601562\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 3500\n",
      "  num_steps_trained: 3500\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 951.953\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 70.0\n",
      "    ram_util_percent: 70.2\n",
      "  pid: 80285\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 655.995\n",
      "  sample_time_ms: 1.524\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.20208640699214986\n",
      "    mean_inference_ms: 0.7696971659046073\n",
      "    mean_processing_ms: 0.7511853695051972\n",
      "  time_since_restore: 10.136258363723755\n",
      "  time_this_iter_s: 0.24901413917541504\n",
      "  time_total_s: 10.136258363723755\n",
      "  timestamp: 1591825209\n",
      "  timesteps_since_restore: 3500\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 3500\n",
      "  training_iteration: 35\n",
      "  trial_id: '00001'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00002:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-40-09\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9525972607474534\n",
      "  episode_reward_mean: 0.902578976734047\n",
      "  episode_reward_min: 0.8366066088955019\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 3500\n",
      "  experiment_id: 30cdd44713174e5382cc8ef5e82ef19e\n",
      "  experiment_tag: '2'\n",
      "  grad_time_ms: 0.883\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.883\n",
      "    learner:\n",
      "      cumulative_regret: 6.616342960768677\n",
      "      update_latency: 0.0008647441864013672\n",
      "    num_steps_sampled: 3500\n",
      "    num_steps_trained: 3500\n",
      "    opt_peak_throughput: 1133.044\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 658.705\n",
      "    sample_time_ms: 1.518\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 35\n",
      "  learner:\n",
      "    cumulative_regret: 6.616342960768677\n",
      "    update_latency: 0.0008647441864013672\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 3500\n",
      "  num_steps_trained: 3500\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1133.044\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 70.1\n",
      "    ram_util_percent: 70.2\n",
      "  pid: 80284\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 658.705\n",
      "  sample_time_ms: 1.518\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.19578428412804907\n",
      "    mean_inference_ms: 0.739643758312357\n",
      "    mean_processing_ms: 0.7685765781527892\n",
      "  time_since_restore: 10.003650188446045\n",
      "  time_this_iter_s: 0.24297523498535156\n",
      "  time_total_s: 10.003650188446045\n",
      "  timestamp: 1591825209\n",
      "  timesteps_since_restore: 3500\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 3500\n",
      "  training_iteration: 35\n",
      "  trial_id: '00002'\n",
      "  update_time_ms: 0.002\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-10 14:40:13,016\tWARNING util.py:137 -- The `process_trial` operation took 2.227809190750122 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00004:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-40-14\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.8777501761402411\n",
      "  episode_reward_mean: 0.8552289931757145\n",
      "  episode_reward_min: 0.7807767063805695\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 4400\n",
      "  experiment_id: 143155dd06b94fa2a5a1cd9ab939ba8b\n",
      "  experiment_tag: '4'\n",
      "  grad_time_ms: 1.035\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 1.035\n",
      "    learner:\n",
      "      cumulative_regret: 5.938656220595568\n",
      "      update_latency: 0.0010323524475097656\n",
      "    num_steps_sampled: 4400\n",
      "    num_steps_trained: 4400\n",
      "    opt_peak_throughput: 966.385\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 706.73\n",
      "    sample_time_ms: 1.415\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 44\n",
      "  learner:\n",
      "    cumulative_regret: 5.938656220595568\n",
      "    update_latency: 0.0010323524475097656\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 4400\n",
      "  num_steps_trained: 4400\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 966.385\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 71.6\n",
      "    ram_util_percent: 73.9\n",
      "  pid: 80282\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 706.73\n",
      "  sample_time_ms: 1.415\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.19297391765363056\n",
      "    mean_inference_ms: 0.7557811533367323\n",
      "    mean_processing_ms: 0.7395840211229904\n",
      "  time_since_restore: 12.635028600692749\n",
      "  time_this_iter_s: 0.3603332042694092\n",
      "  time_total_s: 12.635028600692749\n",
      "  timestamp: 1591825214\n",
      "  timesteps_since_restore: 4400\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 4400\n",
      "  training_iteration: 44\n",
      "  trial_id: '00004'\n",
      "  update_time_ms: 0.002\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 5 (5 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00000</td><td>RUNNING </td><td>192.168.1.149:80283</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         12.396 </td><td style=\"text-align: right;\">4300</td><td style=\"text-align: right;\">0.886025</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00001</td><td>RUNNING </td><td>192.168.1.149:80285</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         12.458 </td><td style=\"text-align: right;\">4300</td><td style=\"text-align: right;\">0.886222</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00002</td><td>RUNNING </td><td>192.168.1.149:80284</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         12.3439</td><td style=\"text-align: right;\">4300</td><td style=\"text-align: right;\">0.901075</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00003</td><td>RUNNING </td><td>192.168.1.149:80288</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         12.0727</td><td style=\"text-align: right;\">4300</td><td style=\"text-align: right;\">0.882945</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00004</td><td>RUNNING </td><td>192.168.1.149:80282</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         12.635 </td><td style=\"text-align: right;\">4400</td><td style=\"text-align: right;\">0.855229</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-40-14\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9130084799930833\n",
      "  episode_reward_mean: 0.8845187990388982\n",
      "  episode_reward_min: 0.8283102401581812\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 4400\n",
      "  experiment_id: a696831a2d8f458aa1154d8dc84e8e7f\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 1.146\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 1.146\n",
      "    learner:\n",
      "      cumulative_regret: 6.195141434894597\n",
      "      update_latency: 0.0009942054748535156\n",
      "    num_steps_sampled: 4400\n",
      "    num_steps_trained: 4400\n",
      "    opt_peak_throughput: 872.632\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 619.808\n",
      "    sample_time_ms: 1.613\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 44\n",
      "  learner:\n",
      "    cumulative_regret: 6.195141434894597\n",
      "    update_latency: 0.0009942054748535156\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 4400\n",
      "  num_steps_trained: 4400\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 872.632\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 71.6\n",
      "    ram_util_percent: 73.9\n",
      "  pid: 80283\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 619.808\n",
      "  sample_time_ms: 1.613\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.19810189444540413\n",
      "    mean_inference_ms: 0.7164100169377062\n",
      "    mean_processing_ms: 0.763650700006396\n",
      "  time_since_restore: 12.835845232009888\n",
      "  time_this_iter_s: 0.4398190975189209\n",
      "  time_total_s: 12.835845232009888\n",
      "  timestamp: 1591825214\n",
      "  timesteps_since_restore: 4400\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 4400\n",
      "  training_iteration: 44\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00003:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-40-14\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9321029404414258\n",
      "  episode_reward_mean: 0.8876026137716289\n",
      "  episode_reward_min: 0.7915503993139652\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 4400\n",
      "  experiment_id: dcf572c1339a48efb3221cfde5907b73\n",
      "  experiment_tag: '3'\n",
      "  grad_time_ms: 1.164\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 1.164\n",
      "    learner:\n",
      "      cumulative_regret: 4.3836872460566045\n",
      "      update_latency: 0.001239776611328125\n",
      "    num_steps_sampled: 4400\n",
      "    num_steps_trained: 4400\n",
      "    opt_peak_throughput: 859.066\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 724.342\n",
      "    sample_time_ms: 1.381\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 44\n",
      "  learner:\n",
      "    cumulative_regret: 4.3836872460566045\n",
      "    update_latency: 0.001239776611328125\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 4400\n",
      "  num_steps_trained: 4400\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 859.066\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 71.6\n",
      "    ram_util_percent: 73.9\n",
      "  pid: 80288\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 724.342\n",
      "  sample_time_ms: 1.381\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.2016622460557504\n",
      "    mean_inference_ms: 0.7160545831050584\n",
      "    mean_processing_ms: 0.7548955753970433\n",
      "  time_since_restore: 12.547756671905518\n",
      "  time_this_iter_s: 0.4750950336456299\n",
      "  time_total_s: 12.547756671905518\n",
      "  timestamp: 1591825214\n",
      "  timesteps_since_restore: 4400\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 4400\n",
      "  training_iteration: 44\n",
      "  trial_id: '00003'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-40-14\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.8989514652605076\n",
      "  episode_reward_mean: 0.884904711575987\n",
      "  episode_reward_min: 0.8489871972592722\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 4400\n",
      "  experiment_id: c2df8311aa46490ebcd32e5bcdd6a560\n",
      "  experiment_tag: '1'\n",
      "  grad_time_ms: 1.075\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 1.075\n",
      "    learner:\n",
      "      cumulative_regret: 7.4206238565080085\n",
      "      update_latency: 0.0005619525909423828\n",
      "    num_steps_sampled: 4400\n",
      "    num_steps_trained: 4400\n",
      "    opt_peak_throughput: 929.918\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 648.741\n",
      "    sample_time_ms: 1.541\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 44\n",
      "  learner:\n",
      "    cumulative_regret: 7.4206238565080085\n",
      "    update_latency: 0.0005619525909423828\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 4400\n",
      "  num_steps_trained: 4400\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 929.918\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 71.5\n",
      "    ram_util_percent: 73.9\n",
      "  pid: 80285\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 648.741\n",
      "  sample_time_ms: 1.541\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.1969380802361701\n",
      "    mean_inference_ms: 0.7461063755124678\n",
      "    mean_processing_ms: 0.7365773791915796\n",
      "  time_since_restore: 12.765944242477417\n",
      "  time_this_iter_s: 0.30790019035339355\n",
      "  time_total_s: 12.765944242477417\n",
      "  timestamp: 1591825214\n",
      "  timesteps_since_restore: 4400\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 4400\n",
      "  training_iteration: 44\n",
      "  trial_id: '00001'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00002:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-40-15\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9525972607474534\n",
      "  episode_reward_mean: 0.9061903188313731\n",
      "  episode_reward_min: 0.8366066088955019\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 4500\n",
      "  experiment_id: 30cdd44713174e5382cc8ef5e82ef19e\n",
      "  experiment_tag: '2'\n",
      "  grad_time_ms: 12.067\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 12.067\n",
      "    learner:\n",
      "      cumulative_regret: 6.804516416636784\n",
      "      update_latency: 0.0008840560913085938\n",
      "    num_steps_sampled: 4500\n",
      "    num_steps_trained: 4500\n",
      "    opt_peak_throughput: 82.871\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 157.711\n",
      "    sample_time_ms: 6.341\n",
      "    update_time_ms: 0.012\n",
      "  iterations_since_restore: 45\n",
      "  learner:\n",
      "    cumulative_regret: 6.804516416636784\n",
      "    update_latency: 0.0008840560913085938\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 4500\n",
      "  num_steps_trained: 4500\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 82.871\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 80284\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 157.711\n",
      "  sample_time_ms: 6.341\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.19525258018291947\n",
      "    mean_inference_ms: 0.7283226751375398\n",
      "    mean_processing_ms: 0.7692725625045562\n",
      "  time_since_restore: 13.125244379043579\n",
      "  time_this_iter_s: 0.45464015007019043\n",
      "  time_total_s: 13.125244379043579\n",
      "  timestamp: 1591825215\n",
      "  timesteps_since_restore: 4500\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 4500\n",
      "  training_iteration: 45\n",
      "  trial_id: '00002'\n",
      "  update_time_ms: 0.012\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00003:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-40-17\n",
      "  done: true\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9321029404414258\n",
      "  episode_reward_mean: 0.8948998191302354\n",
      "  episode_reward_min: 0.7984495829311018\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 5000\n",
      "  experiment_id: dcf572c1339a48efb3221cfde5907b73\n",
      "  experiment_tag: '3'\n",
      "  grad_time_ms: 1.367\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 1.367\n",
      "    learner:\n",
      "      cumulative_regret: 4.4316813476825905\n",
      "      update_latency: 0.001232147216796875\n",
      "    num_steps_sampled: 5000\n",
      "    num_steps_trained: 5000\n",
      "    opt_peak_throughput: 731.276\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 586.829\n",
      "    sample_time_ms: 1.704\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 50\n",
      "  learner:\n",
      "    cumulative_regret: 4.4316813476825905\n",
      "    update_latency: 0.001232147216796875\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 5000\n",
      "  num_steps_trained: 5000\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 731.276\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 80288\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 586.829\n",
      "  sample_time_ms: 1.704\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.20491240191903032\n",
      "    mean_inference_ms: 0.7275807526177869\n",
      "    mean_processing_ms: 0.7532151120587652\n",
      "  time_since_restore: 14.723174095153809\n",
      "  time_this_iter_s: 0.3116002082824707\n",
      "  time_total_s: 14.723174095153809\n",
      "  timestamp: 1591825217\n",
      "  timesteps_since_restore: 5000\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 5000\n",
      "  training_iteration: 50\n",
      "  trial_id: '00003'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-40-17\n",
      "  done: true\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9130084799930833\n",
      "  episode_reward_mean: 0.8882289055914353\n",
      "  episode_reward_min: 0.8324021708251622\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 5000\n",
      "  experiment_id: a696831a2d8f458aa1154d8dc84e8e7f\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 1.309\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 1.309\n",
      "    learner:\n",
      "      cumulative_regret: 6.286649778091199\n",
      "      update_latency: 0.0012879371643066406\n",
      "    num_steps_sampled: 5000\n",
      "    num_steps_trained: 5000\n",
      "    opt_peak_throughput: 763.767\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 628.68\n",
      "    sample_time_ms: 1.591\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 50\n",
      "  learner:\n",
      "    cumulative_regret: 6.286649778091199\n",
      "    update_latency: 0.0012879371643066406\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 5000\n",
      "  num_steps_trained: 5000\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 763.767\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 80283\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 628.68\n",
      "  sample_time_ms: 1.591\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.2062059454716723\n",
      "    mean_inference_ms: 0.7294283178276452\n",
      "    mean_processing_ms: 0.7731017292177552\n",
      "  time_since_restore: 14.986804246902466\n",
      "  time_this_iter_s: 0.29776525497436523\n",
      "  time_total_s: 14.986804246902466\n",
      "  timestamp: 1591825217\n",
      "  timesteps_since_restore: 5000\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 5000\n",
      "  training_iteration: 50\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00004:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-40-17\n",
      "  done: true\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.8777501761402411\n",
      "  episode_reward_mean: 0.8489979907786522\n",
      "  episode_reward_min: 0.7435151880934832\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 5000\n",
      "  experiment_id: 143155dd06b94fa2a5a1cd9ab939ba8b\n",
      "  experiment_tag: '4'\n",
      "  grad_time_ms: 1.385\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 1.385\n",
      "    learner:\n",
      "      cumulative_regret: 6.036372383694408\n",
      "      update_latency: 0.0010228157043457031\n",
      "    num_steps_sampled: 5000\n",
      "    num_steps_trained: 5000\n",
      "    opt_peak_throughput: 721.824\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 608.17\n",
      "    sample_time_ms: 1.644\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 50\n",
      "  learner:\n",
      "    cumulative_regret: 6.036372383694408\n",
      "    update_latency: 0.0010228157043457031\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 5000\n",
      "  num_steps_trained: 5000\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 721.824\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 80282\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 608.17\n",
      "  sample_time_ms: 1.644\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.20003113787642865\n",
      "    mean_inference_ms: 0.771248109386912\n",
      "    mean_processing_ms: 0.7456119383270564\n",
      "  time_since_restore: 14.86109471321106\n",
      "  time_this_iter_s: 0.3144230842590332\n",
      "  time_total_s: 14.86109471321106\n",
      "  timestamp: 1591825217\n",
      "  timesteps_since_restore: 5000\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 5000\n",
      "  training_iteration: 50\n",
      "  trial_id: '00004'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00002:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-40-17\n",
      "  done: true\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9525972607474534\n",
      "  episode_reward_mean: 0.8995755681227938\n",
      "  episode_reward_min: 0.8245379735068428\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 5000\n",
      "  experiment_id: 30cdd44713174e5382cc8ef5e82ef19e\n",
      "  experiment_tag: '2'\n",
      "  grad_time_ms: 1.181\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 1.181\n",
      "    learner:\n",
      "      cumulative_regret: 6.932256626775035\n",
      "      update_latency: 0.0006988048553466797\n",
      "    num_steps_sampled: 5000\n",
      "    num_steps_trained: 5000\n",
      "    opt_peak_throughput: 847.06\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 625.427\n",
      "    sample_time_ms: 1.599\n",
      "    update_time_ms: 0.005\n",
      "  iterations_since_restore: 50\n",
      "  learner:\n",
      "    cumulative_regret: 6.932256626775035\n",
      "    update_latency: 0.0006988048553466797\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 5000\n",
      "  num_steps_trained: 5000\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 847.06\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 80284\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 625.427\n",
      "  sample_time_ms: 1.599\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.1963699991477534\n",
      "    mean_inference_ms: 0.7354758830338425\n",
      "    mean_processing_ms: 0.7726630790785205\n",
      "  time_since_restore: 14.872056484222412\n",
      "  time_this_iter_s: 0.29527711868286133\n",
      "  time_total_s: 14.872056484222412\n",
      "  timestamp: 1591825217\n",
      "  timesteps_since_restore: 5000\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 5000\n",
      "  training_iteration: 50\n",
      "  trial_id: '00002'\n",
      "  update_time_ms: 0.005\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-10_14-40-17\n",
      "  done: true\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.8989514652605076\n",
      "  episode_reward_mean: 0.8880935997196963\n",
      "  episode_reward_min: 0.8533225975915805\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 5000\n",
      "  experiment_id: c2df8311aa46490ebcd32e5bcdd6a560\n",
      "  experiment_tag: '1'\n",
      "  grad_time_ms: 1.378\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 1.378\n",
      "    learner:\n",
      "      cumulative_regret: 7.576738510826825\n",
      "      update_latency: 0.0006341934204101562\n",
      "    num_steps_sampled: 5000\n",
      "    num_steps_trained: 5000\n",
      "    opt_peak_throughput: 725.897\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 662.733\n",
      "    sample_time_ms: 1.509\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 50\n",
      "  learner:\n",
      "    cumulative_regret: 7.576738510826825\n",
      "    update_latency: 0.0006341934204101562\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 5000\n",
      "  num_steps_trained: 5000\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 725.897\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 80285\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 662.733\n",
      "  sample_time_ms: 1.509\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.1960547297889055\n",
      "    mean_inference_ms: 0.7529335483458729\n",
      "    mean_processing_ms: 0.7712868684960515\n",
      "  time_since_restore: 14.98849892616272\n",
      "  time_this_iter_s: 0.307708740234375\n",
      "  time_total_s: 14.98849892616272\n",
      "  timestamp: 1591825217\n",
      "  timesteps_since_restore: 5000\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 5000\n",
      "  training_iteration: 50\n",
      "  trial_id: '00001'\n",
      "  update_time_ms: 0.002\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 5 (5 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         14.9868</td><td style=\"text-align: right;\">5000</td><td style=\"text-align: right;\">0.888229</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         14.9885</td><td style=\"text-align: right;\">5000</td><td style=\"text-align: right;\">0.888094</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00002</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         14.8721</td><td style=\"text-align: right;\">5000</td><td style=\"text-align: right;\">0.899576</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00003</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         14.7232</td><td style=\"text-align: right;\">5000</td><td style=\"text-align: right;\">0.8949  </td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00004</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         14.8611</td><td style=\"text-align: right;\">5000</td><td style=\"text-align: right;\">0.848998</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trials took 23.51621699333191 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "analysis = tune.run(\n",
    "    \"contrib/LinUCB\",\n",
    "    config=UCB_CONFIG,\n",
    "    stop={\"training_iteration\": training_iterations},\n",
    "    num_samples=5,\n",
    "    checkpoint_at_end=False\n",
    ")\n",
    "\n",
    "print(\"The trials took\", time.time() - start_time, \"seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_steps_trained</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3.511102</td>\n",
       "      <td>3.817931</td>\n",
       "      <td>3.093602</td>\n",
       "      <td>0.355700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>4.064315</td>\n",
       "      <td>4.491370</td>\n",
       "      <td>3.377228</td>\n",
       "      <td>0.424538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>4.470640</td>\n",
       "      <td>4.822568</td>\n",
       "      <td>3.520875</td>\n",
       "      <td>0.543014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>4.685584</td>\n",
       "      <td>5.068920</td>\n",
       "      <td>3.653400</td>\n",
       "      <td>0.588148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>4.847873</td>\n",
       "      <td>5.323248</td>\n",
       "      <td>3.707895</td>\n",
       "      <td>0.650397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>4.959078</td>\n",
       "      <td>5.494924</td>\n",
       "      <td>3.765879</td>\n",
       "      <td>0.689057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>5.074850</td>\n",
       "      <td>5.605005</td>\n",
       "      <td>3.806786</td>\n",
       "      <td>0.737699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>5.150581</td>\n",
       "      <td>5.696489</td>\n",
       "      <td>3.882395</td>\n",
       "      <td>0.742712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>5.254922</td>\n",
       "      <td>5.808644</td>\n",
       "      <td>3.927877</td>\n",
       "      <td>0.773881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>5.321351</td>\n",
       "      <td>5.881939</td>\n",
       "      <td>3.981708</td>\n",
       "      <td>0.790230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>5.387552</td>\n",
       "      <td>6.003160</td>\n",
       "      <td>4.022707</td>\n",
       "      <td>0.808463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>5.418084</td>\n",
       "      <td>6.041747</td>\n",
       "      <td>4.028373</td>\n",
       "      <td>0.815855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>5.431204</td>\n",
       "      <td>6.068906</td>\n",
       "      <td>4.037765</td>\n",
       "      <td>0.820435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>5.493056</td>\n",
       "      <td>6.221901</td>\n",
       "      <td>4.068025</td>\n",
       "      <td>0.849296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>5.525878</td>\n",
       "      <td>6.284436</td>\n",
       "      <td>4.099179</td>\n",
       "      <td>0.854037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>5.547031</td>\n",
       "      <td>6.350252</td>\n",
       "      <td>4.111901</td>\n",
       "      <td>0.864246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>5.587271</td>\n",
       "      <td>6.410773</td>\n",
       "      <td>4.123601</td>\n",
       "      <td>0.885998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>5.612208</td>\n",
       "      <td>6.458100</td>\n",
       "      <td>4.123601</td>\n",
       "      <td>0.901386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>5.649529</td>\n",
       "      <td>6.540240</td>\n",
       "      <td>4.147510</td>\n",
       "      <td>0.920527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>5.677999</td>\n",
       "      <td>6.573669</td>\n",
       "      <td>4.151235</td>\n",
       "      <td>0.931724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>5.700254</td>\n",
       "      <td>6.632363</td>\n",
       "      <td>4.151235</td>\n",
       "      <td>0.948447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>5.718850</td>\n",
       "      <td>6.651863</td>\n",
       "      <td>4.189436</td>\n",
       "      <td>0.942896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>5.756432</td>\n",
       "      <td>6.744058</td>\n",
       "      <td>4.198828</td>\n",
       "      <td>0.969567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>5.778019</td>\n",
       "      <td>6.797601</td>\n",
       "      <td>4.208484</td>\n",
       "      <td>0.983539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>5.808446</td>\n",
       "      <td>6.833136</td>\n",
       "      <td>4.208484</td>\n",
       "      <td>1.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>5.841897</td>\n",
       "      <td>6.890834</td>\n",
       "      <td>4.212209</td>\n",
       "      <td>1.024058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>5.856601</td>\n",
       "      <td>6.894961</td>\n",
       "      <td>4.213170</td>\n",
       "      <td>1.026215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>5.868612</td>\n",
       "      <td>6.905680</td>\n",
       "      <td>4.213170</td>\n",
       "      <td>1.031569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>5.891291</td>\n",
       "      <td>6.942647</td>\n",
       "      <td>4.235585</td>\n",
       "      <td>1.036076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>5.910293</td>\n",
       "      <td>6.965785</td>\n",
       "      <td>4.250335</td>\n",
       "      <td>1.039248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>5.928481</td>\n",
       "      <td>7.005925</td>\n",
       "      <td>4.281730</td>\n",
       "      <td>1.038086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>5.945880</td>\n",
       "      <td>7.039370</td>\n",
       "      <td>4.302637</td>\n",
       "      <td>1.041781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>5.957749</td>\n",
       "      <td>7.069090</td>\n",
       "      <td>4.304631</td>\n",
       "      <td>1.049567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>5.983846</td>\n",
       "      <td>7.107082</td>\n",
       "      <td>4.316561</td>\n",
       "      <td>1.056798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500</th>\n",
       "      <td>6.005738</td>\n",
       "      <td>7.148378</td>\n",
       "      <td>4.316561</td>\n",
       "      <td>1.071495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>6.020847</td>\n",
       "      <td>7.170222</td>\n",
       "      <td>4.336019</td>\n",
       "      <td>1.072542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3700</th>\n",
       "      <td>6.043053</td>\n",
       "      <td>7.213744</td>\n",
       "      <td>4.340788</td>\n",
       "      <td>1.084435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>6.057088</td>\n",
       "      <td>7.250217</td>\n",
       "      <td>4.342782</td>\n",
       "      <td>1.093522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3900</th>\n",
       "      <td>6.073521</td>\n",
       "      <td>7.290073</td>\n",
       "      <td>4.349837</td>\n",
       "      <td>1.106082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>6.080989</td>\n",
       "      <td>7.304046</td>\n",
       "      <td>4.351736</td>\n",
       "      <td>1.111284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4100</th>\n",
       "      <td>6.090781</td>\n",
       "      <td>7.304046</td>\n",
       "      <td>4.351736</td>\n",
       "      <td>1.116674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4200</th>\n",
       "      <td>6.114994</td>\n",
       "      <td>7.332545</td>\n",
       "      <td>4.368239</td>\n",
       "      <td>1.120764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>6.137692</td>\n",
       "      <td>7.385776</td>\n",
       "      <td>4.383687</td>\n",
       "      <td>1.130494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>6.146699</td>\n",
       "      <td>7.420624</td>\n",
       "      <td>4.383687</td>\n",
       "      <td>1.139903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>6.160075</td>\n",
       "      <td>7.450179</td>\n",
       "      <td>4.394542</td>\n",
       "      <td>1.145486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>6.171502</td>\n",
       "      <td>7.460784</td>\n",
       "      <td>4.394542</td>\n",
       "      <td>1.152178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4700</th>\n",
       "      <td>6.183739</td>\n",
       "      <td>7.497138</td>\n",
       "      <td>4.394542</td>\n",
       "      <td>1.163528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>6.204179</td>\n",
       "      <td>7.518083</td>\n",
       "      <td>4.409803</td>\n",
       "      <td>1.164406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4900</th>\n",
       "      <td>6.231223</td>\n",
       "      <td>7.550425</td>\n",
       "      <td>4.431681</td>\n",
       "      <td>1.171091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>6.252740</td>\n",
       "      <td>7.576739</td>\n",
       "      <td>4.431681</td>\n",
       "      <td>1.180988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mean       max       min       std\n",
       "num_steps_trained                                        \n",
       "100                3.511102  3.817931  3.093602  0.355700\n",
       "200                4.064315  4.491370  3.377228  0.424538\n",
       "300                4.470640  4.822568  3.520875  0.543014\n",
       "400                4.685584  5.068920  3.653400  0.588148\n",
       "500                4.847873  5.323248  3.707895  0.650397\n",
       "600                4.959078  5.494924  3.765879  0.689057\n",
       "700                5.074850  5.605005  3.806786  0.737699\n",
       "800                5.150581  5.696489  3.882395  0.742712\n",
       "900                5.254922  5.808644  3.927877  0.773881\n",
       "1000               5.321351  5.881939  3.981708  0.790230\n",
       "1100               5.387552  6.003160  4.022707  0.808463\n",
       "1200               5.418084  6.041747  4.028373  0.815855\n",
       "1300               5.431204  6.068906  4.037765  0.820435\n",
       "1400               5.493056  6.221901  4.068025  0.849296\n",
       "1500               5.525878  6.284436  4.099179  0.854037\n",
       "1600               5.547031  6.350252  4.111901  0.864246\n",
       "1700               5.587271  6.410773  4.123601  0.885998\n",
       "1800               5.612208  6.458100  4.123601  0.901386\n",
       "1900               5.649529  6.540240  4.147510  0.920527\n",
       "2000               5.677999  6.573669  4.151235  0.931724\n",
       "2100               5.700254  6.632363  4.151235  0.948447\n",
       "2200               5.718850  6.651863  4.189436  0.942896\n",
       "2300               5.756432  6.744058  4.198828  0.969567\n",
       "2400               5.778019  6.797601  4.208484  0.983539\n",
       "2500               5.808446  6.833136  4.208484  1.000017\n",
       "2600               5.841897  6.890834  4.212209  1.024058\n",
       "2700               5.856601  6.894961  4.213170  1.026215\n",
       "2800               5.868612  6.905680  4.213170  1.031569\n",
       "2900               5.891291  6.942647  4.235585  1.036076\n",
       "3000               5.910293  6.965785  4.250335  1.039248\n",
       "3100               5.928481  7.005925  4.281730  1.038086\n",
       "3200               5.945880  7.039370  4.302637  1.041781\n",
       "3300               5.957749  7.069090  4.304631  1.049567\n",
       "3400               5.983846  7.107082  4.316561  1.056798\n",
       "3500               6.005738  7.148378  4.316561  1.071495\n",
       "3600               6.020847  7.170222  4.336019  1.072542\n",
       "3700               6.043053  7.213744  4.340788  1.084435\n",
       "3800               6.057088  7.250217  4.342782  1.093522\n",
       "3900               6.073521  7.290073  4.349837  1.106082\n",
       "4000               6.080989  7.304046  4.351736  1.111284\n",
       "4100               6.090781  7.304046  4.351736  1.116674\n",
       "4200               6.114994  7.332545  4.368239  1.120764\n",
       "4300               6.137692  7.385776  4.383687  1.130494\n",
       "4400               6.146699  7.420624  4.383687  1.139903\n",
       "4500               6.160075  7.450179  4.394542  1.145486\n",
       "4600               6.171502  7.460784  4.394542  1.152178\n",
       "4700               6.183739  7.497138  4.394542  1.163528\n",
       "4800               6.204179  7.518083  4.409803  1.164406\n",
       "4900               6.231223  7.550425  4.431681  1.171091\n",
       "5000               6.252740  7.576739  4.431681  1.180988"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.DataFrame()\n",
    "\n",
    "for key, df in analysis.trial_dataframes.items():\n",
    "    frame = frame.append(df, ignore_index=True)\n",
    "\n",
    "df = frame.groupby(\"num_steps_trained\")[\n",
    "    \"learner/cumulative_regret\"].aggregate([\"mean\", \"max\", \"min\", \"std\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1103\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1103\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.1.min.js\": \"JpP8FXbgAZLkfur7LiK3j9AGBhHNIvF742meBJrjO2ShJDhCG2I1uVvW+0DUtrmc\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.1.min.js\": \"xZlADit0Q04ISQEdKg2k3L4W9AwQBAuDs9nJL9fM/WwzL1tEU9VPNezOFX0nLEAz\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.1.min.js\": \"4BuPRZkdMKSnj3zoxiNrQ86XgNw0rYmBOxe7nshquXwwcauupgBF2DHLVG1WuZlV\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.1.min.js\": \"Dv1SQ87hmDqK6S5OhBf0bCuwAEvL5QYL0PuR/F1SPVhCS/r/abjkbpKDYL2zeM19\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1103\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1103' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.1.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1103\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1103\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.1.min.js\": \"JpP8FXbgAZLkfur7LiK3j9AGBhHNIvF742meBJrjO2ShJDhCG2I1uVvW+0DUtrmc\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.1.min.js\": \"xZlADit0Q04ISQEdKg2k3L4W9AwQBAuDs9nJL9fM/WwzL1tEU9VPNezOFX0nLEAz\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.1.min.js\": \"4BuPRZkdMKSnj3zoxiNrQ86XgNw0rYmBOxe7nshquXwwcauupgBF2DHLVG1WuZlV\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.1.min.js\": \"Dv1SQ87hmDqK6S5OhBf0bCuwAEvL5QYL0PuR/F1SPVhCS/r/abjkbpKDYL2zeM19\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1103\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1103' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1103\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.models import Band, ColumnDataSource, Range1d\n",
    "import bokeh.io\n",
    "# The next two lines prevent Bokeh from opening the graph in a new window.\n",
    "bokeh.io.reset_output()\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"c614497d-ad0a-4924-bebf-e0449fdee7cf\" data-root-id=\"1207\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"7e0b4a30-20b1-48e7-bb0e-1e375c15c664\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1215\"}],\"center\":[{\"id\":\"1218\"},{\"id\":\"1222\"},{\"id\":\"1240\"}],\"left\":[{\"id\":\"1219\"}],\"renderers\":[{\"id\":\"1238\"}],\"title\":{\"id\":\"1242\"},\"toolbar\":{\"id\":\"1229\"},\"x_range\":{\"id\":\"1208\"},\"x_scale\":{\"id\":\"1211\"},\"y_range\":{\"id\":\"1206\"},\"y_scale\":{\"id\":\"1213\"}},\"id\":\"1207\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1255\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1208\",\"type\":\"DataRange1d\"},{\"attributes\":{\"axis\":{\"id\":\"1219\"},\"dimension\":1,\"grid_line_alpha\":0.5,\"ticker\":null},\"id\":\"1222\",\"type\":\"Grid\"},{\"attributes\":{\"axis\":{\"id\":\"1215\"},\"grid_line_alpha\":0.5,\"ticker\":null},\"id\":\"1218\",\"type\":\"Grid\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"size\":{\"units\":\"screen\",\"value\":5},\"x\":{\"field\":\"num_steps_trained\"},\"y\":{\"field\":\"mean\"}},\"id\":\"1237\",\"type\":\"Scatter\"},{\"attributes\":{\"end\":7.433728122281514,\"start\":3.1554022002659354},\"id\":\"1206\",\"type\":\"Range1d\"},{\"attributes\":{},\"id\":\"1213\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1211\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1220\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis_label\":\"Training Steps\",\"formatter\":{\"id\":\"1257\"},\"ticker\":{\"id\":\"1216\"}},\"id\":\"1215\",\"type\":\"LinearAxis\"},{\"attributes\":{\"source\":{\"id\":\"1205\"}},\"id\":\"1239\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1223\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1226\",\"type\":\"ResetTool\"},{\"attributes\":{\"text\":\"Cumulative Regret\"},\"id\":\"1242\",\"type\":\"Title\"},{\"attributes\":{\"overlay\":{\"id\":\"1228\"}},\"id\":\"1225\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1259\",\"type\":\"Selection\"},{\"attributes\":{\"axis_label\":\"Regret\",\"formatter\":{\"id\":\"1255\"},\"ticker\":{\"id\":\"1220\"}},\"id\":\"1219\",\"type\":\"LinearAxis\"},{\"attributes\":{\"base\":{\"field\":\"num_steps_trained\",\"units\":\"data\"},\"fill_alpha\":0.3,\"level\":\"underlay\",\"line_color\":\"blue\",\"lower\":{\"field\":\"lower\",\"units\":\"data\"},\"source\":{\"id\":\"1205\"},\"upper\":{\"field\":\"upper\",\"units\":\"data\"}},\"id\":\"1240\",\"type\":\"Band\"},{\"attributes\":{},\"id\":\"1260\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1223\"},{\"id\":\"1224\"},{\"id\":\"1225\"},{\"id\":\"1226\"},{\"id\":\"1227\"}]},\"id\":\"1229\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1224\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1228\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"1257\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"data\":{\"index\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"lower\":{\"__ndarray__\":\"9/I+gkM+CUC4SyRFQx4NQP73G43Haw9AKGlTbsZjEECHFmoiN8oQQASXbkqAFBFAFiuA/T1ZEUBAKFh/qKERQEBIBAuW7BFAu1rPLt4fEkDkcFe5/FASQK9PLoCuaBJAgMKRXG1xEkBq8TyrNZMSQCVjZgX3rxJAeEsC3iu7EkAlHDGHGs4SQO+/esbh1xJAZP/0m3/qEkBWCiuGL/wSQCghP5rZARNAV5ZliJMaE0DyNCYNwCUTQKVOFDaMLRNASa4x39Q7E0CKm4aGd0UTQEzI6bxQUhNAwG1L2iFZE0CeGJifvWsTQBiAJCrzexNACIvGvMOPE0CaiNL+y50TQG4II5f6oRNAPSGUKEy1E0DdeMc2qrwTQOfyYowQyxNAj8Xq75/VE0DUnm4WsdoTQC6A8DKo3hNAS3kNdfrgE0AgYyVjfOUTQJ4ZCpEX+hNABURl+14HFEAs7tdo9QYUQBhg/27wDhRAlCAzjckTFEBgcI1WshQUQKApiEO6KBRAcOSBF5M9FEBtpa8ueUkUQA==\",\"dtype\":\"float64\",\"shape\":[50]},\"max\":{\"__ndarray__\":\"G+j7bR+LDkD/X37EKfcRQEnuk1pPShNALC6D9pJGFEC6sIqAAUsVQFcJbVHN+hVAtrtAWIZrFkCV7WdaNMkWQALgQj4NPBdA9DonAhuHF0Alejl0PAMYQGd38sW/KhhA8cUjXI9GGEC9RCcSOuMYQJETEhdDIxlAhwDieKhmGUB3oHfOoaQZQBlSUBgY1RlAVjdbuTQpGkD94xPEb0saQHWKIiWKhxpAM4X8AoKbGkAtMSZD6vkaQBLRqlS+MBtAAZYXoCFVG0D2cqrDNpAbQLq8OsJwlBtAR0k6dmqfG0Df5Cs7RcUbQACJhMP23BtA2hwgIhEGHEBJwiujUCgcQFhtAou/RhxAOQDl+KZtHEAUfdpw8JccQAvHA59OrhxAkUpu1t/aHEA8yO3oOAAdQOMJyfgIKR1Ax//s7lc3HUDH/+zuVzcdQM7EjKGGVB1AsYEbwgiLHUAnei4FuK4dQPx5LcH7zB1ANhw8zdfXHUAXG5jREf0dQL06ZTyEEh5A2DRRk6IzHkA8YUmKlE4eQA==\",\"dtype\":\"float64\",\"shape\":[50]},\"mean\":{\"__ndarray__\":\"ACSAjLwWDEBO91iu20EQQKYIyYPv4RFAO3NfxQm+EkAjeVfYOGQTQAIyMZMY1hNALErifKVMFEDwB+L1MZoUQI456kMKBRVApuWVUxBJFUCuc+ln2owVQNKl2xcerBVA8jzAbo25FUBmQGmM4/gVQEUnMKR/GhZAWsJa1CgwFkDGTI+SXVkWQEEs7a7mchZANvUZNx6ZFkDO+jhfRbYWQDcUFmUPzRZAlb7iKxrgFkDWkvI3lgYXQJBY+PSwHBdA+1ysVtk7F0CDPVxCGl4XQI4qRc8obRdAbjAefnV5F0BrWk6srpAXQPWv4+UjpBdAWglv1MO2F0CqTIO+lMgXQGwWckS81BdAwq1tWHXvF0Ae1Zgw4AUYQFYz4ghZFRhAjDOcKxYsGEBjihY2dToYQOqmYBBJSxhAmsOo5O5SGEDyKxm29VwYQP4e7gnBdRhAG55YPv+MGEB+4j4pOJYYQCvif6rqoxhAUaKAGp6vGECFcocXJrwYQLqSbUIU0RhA2RuHm8XsGECq7iA0zgIZQA==\",\"dtype\":\"float64\",\"shape\":[50]},\"min\":{\"__ndarray__\":\"D3rKbrK/CED2XEffjwQLQC2uA1XAKgxAMkvQryk6DUCBvtq6xKkNQA5X6yqFIA5AUj4YN0x0DkCXzvISJQ8PQC2iHtJKbA9APeJ07InaD0AuDT5gQBcQQEbKc+MNHRBAG3J78asmEEBh6Q5mqEUQQMrXVimPZRBA1uhQKJZyEEDcDptHkX4QQNwOm0eRfhBAOJXQ1AyXEED2f6Jf3ZoQQPZ/ol/dmhBAJfvWZPvBEED6ot5ymcsQQDlz77581RBAOXPvvnzVEED2XcFJTdkQQJjSjjZJ2hBAmNKONknaEECQTSNRPfEQQAeiybdXABFA4SD80X0gEUB3rPJv5jURQEtwkCTxNxFANmN6nChEEUA2Y3qcKEQRQFxLoW0VWBFAbLW0mvdcEUBAeVJPAl8RQDTNFss7ZhFAnN19gi1oEUCc3X2CLWgRQEqNObITeRFAWtI2T+WIEUBa0jZP5YgRQCWVkvIClBFAJZWS8gKUEUAllZLyApQRQEnxblujoxFAGFzarAq6EUAYXNqsCroRQA==\",\"dtype\":\"float64\",\"shape\":[50]},\"num_steps_trained\":[100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000,2100,2200,2300,2400,2500,2600,2700,2800,2900,3000,3100,3200,3300,3400,3500,3600,3700,3800,3900,4000,4100,4200,4300,4400,4500,4600,4700,4800,4900,5000],\"std\":{\"__ndarray__\":\"RYgJUsjD1j8fF228oCvbPzdl2OldYOE/lFBguBrS4j/hFGuvDdDkP/HXFEbCDOY/rfgQ+zub5z99/U60S8TnP22KL8ehw+g/VVc0JpFJ6T9OFpB07d7pPxmxar18G+o/ktNzkQBB6j/kd2IJby3rPwEhTvZEVOs/D7fDsuen6z8JhfFaGFrsP5Jik0Mn2Ow/lK4n2fR07T/Cg2/IrtDtP3qYt1auWe4/8kHpGzUs7j8k72JWsQbvP1pPIPclee8/x7rq3REA8D/mh1bvimLwPwaJbUlga/A/tgpLj06B8D82B9kyxJPwP3a//O7CoPA/RvmhXgCc8D8+EMP+IqvwP/o3PLUGy/A/FDJmv6To8D8DcUXn1yTxP70B/fEhKfE/9LfF7thZ8T89rp9+EH/xP/KawHWDsvE/PSltvtHH8T9JI89L5d3xP38VkOOl7vE/WWjNC4EW8j9H0ZsBCz3yP00IAu7oU/I/8wY2NVJv8j+TCOgDz53yP2eklftnofI/o90UEMq88j/0JMUVVOXyPw==\",\"dtype\":\"float64\",\"shape\":[50]},\"upper\":{\"__ndarray__\":\"CVXBljXvDkDAyB+6lfQRQE0VBEH7DRRATn1rHE0YFUC/20SOOv4VQADN89uwlxZAQmlE/AxAF0Cg52tsu5IXQNwq0Hx+HRhAkXBceEJyGEB4dnsWuMgYQPX7iK+N7xhAZLfugK0BGUBij5VtkV4ZQGXr+UIIhRlAPDmzyiWlGUBnfe2doOQZQJOYX5frDRpACOs+0rxHGkBG60Y4W3AaQEYH7S9FmBpA0+Zfz6ClGkC68L5ibOcaQHti3LPVCxtArQsnzt07G0B83zH+vHYbQNCMoOEAiBtAHPPwIcmZG0A4nAS5n7UbQNLfoqFUzBtArIcX7MPdG0C6EDR+XfMbQGokwfF9BxxARzpHiJ4pHEBfMWoqFk8cQMVzYYWhXxxAiaFNZ4yCHEDydb5VOZocQKbN0O3ptxxA6Q1EVOPEHEDE9AwJb9QcQF4k0oJq8RxAMfhLgZ8SHUDQ1qXpeiUdQD5kAObkOB1ADiTOp3JLHUCqdIHYmWMdQNT7UkFueR1AQlOMH/ibHUDnN5I5I7wdQA==\",\"dtype\":\"float64\",\"shape\":[50]}},\"selected\":{\"id\":\"1259\"},\"selection_policy\":{\"id\":\"1260\"}},\"id\":\"1205\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1216\",\"type\":\"BasicTicker\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.3},\"fill_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":5},\"x\":{\"field\":\"num_steps_trained\"},\"y\":{\"field\":\"mean\"}},\"id\":\"1236\",\"type\":\"Scatter\"},{\"attributes\":{\"data_source\":{\"id\":\"1205\"},\"glyph\":{\"id\":\"1236\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1237\"},\"selection_glyph\":null,\"view\":{\"id\":\"1239\"}},\"id\":\"1238\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1227\",\"type\":\"SaveTool\"}],\"root_ids\":[\"1207\"]},\"title\":\"Bokeh Application\",\"version\":\"2.0.1\"}};\n",
       "  var render_items = [{\"docid\":\"7e0b4a30-20b1-48e7-bb0e-1e375c15c664\",\"root_ids\":[\"1207\"],\"roots\":{\"1207\":\"c614497d-ad0a-4924-bebf-e0449fdee7cf\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1207"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['lower'] = df['mean'] - df['std']\n",
    "df['upper'] = df['mean'] + df['std']\n",
    "ymin=df['lower'].min()\n",
    "ymax=df['upper'].max()\n",
    "\n",
    "source = ColumnDataSource(df.reset_index())\n",
    "\n",
    "TOOLS = \"pan,wheel_zoom,box_zoom,reset,save\"\n",
    "p = figure(tools=TOOLS, y_range=Range1d(ymin,ymax))\n",
    "\n",
    "p.scatter(x='num_steps_trained', y='mean', line_color='black', fill_alpha=0.3, size=5, source=source)\n",
    "band = Band(base='num_steps_trained', lower='lower', upper='upper', source=source, level='underlay',\n",
    "            fill_alpha=0.3, line_width=1, line_color='blue')\n",
    "p.add_layout(band)\n",
    "\n",
    "p.title.text = \"Cumulative Regret\"\n",
    "p.xgrid[0].grid_line_alpha=0.5\n",
    "p.ygrid[0].grid_line_alpha=0.5\n",
    "p.xaxis.axis_label = 'Training Steps'\n",
    "p.yaxis.axis_label = 'Regret'\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slope appears to stop flattening, suggesting that the previous number of steps, 2000, was sufficient to get the optimal behavior. Beyond that, regret continues to accumulate, but it's linear in the number of steps, neither getting better or worse.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04: Linear Upper Confidence Bound - Exercise 2\n",
    "\n",
    "Change the `training_iterations` back to the original value of 20 and try the `LinearDiscreteEnv` ([discrete.py source code](https://github.com/ray-project/ray/blob/master/rllib/contrib/bandits/envs/discrete.py)) as the environment instead of the `ParametricItemRecoEnv`. Also replace `UCB_CONFIG` with `DEFAULT_CONFIG_LINEAR`, which you'll need to import:\n",
    "\n",
    "```python\n",
    "from ray.rllib.contrib.bandits.envs import LinearDiscreteEnv\n",
    "from ray.rllib.contrib.bandits.envs.discrete import DEFAULT_CONFIG_LINEAR\n",
    "```\n",
    "\n",
    "`LinearDiscreteEnv` samples data from linearly parameterized arms. The reward for context $X$ and arm $a$ is given by $X^T * \\theta_a$, for some latent (hidden) set of parameters $\\theta_i : i = 1, ..., k$. The $\\theta$ values are sampled uniformly at random, the contexts are Gaussian, and Gaussian noise is added to the rewards.\n",
    "\n",
    "What does the cumulative regret look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.contrib.bandits.envs import LinearDiscreteEnv\n",
    "from ray.rllib.contrib.bandits.envs.discrete import DEFAULT_CONFIG_LINEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearDiscreteEnv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fd4ff95d72e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearDiscreteEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m  \u001b[0;31m# the default standard deviation value for the result noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LinearDiscreteEnv' is not defined"
     ]
    }
   ],
   "source": [
    "lde = LinearDiscreteEnv()\n",
    "lde.sigma  # the default standard deviation value for the result noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 5 (4 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00001</td><td>PENDING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00002</td><td>PENDING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00003</td><td>PENDING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00004</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-10 15:47:33,783\tERROR trial_runner.py:519 -- Trial contrib_LinUCB_LinearDiscreteEnv_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 431, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/worker.py\", line 1515, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::LinUCB.train()\u001b[39m (pid=80938, ip=192.168.1.149)\n",
      "  File \"python/ray/_raylet.pyx\", line 424, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 459, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 462, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 463, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 417, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 90, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 448, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/trainable.py\", line 174, in __init__\n",
      "    self._setup(copy.deepcopy(self.config))\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 554, in _setup\n",
      "    config)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 921, in merge_trainer_configs\n",
      "    cls._override_all_subkeys_if_type_changes)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/utils/util.py\", line 181, in deep_update\n",
      "    raise Exception(\"Unknown config parameter `{}` \".format(k))\n",
      "Exception: Unknown config parameter `feature_dim`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=80937)\u001b[0m 2020-06-10 15:47:33,756\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=80938)\u001b[0m 2020-06-10 15:47:33,757\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 5 (1 ERROR, 4 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00000</td><td>ERROR   </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00001</td><td>RUNNING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00002</td><td>RUNNING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00003</td><td>RUNNING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00004</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                            </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00000</td><td style=\"text-align: right;\">           1</td><td>/Users/deanwampler/ray_results/contrib/LinUCB/contrib_LinUCB_LinearDiscreteEnv_0_2020-06-10_15-47-27rfpae3sv/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-10 15:47:33,821\tERROR trial_runner.py:519 -- Trial contrib_LinUCB_LinearDiscreteEnv_00001: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 431, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/worker.py\", line 1515, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::LinUCB.train()\u001b[39m (pid=80937, ip=192.168.1.149)\n",
      "  File \"python/ray/_raylet.pyx\", line 424, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 459, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 462, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 463, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 417, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 90, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 448, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/trainable.py\", line 174, in __init__\n",
      "    self._setup(copy.deepcopy(self.config))\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 554, in _setup\n",
      "    config)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 921, in merge_trainer_configs\n",
      "    cls._override_all_subkeys_if_type_changes)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/utils/util.py\", line 181, in deep_update\n",
      "    raise Exception(\"Unknown config parameter `{}` \".format(k))\n",
      "Exception: Unknown config parameter `feature_dim`\n",
      "2020-06-10 15:47:33,920\tERROR trial_runner.py:519 -- Trial contrib_LinUCB_LinearDiscreteEnv_00004: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 431, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/worker.py\", line 1515, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::LinUCB.train()\u001b[39m (pid=81678, ip=192.168.1.149)\n",
      "  File \"python/ray/_raylet.pyx\", line 424, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 459, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 462, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 463, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 417, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 90, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 448, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/trainable.py\", line 174, in __init__\n",
      "    self._setup(copy.deepcopy(self.config))\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 554, in _setup\n",
      "    config)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 921, in merge_trainer_configs\n",
      "    cls._override_all_subkeys_if_type_changes)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/utils/util.py\", line 181, in deep_update\n",
      "    raise Exception(\"Unknown config parameter `{}` \".format(k))\n",
      "Exception: Unknown config parameter `feature_dim`\n",
      "2020-06-10 15:47:33,925\tERROR trial_runner.py:519 -- Trial contrib_LinUCB_LinearDiscreteEnv_00003: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 431, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/worker.py\", line 1515, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::LinUCB.train()\u001b[39m (pid=81680, ip=192.168.1.149)\n",
      "  File \"python/ray/_raylet.pyx\", line 424, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 459, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 462, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 463, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 417, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 90, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 448, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/trainable.py\", line 174, in __init__\n",
      "    self._setup(copy.deepcopy(self.config))\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 554, in _setup\n",
      "    config)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 921, in merge_trainer_configs\n",
      "    cls._override_all_subkeys_if_type_changes)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/utils/util.py\", line 181, in deep_update\n",
      "    raise Exception(\"Unknown config parameter `{}` \".format(k))\n",
      "Exception: Unknown config parameter `feature_dim`\n",
      "2020-06-10 15:47:33,948\tERROR trial_runner.py:519 -- Trial contrib_LinUCB_LinearDiscreteEnv_00002: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 431, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/worker.py\", line 1515, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::LinUCB.train()\u001b[39m (pid=81679, ip=192.168.1.149)\n",
      "  File \"python/ray/_raylet.pyx\", line 424, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 459, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 462, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 463, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 417, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 90, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 448, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/trainable.py\", line 174, in __init__\n",
      "    self._setup(copy.deepcopy(self.config))\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 554, in _setup\n",
      "    config)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 921, in merge_trainer_configs\n",
      "    cls._override_all_subkeys_if_type_changes)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/utils/util.py\", line 181, in deep_update\n",
      "    raise Exception(\"Unknown config parameter `{}` \".format(k))\n",
      "Exception: Unknown config parameter `feature_dim`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 5 (5 ERROR)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00000</td><td>ERROR   </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00001</td><td>ERROR   </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00002</td><td>ERROR   </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00003</td><td>ERROR   </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00004</td><td>ERROR   </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 5<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                            </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00000</td><td style=\"text-align: right;\">           1</td><td>/Users/deanwampler/ray_results/contrib/LinUCB/contrib_LinUCB_LinearDiscreteEnv_0_2020-06-10_15-47-27rfpae3sv/error.txt</td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00001</td><td style=\"text-align: right;\">           1</td><td>/Users/deanwampler/ray_results/contrib/LinUCB/contrib_LinUCB_LinearDiscreteEnv_1_2020-06-10_15-47-27iy93qn91/error.txt</td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00002</td><td style=\"text-align: right;\">           1</td><td>/Users/deanwampler/ray_results/contrib/LinUCB/contrib_LinUCB_LinearDiscreteEnv_2_2020-06-10_15-47-28d6xj_u3v/error.txt</td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00003</td><td style=\"text-align: right;\">           1</td><td>/Users/deanwampler/ray_results/contrib/LinUCB/contrib_LinUCB_LinearDiscreteEnv_3_2020-06-10_15-47-28c2j50oiz/error.txt</td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00004</td><td style=\"text-align: right;\">           1</td><td>/Users/deanwampler/ray_results/contrib/LinUCB/contrib_LinUCB_LinearDiscreteEnv_4_2020-06-10_15-47-28fyl8d44r/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=81678)\u001b[0m 2020-06-10 15:47:33,913\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=81679)\u001b[0m 2020-06-10 15:47:33,939\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=81680)\u001b[0m 2020-06-10 15:47:33,915\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [contrib_LinUCB_LinearDiscreteEnv_00000, contrib_LinUCB_LinearDiscreteEnv_00001, contrib_LinUCB_LinearDiscreteEnv_00002, contrib_LinUCB_LinearDiscreteEnv_00003, contrib_LinUCB_LinearDiscreteEnv_00004])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-aec37b45769f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"training_iteration\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining_iterations\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcheckpoint_at_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, stop, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, loggers, sync_to_cloud, sync_to_driver, checkpoint_freq, checkpoint_at_end, sync_on_checkpoint, keep_checkpoints_num, checkpoint_score_attr, global_checkpoint_period, export_formats, max_failures, fail_fast, restore, search_alg, scheduler, with_server, server_port, verbose, progress_reporter, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, return_trials, ray_auto_init)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [contrib_LinUCB_LinearDiscreteEnv_00000, contrib_LinUCB_LinearDiscreteEnv_00001, contrib_LinUCB_LinearDiscreteEnv_00002, contrib_LinUCB_LinearDiscreteEnv_00003, contrib_LinUCB_LinearDiscreteEnv_00004])"
     ]
    }
   ],
   "source": [
    "DEFAULT_CONFIG_LINEAR[\"env\"] = LinearDiscreteEnv\n",
    "\n",
    "training_iterations = 20\n",
    "start_time = time.time()\n",
    "\n",
    "analysis = tune.run(\n",
    "    \"contrib/LinUCB\",\n",
    "    config=DEFAULT_CONFIG_LINEAR,\n",
    "    stop={\"training_iteration\": training_iterations},\n",
    "    num_samples=5,\n",
    "    checkpoint_at_end=False\n",
    ")\n",
    "\n",
    "print(\"The trials took\", time.time() - start_time, \"seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_steps_trained</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>7.611318</td>\n",
       "      <td>9.448277</td>\n",
       "      <td>5.593304</td>\n",
       "      <td>1.464855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>8.258989</td>\n",
       "      <td>10.153932</td>\n",
       "      <td>6.232646</td>\n",
       "      <td>1.488315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>8.417410</td>\n",
       "      <td>10.442850</td>\n",
       "      <td>6.266983</td>\n",
       "      <td>1.584913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>8.562657</td>\n",
       "      <td>10.681834</td>\n",
       "      <td>6.279945</td>\n",
       "      <td>1.689853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>8.671795</td>\n",
       "      <td>10.738362</td>\n",
       "      <td>6.414168</td>\n",
       "      <td>1.698496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>8.719458</td>\n",
       "      <td>10.779685</td>\n",
       "      <td>6.429091</td>\n",
       "      <td>1.720209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>8.793430</td>\n",
       "      <td>10.876758</td>\n",
       "      <td>6.601496</td>\n",
       "      <td>1.691483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>8.841272</td>\n",
       "      <td>10.902503</td>\n",
       "      <td>6.622167</td>\n",
       "      <td>1.690920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>8.899291</td>\n",
       "      <td>10.906337</td>\n",
       "      <td>6.722436</td>\n",
       "      <td>1.675522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>8.941444</td>\n",
       "      <td>10.918904</td>\n",
       "      <td>6.756243</td>\n",
       "      <td>1.691254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>8.976318</td>\n",
       "      <td>10.929798</td>\n",
       "      <td>6.795594</td>\n",
       "      <td>1.679117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>8.992674</td>\n",
       "      <td>10.934560</td>\n",
       "      <td>6.812996</td>\n",
       "      <td>1.668886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>9.019023</td>\n",
       "      <td>10.939009</td>\n",
       "      <td>6.826301</td>\n",
       "      <td>1.665797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>9.043969</td>\n",
       "      <td>10.962830</td>\n",
       "      <td>6.847440</td>\n",
       "      <td>1.673151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>9.063073</td>\n",
       "      <td>10.978734</td>\n",
       "      <td>6.878249</td>\n",
       "      <td>1.673947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>9.074694</td>\n",
       "      <td>11.002065</td>\n",
       "      <td>6.887194</td>\n",
       "      <td>1.680219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>9.095403</td>\n",
       "      <td>11.005611</td>\n",
       "      <td>6.917478</td>\n",
       "      <td>1.667970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>9.107618</td>\n",
       "      <td>11.013264</td>\n",
       "      <td>6.940859</td>\n",
       "      <td>1.665758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>9.112331</td>\n",
       "      <td>11.019371</td>\n",
       "      <td>6.958317</td>\n",
       "      <td>1.661840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>9.125851</td>\n",
       "      <td>11.052907</td>\n",
       "      <td>6.977317</td>\n",
       "      <td>1.667782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mean        max       min       std\n",
       "num_steps_trained                                         \n",
       "100                7.611318   9.448277  5.593304  1.464855\n",
       "200                8.258989  10.153932  6.232646  1.488315\n",
       "300                8.417410  10.442850  6.266983  1.584913\n",
       "400                8.562657  10.681834  6.279945  1.689853\n",
       "500                8.671795  10.738362  6.414168  1.698496\n",
       "600                8.719458  10.779685  6.429091  1.720209\n",
       "700                8.793430  10.876758  6.601496  1.691483\n",
       "800                8.841272  10.902503  6.622167  1.690920\n",
       "900                8.899291  10.906337  6.722436  1.675522\n",
       "1000               8.941444  10.918904  6.756243  1.691254\n",
       "1100               8.976318  10.929798  6.795594  1.679117\n",
       "1200               8.992674  10.934560  6.812996  1.668886\n",
       "1300               9.019023  10.939009  6.826301  1.665797\n",
       "1400               9.043969  10.962830  6.847440  1.673151\n",
       "1500               9.063073  10.978734  6.878249  1.673947\n",
       "1600               9.074694  11.002065  6.887194  1.680219\n",
       "1700               9.095403  11.005611  6.917478  1.667970\n",
       "1800               9.107618  11.013264  6.940859  1.665758\n",
       "1900               9.112331  11.019371  6.958317  1.661840\n",
       "2000               9.125851  11.052907  6.977317  1.667782"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.DataFrame()\n",
    "\n",
    "for key, df in analysis.trial_dataframes.items():\n",
    "    frame = frame.append(df, ignore_index=True)\n",
    "\n",
    "df = frame.groupby(\"num_steps_trained\")[\n",
    "    \"learner/cumulative_regret\"].aggregate([\"mean\", \"max\", \"min\", \"std\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"2791b290-6abb-4690-b1cd-acdfa4e371f8\" data-root-id=\"1564\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"21867dca-169b-438c-b8ad-56872e3ecd5a\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1572\"}],\"center\":[{\"id\":\"1575\"},{\"id\":\"1579\"},{\"id\":\"1597\"}],\"left\":[{\"id\":\"1576\"}],\"renderers\":[{\"id\":\"1595\"}],\"title\":{\"id\":\"1599\"},\"toolbar\":{\"id\":\"1586\"},\"x_range\":{\"id\":\"1565\"},\"x_scale\":{\"id\":\"1568\"},\"y_range\":{\"id\":\"1563\"},\"y_scale\":{\"id\":\"1570\"}},\"id\":\"1564\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"axis\":{\"id\":\"1576\"},\"dimension\":1,\"grid_line_alpha\":0.5,\"ticker\":null},\"id\":\"1579\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1581\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1565\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1577\",\"type\":\"BasicTicker\"},{\"attributes\":{\"data\":{\"index\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"lower\":{\"__ndarray__\":\"UuNylvqVGEA5LSOcKxUbQDXw6fJ5VBtApyrYL8B9G0A/MrSeqOQbQD4oFy47/xtAjUGt6GRoHEAUsYi59ZkcQFT79Hcj5RxATdZMxzEAHUCEinpmVTAdQJSLWvKOSx1AxrXrBrRpHUBmZqrYt3sdQAae5x13jh1ApusbSvGTHUDuDf/3sLUdQGSDext3xB1AkCDMlU3NHUDWbdUQENUdQA==\",\"dtype\":\"float64\",\"shape\":[20]},\"max\":{\"__ndarray__\":\"t3xOj4TlIkAaStI30E4kQA8xVS+94iRAQU/ZVRldJUBT6BSkCnolQNOe7OYyjyVAyKWQb+bAJUC2w4bUFM4lQAb9r10L0CVA3gOTinrWJUCxbZZwDtwlQIuryLV+3iVAEbmaz8XgJUDNaxQa+OwlQNKnsZYc9SVApdymmQ4BJkCT2DN83wImQH1joZbKBiZACYoP9+oJJkBpFXifFhsmQA==\",\"dtype\":\"float64\",\"shape\":[20]},\"mean\":{\"__ndarray__\":\"2gvbbv1xHkCr7lpCmoQgQMVlkLS21SBAWDstihQgIUAO01KM9VchQHuoZ8lccCFA9qfAgjyWIUBnvv4lu64hQEMrgtFvzCFAuC4e6QTiIUAC7yf83/MhQE9tusA//CFApD/fVb0JIkB8T9QfgxYiQLIYdhdLICJAyc/PRj4mIkDU/re02DAiQEgDkb0ZNyJAaICedIM5IkDrgDB/b0AiQA==\",\"dtype\":\"float64\",\"shape\":[20]},\"min\":{\"__ndarray__\":\"+QRMFItfFkCp4BPdOu4YQFDi2BlkERlAwD8f6KkeGUBULAqaG6gZQLYtGq5jtxlAy4riee5nGkAX081WGX0aQEyhblXG4xpA/5ualGQGG0AmAeQysC4bQHAsWRqCQBtAwtuK7iFOG0CEFsVUx2MbQDq4LZpTgxtAsHhbrHyMG0DA/sA9f6sbQLUlT5hwwxtA57v5/VDVG0CVYD65xegbQA==\",\"dtype\":\"float64\",\"shape\":[20]},\"num_steps_trained\":[100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000],\"std\":{\"__ndarray__\":\"H6KgYQtw9z90wEqiI9D3P1Nt29jNW/k/IzAJkqMJ+z9zz8XnCS37P9+i4JL5hfs/fDlQc1AQ+z/nLtNJAg77P8dsPazwzvo/jRy+K2AP+z8ATlVHqt36PyY8aTzCs/o/BiZLkxqn+j9G4vibOcX6P3hNEkR8yPo/ss8ODi3i+j/qvsPFAbD6P7EMmn7xpvo/AIHDTeWW+j8CUC62O6/6Pw==\",\"dtype\":\"float64\",\"shape\":[20]},\"upper\":{\"__ndarray__\":\"MZqhIwAnIkC6RqS2nn4jQG/Tq28wASRAXGFu/EiBJED8jEvJlr0kQNe8w/sb4SRAJq8qkUb4JEBEJDlvexAlQNzYCedNJiVASvKV7vBDJUDCmBJFlU8lQNSURwi4UiVAZaRIqKBeJUDFa1NTKm8lQGFi+J9aeSVAv6mR6IOCJUCxdnDt2IYlQN5EZO33iyVAiPBWHmCMJUDrSvb1VpYlQA==\",\"dtype\":\"float64\",\"shape\":[20]}},\"selected\":{\"id\":\"1643\"},\"selection_policy\":{\"id\":\"1644\"}},\"id\":\"1562\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1570\",\"type\":\"LinearScale\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.3},\"fill_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":5},\"x\":{\"field\":\"num_steps_trained\"},\"y\":{\"field\":\"mean\"}},\"id\":\"1593\",\"type\":\"Scatter\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1585\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"text\":\"Cumulative Regret\"},\"id\":\"1599\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1641\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1584\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1644\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"overlay\":{\"id\":\"1585\"}},\"id\":\"1582\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"axis\":{\"id\":\"1572\"},\"grid_line_alpha\":0.5,\"ticker\":null},\"id\":\"1575\",\"type\":\"Grid\"},{\"attributes\":{\"axis_label\":\"Regret\",\"formatter\":{\"id\":\"1639\"},\"ticker\":{\"id\":\"1577\"}},\"id\":\"1576\",\"type\":\"LinearAxis\"},{\"attributes\":{\"axis_label\":\"Training Steps\",\"formatter\":{\"id\":\"1641\"},\"ticker\":{\"id\":\"1573\"}},\"id\":\"1572\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1643\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1583\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1573\",\"type\":\"BasicTicker\"},{\"attributes\":{\"source\":{\"id\":\"1562\"}},\"id\":\"1596\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1639\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1568\",\"type\":\"LinearScale\"},{\"attributes\":{\"data_source\":{\"id\":\"1562\"},\"glyph\":{\"id\":\"1593\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1594\"},\"selection_glyph\":null,\"view\":{\"id\":\"1596\"}},\"id\":\"1595\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"size\":{\"units\":\"screen\",\"value\":5},\"x\":{\"field\":\"num_steps_trained\"},\"y\":{\"field\":\"mean\"}},\"id\":\"1594\",\"type\":\"Scatter\"},{\"attributes\":{\"end\":10.79363220817091,\"start\":6.146463728677945},\"id\":\"1563\",\"type\":\"Range1d\"},{\"attributes\":{\"base\":{\"field\":\"num_steps_trained\",\"units\":\"data\"},\"fill_alpha\":0.3,\"level\":\"underlay\",\"line_color\":\"blue\",\"lower\":{\"field\":\"lower\",\"units\":\"data\"},\"source\":{\"id\":\"1562\"},\"upper\":{\"field\":\"upper\",\"units\":\"data\"}},\"id\":\"1597\",\"type\":\"Band\"},{\"attributes\":{},\"id\":\"1580\",\"type\":\"PanTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1580\"},{\"id\":\"1581\"},{\"id\":\"1582\"},{\"id\":\"1583\"},{\"id\":\"1584\"}]},\"id\":\"1586\",\"type\":\"Toolbar\"}],\"root_ids\":[\"1564\"]},\"title\":\"Bokeh Application\",\"version\":\"2.0.1\"}};\n",
       "  var render_items = [{\"docid\":\"21867dca-169b-438c-b8ad-56872e3ecd5a\",\"root_ids\":[\"1564\"],\"roots\":{\"1564\":\"2791b290-6abb-4690-b1cd-acdfa4e371f8\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1564"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['lower'] = df['mean'] - df['std']\n",
    "df['upper'] = df['mean'] + df['std']\n",
    "ymin=df['lower'].min()\n",
    "ymax=df['upper'].max()\n",
    "\n",
    "source = ColumnDataSource(df.reset_index())\n",
    "\n",
    "TOOLS = \"pan,wheel_zoom,box_zoom,reset,save\"\n",
    "p = figure(tools=TOOLS, y_range=Range1d(ymin,ymax))\n",
    "\n",
    "p.scatter(x='num_steps_trained', y='mean', line_color='black', fill_alpha=0.3, size=5, source=source)\n",
    "band = Band(base='num_steps_trained', lower='lower', upper='upper', source=source, level='underlay',\n",
    "            fill_alpha=0.3, line_width=1, line_color='blue')\n",
    "p.add_layout(band)\n",
    "\n",
    "p.title.text = \"Cumulative Regret\"\n",
    "p.xgrid[0].grid_line_alpha=0.5\n",
    "p.ygrid[0].grid_line_alpha=0.5\n",
    "p.xaxis.axis_label = 'Training Steps'\n",
    "p.yaxis.axis_label = 'Regret'\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regret appears to flatten more quickly, but the standard deviation is huge! So, let's see if changing any of the parameters defined in `DEFAULT_CONFIG_LINEAR` makes a difference. \n",
    "\n",
    "> **NOTE:** If you change a value and try it, then change another value and try again, reset the first value, etc.!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 5 (4 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00001</td><td>PENDING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00002</td><td>PENDING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00003</td><td>PENDING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00004</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-10 16:02:12,675\tERROR trial_runner.py:519 -- Trial contrib_LinUCB_LinearDiscreteEnv_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 431, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/worker.py\", line 1515, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::LinUCB.train()\u001b[39m (pid=82991, ip=192.168.1.149)\n",
      "  File \"python/ray/_raylet.pyx\", line 424, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 459, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 462, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 463, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 417, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 90, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 448, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/trainable.py\", line 174, in __init__\n",
      "    self._setup(copy.deepcopy(self.config))\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 554, in _setup\n",
      "    config)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 921, in merge_trainer_configs\n",
      "    cls._override_all_subkeys_if_type_changes)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/utils/util.py\", line 181, in deep_update\n",
      "    raise Exception(\"Unknown config parameter `{}` \".format(k))\n",
      "Exception: Unknown config parameter `feature_dim`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.4/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 5 (1 ERROR, 4 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00000</td><td>ERROR   </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00001</td><td>RUNNING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00002</td><td>RUNNING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00003</td><td>RUNNING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00004</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                            </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00000</td><td style=\"text-align: right;\">           1</td><td>/Users/deanwampler/ray_results/contrib/LinUCB/contrib_LinUCB_LinearDiscreteEnv_0_2020-06-10_16-02-071h2ye8rk/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=82991)\u001b[0m 2020-06-10 16:02:12,667\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-10 16:02:13,341\tERROR trial_runner.py:519 -- Trial contrib_LinUCB_LinearDiscreteEnv_00002: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 431, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/worker.py\", line 1515, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::LinUCB.train()\u001b[39m (pid=83043, ip=192.168.1.149)\n",
      "  File \"python/ray/_raylet.pyx\", line 424, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 459, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 462, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 463, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 417, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 90, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 448, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/trainable.py\", line 174, in __init__\n",
      "    self._setup(copy.deepcopy(self.config))\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 554, in _setup\n",
      "    config)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 921, in merge_trainer_configs\n",
      "    cls._override_all_subkeys_if_type_changes)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/utils/util.py\", line 181, in deep_update\n",
      "    raise Exception(\"Unknown config parameter `{}` \".format(k))\n",
      "Exception: Unknown config parameter `feature_dim`\n",
      "2020-06-10 16:02:13,361\tERROR trial_runner.py:519 -- Trial contrib_LinUCB_LinearDiscreteEnv_00001: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 431, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/worker.py\", line 1515, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::LinUCB.train()\u001b[39m (pid=83041, ip=192.168.1.149)\n",
      "  File \"python/ray/_raylet.pyx\", line 424, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 459, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 462, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 463, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 417, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 90, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 448, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/trainable.py\", line 174, in __init__\n",
      "    self._setup(copy.deepcopy(self.config))\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 554, in _setup\n",
      "    config)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 921, in merge_trainer_configs\n",
      "    cls._override_all_subkeys_if_type_changes)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/utils/util.py\", line 181, in deep_update\n",
      "    raise Exception(\"Unknown config parameter `{}` \".format(k))\n",
      "Exception: Unknown config parameter `feature_dim`\n",
      "2020-06-10 16:02:13,368\tERROR trial_runner.py:519 -- Trial contrib_LinUCB_LinearDiscreteEnv_00004: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 431, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/worker.py\", line 1515, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::LinUCB.train()\u001b[39m (pid=83042, ip=192.168.1.149)\n",
      "  File \"python/ray/_raylet.pyx\", line 424, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 459, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 462, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 463, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 417, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 90, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 448, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/trainable.py\", line 174, in __init__\n",
      "    self._setup(copy.deepcopy(self.config))\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 554, in _setup\n",
      "    config)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 921, in merge_trainer_configs\n",
      "    cls._override_all_subkeys_if_type_changes)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/utils/util.py\", line 181, in deep_update\n",
      "    raise Exception(\"Unknown config parameter `{}` \".format(k))\n",
      "Exception: Unknown config parameter `feature_dim`\n",
      "2020-06-10 16:02:13,390\tERROR trial_runner.py:519 -- Trial contrib_LinUCB_LinearDiscreteEnv_00003: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 431, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/worker.py\", line 1515, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::LinUCB.train()\u001b[39m (pid=83044, ip=192.168.1.149)\n",
      "  File \"python/ray/_raylet.pyx\", line 424, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 459, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 462, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 463, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 417, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 90, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 448, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/trainable.py\", line 174, in __init__\n",
      "    self._setup(copy.deepcopy(self.config))\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 554, in _setup\n",
      "    config)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 921, in merge_trainer_configs\n",
      "    cls._override_all_subkeys_if_type_changes)\n",
      "  File \"/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/utils/util.py\", line 181, in deep_update\n",
      "    raise Exception(\"Unknown config parameter `{}` \".format(k))\n",
      "Exception: Unknown config parameter `feature_dim`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=83041)\u001b[0m 2020-06-10 16:02:13,338\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=83043)\u001b[0m 2020-06-10 16:02:13,335\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=83042)\u001b[0m 2020-06-10 16:02:13,338\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/4.44 GiB heap, 0.0/1.51 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 5 (5 ERROR)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00000</td><td>ERROR   </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00001</td><td>ERROR   </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00002</td><td>ERROR   </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00003</td><td>ERROR   </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00004</td><td>ERROR   </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 5<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                            </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00000</td><td style=\"text-align: right;\">           1</td><td>/Users/deanwampler/ray_results/contrib/LinUCB/contrib_LinUCB_LinearDiscreteEnv_0_2020-06-10_16-02-071h2ye8rk/error.txt</td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00001</td><td style=\"text-align: right;\">           1</td><td>/Users/deanwampler/ray_results/contrib/LinUCB/contrib_LinUCB_LinearDiscreteEnv_1_2020-06-10_16-02-07v9cieqvg/error.txt</td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00002</td><td style=\"text-align: right;\">           1</td><td>/Users/deanwampler/ray_results/contrib/LinUCB/contrib_LinUCB_LinearDiscreteEnv_2_2020-06-10_16-02-07wtuk5mi3/error.txt</td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00003</td><td style=\"text-align: right;\">           1</td><td>/Users/deanwampler/ray_results/contrib/LinUCB/contrib_LinUCB_LinearDiscreteEnv_3_2020-06-10_16-02-078rv3syv0/error.txt</td></tr>\n",
       "<tr><td>contrib_LinUCB_LinearDiscreteEnv_00004</td><td style=\"text-align: right;\">           1</td><td>/Users/deanwampler/ray_results/contrib/LinUCB/contrib_LinUCB_LinearDiscreteEnv_4_2020-06-10_16-02-072f0qh259/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=83044)\u001b[0m 2020-06-10 16:02:13,381\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [contrib_LinUCB_LinearDiscreteEnv_00000, contrib_LinUCB_LinearDiscreteEnv_00001, contrib_LinUCB_LinearDiscreteEnv_00002, contrib_LinUCB_LinearDiscreteEnv_00003, contrib_LinUCB_LinearDiscreteEnv_00004])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-1704bdbb1fbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"training_iteration\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining_iterations\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcheckpoint_at_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, stop, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, loggers, sync_to_cloud, sync_to_driver, checkpoint_freq, checkpoint_at_end, sync_on_checkpoint, keep_checkpoints_num, checkpoint_score_attr, global_checkpoint_period, export_formats, max_failures, fail_fast, restore, search_alg, scheduler, with_server, server_port, verbose, progress_reporter, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, return_trials, ray_auto_init)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [contrib_LinUCB_LinearDiscreteEnv_00000, contrib_LinUCB_LinearDiscreteEnv_00001, contrib_LinUCB_LinearDiscreteEnv_00002, contrib_LinUCB_LinearDiscreteEnv_00003, contrib_LinUCB_LinearDiscreteEnv_00004])"
     ]
    }
   ],
   "source": [
    "DEFAULT_CONFIG_LINEAR[\"reward_noise_std\"] = 0.001  # default 0.01\n",
    "DEFAULT_CONFIG_LINEAR[\"num_actions\"] = 4           # default 4\n",
    "DEFAULT_CONFIG_LINEAR[\"feature_dim\"] = 8           # default 8\n",
    "\n",
    "analysis = tune.run(\n",
    "    \"contrib/LinUCB\",\n",
    "    config=DEFAULT_CONFIG_LINEAR,\n",
    "    stop={\"training_iteration\": training_iterations},\n",
    "    num_samples=5,\n",
    "    checkpoint_at_end=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'num_steps_trained'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-ff73cb49d922>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m df2 = frame2.groupby(\"num_steps_trained\")[\n\u001b[0m\u001b[1;32m      7\u001b[0m     \"learner/cumulative_regret\"].aggregate([\"mean\", \"max\", \"min\", \"std\"])\n\u001b[1;32m      8\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed)\u001b[0m\n\u001b[1;32m   5808\u001b[0m             \u001b[0mgroup_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5809\u001b[0m             \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5810\u001b[0;31m             \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5811\u001b[0m         )\n\u001b[1;32m   5812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                 \u001b[0mmutated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m             )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate)\u001b[0m\n\u001b[1;32m    596\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'num_steps_trained'"
     ]
    }
   ],
   "source": [
    "frame2 = pd.DataFrame()\n",
    "\n",
    "for key, df in analysis.trial_dataframes.items():\n",
    "    frame = frame.append(df, ignore_index=True)\n",
    "\n",
    "df2 = frame2.groupby(\"num_steps_trained\")[\n",
    "    \"learner/cumulative_regret\"].aggregate([\"mean\", \"max\", \"min\", \"std\"])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"3cb07163-33d8-4075-a51b-8b67f114c215\" data-root-id=\"2002\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"e28e8499-2aa3-4172-87b2-72b05f526a89\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"2010\"}],\"center\":[{\"id\":\"2013\"},{\"id\":\"2017\"},{\"id\":\"2035\"}],\"left\":[{\"id\":\"2014\"}],\"renderers\":[{\"id\":\"2033\"}],\"title\":{\"id\":\"2037\"},\"toolbar\":{\"id\":\"2024\"},\"x_range\":{\"id\":\"2003\"},\"x_scale\":{\"id\":\"2006\"},\"y_range\":{\"id\":\"2001\"},\"y_scale\":{\"id\":\"2008\"}},\"id\":\"2002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"axis\":{\"id\":\"2010\"},\"grid_line_alpha\":0.5,\"ticker\":null},\"id\":\"2013\",\"type\":\"Grid\"},{\"attributes\":{\"base\":{\"field\":\"num_steps_trained\",\"units\":\"data\"},\"fill_alpha\":0.3,\"level\":\"underlay\",\"line_color\":\"blue\",\"lower\":{\"field\":\"lower\",\"units\":\"data\"},\"source\":{\"id\":\"2000\"},\"upper\":{\"field\":\"upper\",\"units\":\"data\"}},\"id\":\"2035\",\"type\":\"Band\"},{\"attributes\":{\"end\":10.79363220817091,\"start\":6.146463728677945},\"id\":\"2001\",\"type\":\"Range1d\"},{\"attributes\":{\"axis\":{\"id\":\"2014\"},\"dimension\":1,\"grid_line_alpha\":0.5,\"ticker\":null},\"id\":\"2017\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"2018\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"2019\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"2106\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"axis_label\":\"Regret\",\"formatter\":{\"id\":\"2104\"},\"ticker\":{\"id\":\"2015\"}},\"id\":\"2014\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"2008\",\"type\":\"LinearScale\"},{\"attributes\":{\"text\":\"Cumulative Regret\"},\"id\":\"2037\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"2109\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"2018\"},{\"id\":\"2019\"},{\"id\":\"2020\"},{\"id\":\"2021\"},{\"id\":\"2022\"}]},\"id\":\"2024\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"2006\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"2003\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"2011\",\"type\":\"BasicTicker\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"2023\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"2108\",\"type\":\"Selection\"},{\"attributes\":{\"data_source\":{\"id\":\"2000\"},\"glyph\":{\"id\":\"2031\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"2032\"},\"selection_glyph\":null,\"view\":{\"id\":\"2034\"}},\"id\":\"2033\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"size\":{\"units\":\"screen\",\"value\":5},\"x\":{\"field\":\"num_steps_trained\"},\"y\":{\"field\":\"mean\"}},\"id\":\"2032\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"2022\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"2015\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"2021\",\"type\":\"ResetTool\"},{\"attributes\":{\"source\":{\"id\":\"2000\"}},\"id\":\"2034\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"2104\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"overlay\":{\"id\":\"2023\"}},\"id\":\"2020\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"data\":{\"index\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"lower\":{\"__ndarray__\":\"UuNylvqVGEA5LSOcKxUbQDXw6fJ5VBtApyrYL8B9G0A/MrSeqOQbQD4oFy47/xtAjUGt6GRoHEAUsYi59ZkcQFT79Hcj5RxATdZMxzEAHUCEinpmVTAdQJSLWvKOSx1AxrXrBrRpHUBmZqrYt3sdQAae5x13jh1ApusbSvGTHUDuDf/3sLUdQGSDext3xB1AkCDMlU3NHUDWbdUQENUdQA==\",\"dtype\":\"float64\",\"shape\":[20]},\"max\":{\"__ndarray__\":\"t3xOj4TlIkAaStI30E4kQA8xVS+94iRAQU/ZVRldJUBT6BSkCnolQNOe7OYyjyVAyKWQb+bAJUC2w4bUFM4lQAb9r10L0CVA3gOTinrWJUCxbZZwDtwlQIuryLV+3iVAEbmaz8XgJUDNaxQa+OwlQNKnsZYc9SVApdymmQ4BJkCT2DN83wImQH1joZbKBiZACYoP9+oJJkBpFXifFhsmQA==\",\"dtype\":\"float64\",\"shape\":[20]},\"mean\":{\"__ndarray__\":\"2gvbbv1xHkCr7lpCmoQgQMVlkLS21SBAWDstihQgIUAO01KM9VchQHuoZ8lccCFA9qfAgjyWIUBnvv4lu64hQEMrgtFvzCFAuC4e6QTiIUAC7yf83/MhQE9tusA//CFApD/fVb0JIkB8T9QfgxYiQLIYdhdLICJAyc/PRj4mIkDU/re02DAiQEgDkb0ZNyJAaICedIM5IkDrgDB/b0AiQA==\",\"dtype\":\"float64\",\"shape\":[20]},\"min\":{\"__ndarray__\":\"+QRMFItfFkCp4BPdOu4YQFDi2BlkERlAwD8f6KkeGUBULAqaG6gZQLYtGq5jtxlAy4riee5nGkAX081WGX0aQEyhblXG4xpA/5ualGQGG0AmAeQysC4bQHAsWRqCQBtAwtuK7iFOG0CEFsVUx2MbQDq4LZpTgxtAsHhbrHyMG0DA/sA9f6sbQLUlT5hwwxtA57v5/VDVG0CVYD65xegbQA==\",\"dtype\":\"float64\",\"shape\":[20]},\"num_steps_trained\":[100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000],\"std\":{\"__ndarray__\":\"H6KgYQtw9z90wEqiI9D3P1Nt29jNW/k/IzAJkqMJ+z9zz8XnCS37P9+i4JL5hfs/fDlQc1AQ+z/nLtNJAg77P8dsPazwzvo/jRy+K2AP+z8ATlVHqt36PyY8aTzCs/o/BiZLkxqn+j9G4vibOcX6P3hNEkR8yPo/ss8ODi3i+j/qvsPFAbD6P7EMmn7xpvo/AIHDTeWW+j8CUC62O6/6Pw==\",\"dtype\":\"float64\",\"shape\":[20]},\"upper\":{\"__ndarray__\":\"MZqhIwAnIkC6RqS2nn4jQG/Tq28wASRAXGFu/EiBJED8jEvJlr0kQNe8w/sb4SRAJq8qkUb4JEBEJDlvexAlQNzYCedNJiVASvKV7vBDJUDCmBJFlU8lQNSURwi4UiVAZaRIqKBeJUDFa1NTKm8lQGFi+J9aeSVAv6mR6IOCJUCxdnDt2IYlQN5EZO33iyVAiPBWHmCMJUDrSvb1VpYlQA==\",\"dtype\":\"float64\",\"shape\":[20]}},\"selected\":{\"id\":\"2108\"},\"selection_policy\":{\"id\":\"2109\"}},\"id\":\"2000\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"axis_label\":\"Training Steps\",\"formatter\":{\"id\":\"2106\"},\"ticker\":{\"id\":\"2011\"}},\"id\":\"2010\",\"type\":\"LinearAxis\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.3},\"fill_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":5},\"x\":{\"field\":\"num_steps_trained\"},\"y\":{\"field\":\"mean\"}},\"id\":\"2031\",\"type\":\"Scatter\"}],\"root_ids\":[\"2002\"]},\"title\":\"Bokeh Application\",\"version\":\"2.0.1\"}};\n",
       "  var render_items = [{\"docid\":\"e28e8499-2aa3-4172-87b2-72b05f526a89\",\"root_ids\":[\"2002\"],\"roots\":{\"2002\":\"3cb07163-33d8-4075-a51b-8b67f114c215\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "2002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2['lower'] = df2['mean'] - df2['std']\n",
    "df2['upper'] = df2['mean'] + df2['std']\n",
    "ymin2=df2['lower'].min()\n",
    "ymax2=df2['upper'].max()\n",
    "\n",
    "source2 = ColumnDataSource(df2.reset_index())\n",
    "\n",
    "TOOLS = \"pan,wheel_zoom,box_zoom,reset,save\"\n",
    "p2 = figure(tools=TOOLS, y_range=Range1d(ymin2,ymax2))\n",
    "\n",
    "p2.scatter(x='num_steps_trained', y='mean', line_color='black', fill_alpha=0.3, size=5, source=source2)\n",
    "band2 = Band(base='num_steps_trained', lower='lower', upper='upper', source=source2, level='underlay',\n",
    "            fill_alpha=0.3, line_width=1, line_color='blue')\n",
    "p2.add_layout(band2)\n",
    "\n",
    "p2.title.text = \"Cumulative Regret\"\n",
    "p2.xgrid[0].grid_line_alpha=0.5\n",
    "p2.ygrid[0].grid_line_alpha=0.5\n",
    "p2.xaxis.axis_label = 'Training Steps'\n",
    "p2.yaxis.axis_label = 'Regret'\n",
    "\n",
    "show(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope, changing the standard deviation and any of the other fields didn't made a difference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
